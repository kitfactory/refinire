#!/usr/bin/env python3
"""
Advanced Features Demo - routing_instructionã€fast_modeã€Flowã®çµ±åˆãƒ‡ãƒ¢
é«˜åº¦æ©Ÿèƒ½ãƒ‡ãƒ¢ - ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æŒ‡ç¤ºã€é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã€ãƒ•ãƒ­ãƒ¼ã®çµ±åˆå®Ÿæ¼”

This demonstrates the combined use of routing_instruction, fast_mode, and Flow.
ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æŒ‡ç¤ºã€é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã€ãƒ•ãƒ­ãƒ¼ã®çµ„ã¿åˆã‚ã›ä½¿ç”¨ã‚’å®Ÿæ¼”ã—ã¾ã™ã€‚
"""

import asyncio
import os
import time
from typing import Literal
from refinire import RefinireAgent
from refinire.agents.flow import Flow, FunctionStep, ConditionStep, Context


# Define request types / ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ—ã‚’å®šç¾©
RequestType = Literal["urgent", "standard", "analysis"]


class SmartRequestProcessor:
    """
    Smart request processor combining all advanced features
    ã™ã¹ã¦ã®é«˜åº¦æ©Ÿèƒ½ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¹ãƒãƒ¼ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
    """
    
    def __init__(self):
        # Router agent with routing_instruction / ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æŒ‡ç¤ºä»˜ããƒ«ãƒ¼ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
        self.router = RefinireAgent(
            name="smart_router",
            generation_instructions="""
You are an intelligent request classifier. Analyze incoming requests and categorize them:

- urgent: Time-sensitive requests, quick questions, immediate needs
- standard: Regular requests that need thorough processing
- analysis: Complex analytical tasks requiring detailed investigation

ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æã—ã€ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã¦ãã ã•ã„:
- urgent: æ™‚é–“ã«æ•æ„Ÿãªè¦æ±‚ã€ç°¡å˜ãªè³ªå•ã€å³åº§ã®å¿…è¦æ€§
- standard: å¾¹åº•çš„ãªå‡¦ç†ãŒå¿…è¦ãªé€šå¸¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ  
- analysis: è©³ç´°ãªèª¿æŸ»ãŒå¿…è¦ãªè¤‡é›‘ãªåˆ†æã‚¿ã‚¹ã‚¯
            """,
            model="gpt-4o-mini",
            routing_instruction="Classify this request into the most appropriate category",
            fast_mode=True,  # Use fast mode for quick routing / é«˜é€Ÿãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ãŸã‚é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ä½¿ç”¨
            timeout=30
        )
        
        # Urgent processor with fast_mode / é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ä»˜ãç·Šæ€¥ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
        self.urgent_processor = RefinireAgent(
            name="urgent_handler",
            generation_instructions="Provide quick, direct answers. Be concise and helpful.",
            model="gpt-4o-mini",
            fast_mode=True,
            evaluation_enabled=False,
            max_tokens=150,
            timeout=20
        )
        
        # Standard processor / æ¨™æº–ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
        self.standard_processor = RefinireAgent(
            name="standard_handler", 
            generation_instructions="Provide thorough, well-researched responses with examples.",
            model="gpt-4o-mini",
            fast_mode=False,
            evaluation_enabled=True,
            timeout=60
        )
    
    async def route_request(self, context: Context) -> str:
        """Route request using routing_instruction"""
        print("ğŸ”€ Routing request...")
        print("ğŸ”€ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ä¸­...")
        
        user_request = context.shared_state.get('user_request', '')
        start_time = time.time()
        
        try:
            result = await self.router.run(user_request, expected_output=RequestType)
            routing_time = time.time() - start_time
            
            if result.success:
                request_type = result.content
                context.shared_state['request_type'] = request_type
                context.shared_state['routing_time'] = routing_time
                
                print(f"   âœ… Routed to: {request_type} ({routing_time:.2f}s)")
                print(f"   âœ… ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å…ˆ: {request_type} ({routing_time:.2f}ç§’)")
                return request_type
            else:
                print(f"   âŒ Routing failed: {result.content}")
                context.shared_state['request_type'] = 'standard'
                return 'standard'
                
        except Exception as e:
            print(f"   âŒ Routing error: {e}")
            context.shared_state['request_type'] = 'standard'
            return 'standard'
    
    def route_by_type(self, context: Context) -> str:
        """Conditional routing based on request type"""
        request_type = context.shared_state.get('request_type', 'standard')
        
        if request_type == 'urgent':
            return 'process_urgent'
        elif request_type == 'analysis':
            return 'process_analysis'
        else:
            return 'process_standard'
    
    async def process_urgent(self, context: Context) -> str:
        """Process urgent requests with fast_mode"""
        print("âš¡ Processing urgent request (fast mode)...")
        print("âš¡ ç·Šæ€¥ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ä¸­ï¼ˆé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰...")
        
        user_request = context.shared_state.get('user_request', '')
        start_time = time.time()
        
        try:
            result = await self.urgent_processor.run(user_request)
            processing_time = time.time() - start_time
            
            if result.success:
                response = result.content
                context.shared_state['response'] = response
                context.shared_state['processing_time'] = processing_time
                
                print(f"   âœ… Urgent response ready ({processing_time:.2f}s)")
                print(f"   âœ… ç·Šæ€¥å¿œç­”æº–å‚™å®Œäº† ({processing_time:.2f}ç§’)")
                return response
            else:
                print(f"   âŒ Urgent processing failed: {result.content}")
                return "Urgent processing failed"
                
        except Exception as e:
            print(f"   âŒ Urgent processing error: {e}")
            return f"Error: {e}"
    
    async def process_standard(self, context: Context) -> str:
        """Process standard requests with full evaluation"""
        print("ğŸ“ Processing standard request (full evaluation)...")
        print("ğŸ“ æ¨™æº–ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ä¸­ï¼ˆå®Œå…¨è©•ä¾¡ï¼‰...")
        
        user_request = context.shared_state.get('user_request', '')
        start_time = time.time()
        
        try:
            result = await self.standard_processor.run(user_request)
            processing_time = time.time() - start_time
            
            if result.success:
                response = result.content
                context.shared_state['response'] = response
                context.shared_state['processing_time'] = processing_time
                
                print(f"   âœ… Standard response ready ({processing_time:.2f}s)")
                print(f"   âœ… æ¨™æº–å¿œç­”æº–å‚™å®Œäº† ({processing_time:.2f}ç§’)")
                return response
            else:
                print(f"   âŒ Standard processing failed: {result.content}")
                return "Standard processing failed"
                
        except Exception as e:
            print(f"   âŒ Standard processing error: {e}")
            return f"Error: {e}"
    
    async def process_analysis(self, context: Context) -> str:
        """Process analytical requests with detailed investigation"""
        print("ğŸ” Processing analysis request (detailed investigation)...")
        print("ğŸ” åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ä¸­ï¼ˆè©³ç´°èª¿æŸ»ï¼‰...")
        
        user_request = context.shared_state.get('user_request', '')
        start_time = time.time()
        
        # Multi-step analysis using specialized agents
        # å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ãŸãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—åˆ†æ
        
        # Step 1: Break down the analysis
        analyzer = RefinireAgent(
            name="analyst",
            generation_instructions="""
Break down this analytical request into key components:
1. Main question or problem
2. Required data or information
3. Analysis approach
4. Expected deliverables

ã“ã®åˆ†æè¦æ±‚ã‚’ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«åˆ†è§£ã—ã¦ãã ã•ã„:
1. ä¸»è¦ãªè³ªå•ã‚„å•é¡Œ
2. å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚„æƒ…å ±
3. åˆ†æã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
4. æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©
            """,
            model="gpt-4o-mini"
        )
        
        breakdown_result = await analyzer.run(f"Analyze this request: {user_request}")
        breakdown = breakdown_result.content if breakdown_result.success else "Analysis breakdown failed"
        
        # Step 2: Conduct detailed analysis
        detailed_analyzer = RefinireAgent(
            name="detailed_analyst",
            generation_instructions="""
Provide comprehensive analysis with:
- Detailed findings
- Supporting evidence
- Multiple perspectives
- Actionable recommendations

ä»¥ä¸‹ã‚’å«ã‚€åŒ…æ‹¬çš„åˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„:
- è©³ç´°ãªç™ºè¦‹
- è£ä»˜ã‘è¨¼æ‹ 
- è¤‡æ•°ã®è¦–ç‚¹
- å®Ÿè¡Œå¯èƒ½ãªæ¨å¥¨äº‹é …
            """,
            model="gpt-4o-mini"
        )
        
        analysis_result = await detailed_analyzer.run(f"Conduct detailed analysis based on: {breakdown}")
        analysis = analysis_result.content if analysis_result.success else "Detailed analysis failed"
        
        processing_time = time.time() - start_time
        
        response = f"Analysis Breakdown:\n{breakdown}\n\nDetailed Analysis:\n{analysis}"
        context.shared_state['response'] = response
        context.shared_state['processing_time'] = processing_time
        
        print(f"   âœ… Analysis complete ({processing_time:.2f}s)")
        print(f"   âœ… åˆ†æå®Œäº† ({processing_time:.2f}ç§’)")
        return response
    
    async def finalize_response(self, context: Context) -> str:
        """Finalize and format the response"""
        print("ğŸ“‹ Finalizing response...")
        print("ğŸ“‹ å¿œç­”ã®æœ€çµ‚å‡¦ç†ä¸­...")
        
        response = context.shared_state.get('response', 'No response generated')
        request_type = context.shared_state.get('request_type', 'unknown')
        routing_time = context.shared_state.get('routing_time', 0)
        processing_time = context.shared_state.get('processing_time', 0)
        total_time = routing_time + processing_time
        
        # Add metadata
        final_response = f"""
Response Type: {request_type}
Processing Time: {total_time:.2f}s (routing: {routing_time:.2f}s, processing: {processing_time:.2f}s)

{response}
        """.strip()
        
        context.shared_state['final_response'] = final_response
        return final_response
    
    def create_workflow(self) -> Flow:
        """Create the processing workflow using Flow"""
        return Flow({
            "start": FunctionStep("route", self.route_request),
            "routing": ConditionStep("type_route", self.route_by_type, "process_standard", "process_urgent", "process_analysis"),
            "process_urgent": FunctionStep("urgent", self.process_urgent),
            "process_standard": FunctionStep("standard", self.process_standard), 
            "process_analysis": FunctionStep("analysis", self.process_analysis),
            "finalize": FunctionStep("finalize", self.finalize_response)
        })


async def advanced_features_demo():
    """
    Demonstrate the integration of all advanced features
    ã™ã¹ã¦ã®é«˜åº¦æ©Ÿèƒ½ã®çµ±åˆã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    print("ğŸš€ Advanced Features Integration Demo")
    print("ğŸš€ é«˜åº¦æ©Ÿèƒ½çµ±åˆãƒ‡ãƒ¢")
    print("=" * 60)
    
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ Please set OPENAI_API_KEY environment variable.")
        print("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    # Create processor and workflow
    processor = SmartRequestProcessor()
    workflow = processor.create_workflow()
    
    # Test requests / ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    test_requests = [
        {
            "type": "urgent",
            "request": "What's 2+2?",
            "description": "Simple math question (should route to urgent)"
        },
        {
            "type": "standard", 
            "request": "How do I learn Python programming?",
            "description": "Learning guidance (should route to standard)"
        },
        {
            "type": "analysis",
            "request": "Analyze the pros and cons of remote work vs office work in 2024",
            "description": "Complex analysis (should route to analysis)"
        }
    ]
    
    print(f"\nğŸ§ª Testing {len(test_requests)} different request types:")
    print(f"ğŸ§ª {len(test_requests)}ç¨®é¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ—ã‚’ãƒ†ã‚¹ãƒˆ:")
    
    total_start_time = time.time()
    
    for i, test_case in enumerate(test_requests, 1):
        print(f"\n{'='*50}")
        print(f"ğŸ“‹ Test {i}: {test_case['description']}")
        print(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆ{i}: {test_case['description']}")
        print(f"ğŸ“ Request: {test_case['request']}")
        print(f"ğŸ“ ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {test_case['request']}")
        print("-" * 30)
        
        # Create context and run workflow
        context = Context()
        context.shared_state['user_request'] = test_case['request']
        
        try:
            start_time = time.time()
            result = await workflow.run(context)
            execution_time = time.time() - start_time
            
            if result:
                final_response = context.shared_state.get('final_response', 'No response')
                request_type = context.shared_state.get('request_type', 'unknown')
                
                print(f"\nâœ… Test {i} completed successfully!")
                print(f"âœ… ãƒ†ã‚¹ãƒˆ{i} æ­£å¸¸å®Œäº†ï¼")
                print(f"ğŸ¯ Detected type: {request_type}")
                print(f"ğŸ¯ æ¤œå‡ºã‚¿ã‚¤ãƒ—: {request_type}")
                print(f"â±ï¸  Total execution: {execution_time:.2f}s")
                print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
                print(f"\nğŸ“„ Response:\n{final_response}")
                
                # Verify routing accuracy
                expected_contains = test_case['type']
                if expected_contains in request_type or test_case['type'] == 'standard':
                    print(f"âœ… Routing accuracy: Correct")
                    print(f"âœ… ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç²¾åº¦: æ­£ç¢º")
                else:
                    print(f"âš ï¸  Routing accuracy: Expected {test_case['type']}, got {request_type}")
                    print(f"âš ï¸  ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç²¾åº¦: æœŸå¾…å€¤{test_case['type']}ã€å®Ÿéš›{request_type}")
                
            else:
                print(f"âŒ Test {i} failed")
                print(f"âŒ ãƒ†ã‚¹ãƒˆ{i} å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ Test {i} error: {e}")
            print(f"âŒ ãƒ†ã‚¹ãƒˆ{i} ã‚¨ãƒ©ãƒ¼: {e}")
    
    total_time = time.time() - total_start_time
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ Advanced Features Demo Complete!")
    print(f"ğŸ‰ é«˜åº¦æ©Ÿèƒ½ãƒ‡ãƒ¢å®Œäº†ï¼")
    print(f"â±ï¸  Total demo time: {total_time:.2f}s")
    print(f"â±ï¸  ç·ãƒ‡ãƒ¢æ™‚é–“: {total_time:.2f}ç§’")
    
    print(f"\nğŸ’¡ Features Demonstrated:")
    print(f"ğŸ’¡ å®Ÿæ¼”ã•ã‚ŒãŸæ©Ÿèƒ½:")
    print(f"   âœ… routing_instruction - Intelligent request classification")
    print(f"   âœ… fast_mode - High-speed processing for urgent requests")
    print(f"   âœ… Flow - Complex multi-step workflow orchestration")
    print(f"   âœ… Conditional routing - Dynamic workflow paths")
    print(f"   âœ… Performance optimization - Different modes for different needs")


if __name__ == "__main__":
    asyncio.run(advanced_features_demo())