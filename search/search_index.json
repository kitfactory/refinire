{"config":{"lang":["ja"],"separator":"[\\s\\-\u3000\u3001\u3002\uff0c\uff0e]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"Welcome to Refinire","text":"<p>A comprehensive extension for OpenAI Agents SDK that provides unified interfaces for multiple LLM providers and advanced workflow capabilities.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Easy switching between OpenAI, Gemini, Claude, Ollama and other major LLMs</li> <li>\ud83d\ude80 New Feature: Ultra-simple workflow creation with <code>Flow(steps=gen_agent)</code></li> <li>\ud83d\ude80 New Feature: Automatic sequential execution with <code>Flow(steps=[step1, step2])</code></li> <li>Integrated pipeline combining generation, evaluation, tools, and guardrails</li> <li>Self-improvement cycles with just model names and prompts</li> <li>Pydantic-based structured output support</li> <li>Python 3.9+ / Windows, Linux, MacOS support</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi","title":"From PyPI","text":"<pre><code>pip install refinire\n</code></pre>"},{"location":"#using-uv","title":"Using uv","text":"<pre><code>uv pip install refinire\n</code></pre>"},{"location":"#development-recommended","title":"Development (Recommended)","text":"<pre><code>git clone https://github.com/kitfactory/refinire.git\ncd refinire\npython -m venv .venv\n.venv\\Scripts\\activate  # Windows\nsource .venv/bin/activate  # Linux/Mac\nuv pip install -e .[dev]\n</code></pre>"},{"location":"#supported-environments","title":"Supported Environments","text":"<ul> <li>Python 3.9+</li> <li>OpenAI Agents SDK 0.0.9+</li> <li>Windows, Linux, MacOS </li> </ul>"},{"location":"#tracing","title":"Tracing","text":"<p>This library supports OpenAI Agents SDK tracing features. For details, see Tracing.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>API Reference - Detailed class and function documentation</li> <li>Quick Start - Get started immediately</li> <li>Composable Flow Architecture - Advanced workflow construction</li> </ul>"},{"location":"#learning-resources","title":"Learning Resources","text":"<ul> <li>Tutorials - Step-by-step learning content</li> <li>Examples - Practical use cases  </li> <li>Developer Guide - Information for contributors </li> </ul>"},{"location":"README_ja/","title":"agents-sdk-models \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":""},{"location":"README_ja/#_1","title":"\ud83c\udf1f \u306f\u3058\u3081\u306b","text":"<p>\u3053\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f\u3001OpenAI Agents SDK\u3092\u6d3b\u7528\u3057\u305f\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u30fb\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u69cb\u7bc9\u3092\u652f\u63f4\u3059\u308bPython\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002 \u751f\u6210\u30fb\u8a55\u4fa1\u30fb\u30c4\u30fc\u30eb\u9023\u643a\u30fb\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u306a\u3069\u3001\u5b9f\u8df5\u7684\u306aAI\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u6700\u5c0f\u9650\u306e\u8a18\u8ff0\u3067\u5b9f\u73fe\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"README_ja/#_2","title":"\ud83d\ude80 \u7279\u5fb4\u30fb\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\ud83e\udde9 \u751f\u6210\u30fb\u8a55\u4fa1\u30fb\u30c4\u30fc\u30eb\u30fb\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3092\u67d4\u8edf\u306b\u7d44\u307f\u5408\u308f\u305b\u305f\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u7c21\u5358\u306b\u69cb\u7bc9</li> <li>\ud83d\udee0\ufe0f Python\u95a2\u6570\u3092\u305d\u306e\u307e\u307e\u30c4\u30fc\u30eb\u3068\u3057\u3066\u5229\u7528\u53ef\u80fd</li> <li>\ud83d\udee1\ufe0f \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3067\u5b89\u5168\u30fb\u5805\u7262\u306a\u5165\u529b/\u51fa\u529b\u5236\u5fa1</li> <li>\ud83d\udce6 \u8c4a\u5bcc\u306a\u30b5\u30f3\u30d7\u30eb\uff08<code>examples/</code>\uff09\u3067\u3059\u3050\u306b\u8a66\u305b\u308b</li> <li>\ud83d\ude80 \u6700\u5c0f\u9650\u306e\u8a18\u8ff0\u3067\u7d20\u65e9\u304f\u30d7\u30ed\u30c8\u30bf\u30a4\u30d4\u30f3\u30b0</li> </ul>"},{"location":"README_ja/#_3","title":"\u26a1 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<p><pre><code>pip install agents-sdk-models\n</code></pre> - OpenAI Agents SDK, pydantic 2.x \u306a\u3069\u304c\u5fc5\u8981\u3067\u3059\u3002\u8a73\u7d30\u306f\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3082\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"README_ja/#agentpipeline","title":"\ud83c\udfd7\ufe0f AgentPipeline\u30af\u30e9\u30b9\u306e\u4f7f\u3044\u65b9","text":"<p><code>AgentPipeline</code> \u30af\u30e9\u30b9\u306f\u3001\u751f\u6210\u6307\u793a\u30fb\u8a55\u4fa1\u6307\u793a\u30fb\u30c4\u30fc\u30eb\u30fb\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u306a\u3069\u3092\u67d4\u8edf\u306b\u7d44\u307f\u5408\u308f\u305b\u3066\u3001LLM\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u7c21\u5358\u306b\u69cb\u7bc9\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"README_ja/#_4","title":"\u57fa\u672c\u69cb\u6210","text":"<pre><code>from agents_sdk_models import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"my_pipeline\",\n    generation_instructions=\"...\",  # \u751f\u6210\u6307\u793a\n    evaluation_instructions=None,    # \u8a55\u4fa1\u4e0d\u8981\u306a\u3089None\n    model=\"gpt-3.5-turbo\"\n)\nresult = pipeline.run(\"\u30e6\u30fc\u30b6\u30fc\u5165\u529b\")\n</code></pre>"},{"location":"README_ja/#_5","title":"\u751f\u6210\u7269\u306e\u81ea\u52d5\u8a55\u4fa1","text":"<pre><code>pipeline = AgentPipeline(\n    name=\"evaluated_generator\",\n    generation_instructions=\"...\",\n    evaluation_instructions=\"...\",  # \u8a55\u4fa1\u6307\u793a\n    model=\"gpt-3.5-turbo\",\n    threshold=70\n)\nresult = pipeline.run(\"\u8a55\u4fa1\u5bfe\u8c61\u306e\u5165\u529b\")\n</code></pre>"},{"location":"README_ja/#_6","title":"\u30c4\u30fc\u30eb\u9023\u643a","text":"<pre><code>from agents import function_tool\n\n@function_tool\ndef search_web(query: str) -&gt; str:\n    ...\n\npipeline = AgentPipeline(\n    name=\"tooled_generator\",\n    generation_instructions=\"...\",\n    evaluation_instructions=None,\n    model=\"gpt-3.5-turbo\",\n    generation_tools=[search_web]\n)\n</code></pre>"},{"location":"README_ja/#_7","title":"\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff08\u5165\u529b\u5236\u5fa1\uff09","text":"<pre><code>from agents import input_guardrail, GuardrailFunctionOutput, InputGuardrailTripwireTriggered\n\n@input_guardrail\nasync def math_guardrail(ctx, agent, input):\n    ...\n\npipeline = AgentPipeline(\n    name=\"guardrail_pipeline\",\n    generation_instructions=\"...\",\n    evaluation_instructions=None,\n    model=\"gpt-4o\",\n    input_guardrails=[math_guardrail]\n)\n\ntry:\n    result = pipeline.run(\"Can you help me solve for x: 2x + 3 = 11?\")\nexcept InputGuardrailTripwireTriggered:\n    print(\"[Guardrail Triggered] Math homework detected. Request blocked.\")\n</code></pre>"},{"location":"README_ja/#_8","title":"\u30ea\u30c8\u30e9\u30a4\u6642\u306e\u30b3\u30e1\u30f3\u30c8\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af","text":"<p><pre><code>from agents_sdk_models import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"comment_retry\",\n    generation_instructions=\"\u751f\u6210\u30d7\u30ed\u30f3\u30d7\u30c8\",\n    evaluation_instructions=\"\u8a55\u4fa1\u30d7\u30ed\u30f3\u30d7\u30c8\",\n    model=\"gpt-4o-mini\",\n    threshold=80,\n    retries=2,\n    retry_comment_importance=[\"serious\", \"normal\"]\n)\nresult = pipeline.run(\"\u5165\u529b\u30c6\u30ad\u30b9\u30c8\")\nprint(result)\n</code></pre> \u30ea\u30c8\u30e9\u30a4\u6642\u306b\u524d\u56de\u306e\u8a55\u4fa1\u30b3\u30e1\u30f3\u30c8\uff08\u6307\u5b9a\u3057\u305f\u91cd\u5927\u5ea6\u306e\u307f\uff09\u304c\u751f\u6210\u30d7\u30ed\u30f3\u30d7\u30c8\u306b\u81ea\u52d5\u3067\u4ed8\u4e0e\u3055\u308c\u3001\u6539\u5584\u3092\u4fc3\u3057\u307e\u3059\u3002</p>"},{"location":"README_ja/#flowv008","title":"\ud83d\ude80 \u65b0\u6a5f\u80fd\uff1a\u8d85\u30b7\u30f3\u30d7\u30ebFlow\uff08v0.0.8+\uff09","text":"<p>\u65b0\u3057\u3044Flow\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u30673\u3064\u306e\u65b9\u6cd5\u3067\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u4f5c\u6210\u3067\u304d\u307e\u3059\uff1a</p>"},{"location":"README_ja/#flow","title":"\u5358\u4e00\u30b9\u30c6\u30c3\u30d7Flow\uff08\u6700\u3082\u30b7\u30f3\u30d7\u30eb\uff01\uff09","text":"<pre><code>from agents_sdk_models import create_simple_gen_agent, Flow\n\ngen_agent = create_simple_gen_agent(\"assistant\", \"\u89aa\u5207\u306b\u56de\u7b54\u3057\u307e\u3059\", \"gpt-4o-mini\")\nflow = Flow(steps=gen_agent)  # \u305f\u3063\u305f1\u884c\uff01\nresult = await flow.run(input_data=\"\u3053\u3093\u306b\u3061\u306f\")\n</code></pre>"},{"location":"README_ja/#flow_1","title":"\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30ebFlow\uff08\u81ea\u52d5\u63a5\u7d9a\uff01\uff09","text":"<pre><code>from agents_sdk_models import create_simple_gen_agent, Flow\n\nidea_gen = create_simple_gen_agent(\"idea\", \"\u30a2\u30a4\u30c7\u30a2\u751f\u6210\", \"gpt-4o-mini\")\nwriter = create_simple_gen_agent(\"writer\", \"\u8a18\u4e8b\u57f7\u7b46\", \"gpt-4o\")\nreviewer = create_simple_gen_agent(\"reviewer\", \"\u30ec\u30d3\u30e5\u30fc\", \"claude-3-5-sonnet-latest\")\n\nflow = Flow(steps=[idea_gen, writer, reviewer])  # \u81ea\u52d5\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u5b9f\u884c\uff01\nresult = await flow.run(input_data=\"AI\u6280\u8853\u306b\u3064\u3044\u3066\")\n</code></pre>"},{"location":"README_ja/#_9","title":"\u5f93\u6765\u65b9\u5f0f\uff08\u8907\u96d1\u306a\u30d5\u30ed\u30fc\u7528\uff09","text":"<pre><code>flow = Flow(\n    start=\"step1\",\n    steps={\"step1\": step1, \"step2\": step2}\n)\n</code></pre> <p>\ud83d\udcda \u8a73\u7d30\u30ac\u30a4\u30c9\uff1a \u65b0\u3057\u3044Flow\u6a5f\u80fd\u5b8c\u5168\u30ac\u30a4\u30c9</p>"},{"location":"README_ja/#_10","title":"\ud83d\udcda \u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u65b0\u3057\u3044Flow\u6a5f\u80fd\u5b8c\u5168\u30ac\u30a4\u30c9 - v0.0.8\u3067\u8ffd\u52a0\u3055\u308c\u305f\u8d85\u30b7\u30f3\u30d7\u30eb\u306aFlow\u4f5c\u6210\u65b9\u6cd5</li> <li>\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8 - 3\u884c\u3067AI\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u69cb\u7bc9</li> <li>\u5fdc\u7528\u4f8b - \u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u5354\u8abf\u3068\u30c4\u30fc\u30eb\u9023\u643a</li> <li>Flow/Step API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 - \u8a73\u7d30\u306aAPI\u4ed5\u69d8</li> </ul>"},{"location":"agents/","title":"Agent \u30d1\u30bf\u30fc\u30f3\u4e00\u89a7","text":""},{"location":"agents/#_1","title":"\u6982\u8981","text":"<p>\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f\u3001Agents SDK Models\u3067\u5229\u7528\u53ef\u80fd\u306a\u3001\u307e\u305f\u306f\u5b9f\u88c5\u4e88\u5b9a\u306eAgent\u30d1\u30bf\u30fc\u30f3\u3092\u6574\u7406\u3057\u3066\u3044\u307e\u3059\u3002\u5404Agent\u306fStep\u30af\u30e9\u30b9\u3068\u3057\u3066\u5b9f\u88c5\u3055\u308c\u3001Flow\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u5185\u3067\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"agents/#_2","title":"\u5b9f\u88c5\u72b6\u6cc1","text":"<ul> <li>\u2705 \u5b9f\u88c5\u6e08\u307f</li> <li>\ud83d\udea7 \u90e8\u5206\u5b9f\u88c5</li> <li>\ud83d\udccb \u8a2d\u8a08\u6e08\u307f</li> <li>\ud83d\udca1 \u691c\u8a0e\u4e2d</li> </ul>"},{"location":"agents/#agent_1","title":"\u73fe\u5728\u5b9f\u88c5\u6e08\u307f\u306eAgent","text":""},{"location":"agents/#genagent","title":"GenAgent \u2705","text":"<p>\u76ee\u7684: LLM\u30d9\u30fc\u30b9\u306e\u751f\u6210\u3068\u8a55\u4fa1\u3092\u884c\u3046\u6c4e\u7528\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30c6\u30ad\u30b9\u30c8\u751f\u6210 - \u751f\u6210\u7d50\u679c\u306e\u8a55\u4fa1 - \u30ea\u30c8\u30e9\u30a4\u6a5f\u80fd - \u69cb\u9020\u5316\u51fa\u529b\u5bfe\u5fdc</p> <p>\u4f7f\u7528\u4f8b: - \u6587\u66f8\u4f5c\u6210 - \u30b3\u30fc\u30c9\u751f\u6210 - \u8981\u7d04\u4f5c\u6210</p>"},{"location":"agents/#clarifyagent","title":"ClarifyAgent \u2705","text":"<p>\u76ee\u7684: \u30e6\u30fc\u30b6\u30fc\u3068\u306e\u5bfe\u8a71\u3092\u901a\u3058\u3066\u8981\u4ef6\u3084\u60c5\u5831\u3092\u660e\u78ba\u5316</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u5bfe\u8a71\u7684\u8cea\u554f\u751f\u6210 - \u8981\u4ef6\u53ce\u96c6 - \u30bf\u30fc\u30f3\u7ba1\u7406 - \u5b8c\u4e86\u6761\u4ef6\u5224\u5b9a</p> <p>\u4f7f\u7528\u4f8b: - \u8981\u4ef6\u5b9a\u7fa9 - \u30e6\u30fc\u30b6\u30fc\u60c5\u5831\u53ce\u96c6 - \u8a2d\u5b9a\u30a6\u30a3\u30b6\u30fc\u30c9</p>"},{"location":"agents/#agent_2","title":"\u5178\u578b\u7684\u306aAgent\u30d1\u30bf\u30fc\u30f3\uff08\u30ab\u30c6\u30b4\u30ea\u5225\uff09","text":""},{"location":"agents/#1-processing-agents","title":"1. Processing Agents\uff08\u51e6\u7406\u7cfb\uff09","text":""},{"location":"agents/#transformeragent","title":"TransformerAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u30c7\u30fc\u30bf\u3092\u4e00\u3064\u306e\u5f62\u5f0f\u304b\u3089\u5225\u306e\u5f62\u5f0f\u306b\u5909\u63db</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u5909\u63db\uff08JSON \u2194 XML \u2194 YAML\uff09 - \u30c7\u30fc\u30bf\u6b63\u898f\u5316 - \u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u5909\u63db - \u30b9\u30ad\u30fc\u30de\u5909\u63db</p> <p>\u4f7f\u7528\u4f8b: <pre><code>transformer = TransformerAgent(\n    name=\"json_to_xml\",\n    transformation_type=\"json_to_xml\",\n    schema_mapping=mapping_rules\n)\n</code></pre></p>"},{"location":"agents/#extractoragent","title":"ExtractorAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u975e\u69cb\u9020\u5316\u30c7\u30fc\u30bf\u304b\u3089\u7279\u5b9a\u306e\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3001\u69cb\u9020\u5316\u3055\u308c\u305f\u30c7\u30fc\u30bf\u3068\u3057\u3066\u51fa\u529b</p> <p>\u8cac\u52d9\u306e\u660e\u78ba\u5316: - \u5165\u529b: \u30c6\u30ad\u30b9\u30c8\u3001HTML\u3001PDF\u3001\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u306a\u3069\u306e\u975e\u69cb\u9020\u5316\u30c7\u30fc\u30bf - \u51e6\u7406: \u4e8b\u524d\u5b9a\u7fa9\u3055\u308c\u305f\u30d1\u30bf\u30fc\u30f3\u3084\u30eb\u30fc\u30eb\u306b\u57fa\u3065\u304f\u60c5\u5831\u62bd\u51fa - \u51fa\u529b: \u69cb\u9020\u5316\u3055\u308c\u305f\u30c7\u30fc\u30bf\uff08\u8f9e\u66f8\u3001\u30ea\u30b9\u30c8\u3001Pydantic\u30e2\u30c7\u30eb\uff09</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30d1\u30bf\u30fc\u30f3\u30d9\u30fc\u30b9\u62bd\u51fa: \u6b63\u898f\u8868\u73fe\u3001XPath\u3001CSS\u30bb\u30ec\u30af\u30bf\u30fc - LLM\u30d9\u30fc\u30b9\u62bd\u51fa: \u81ea\u7136\u8a00\u8a9e\u306b\u3088\u308b\u62bd\u51fa\u6307\u793a\u3068\u30b9\u30ad\u30fc\u30de\u5b9a\u7fa9 - \u30de\u30eb\u30c1\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u5bfe\u5fdc: \u30c6\u30ad\u30b9\u30c8\u3001HTML\u3001JSON\u3001XML\u3001CSV\u5bfe\u5fdc - \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3: \u62bd\u51fa\u7d50\u679c\u306e\u691c\u8a3c\u3068\u54c1\u8cea\u30c1\u30a7\u30c3\u30af - \u8907\u6570\u62bd\u51fa: \u4e00\u3064\u306e\u5165\u529b\u304b\u3089\u8907\u6570\u306e\u60c5\u5831\u3092\u540c\u6642\u62bd\u51fa - \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0: \u62bd\u51fa\u5931\u6557\u6642\u306e\u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af\u51e6\u7406</p> <p>\u4ed6Agent\u3068\u306e\u5f79\u5272\u5206\u62c5: - vs ClassifierAgent: \u5206\u985e\u3067\u306f\u306a\u304f\u5177\u4f53\u7684\u306a\u30c7\u30fc\u30bf\u5024\u3092\u62bd\u51fa - vs TransformerAgent: \u5f62\u5f0f\u5909\u63db\u3067\u306f\u306a\u304f\u60c5\u5831\u306e\u53d6\u308a\u51fa\u3057 - vs ValidatorAgent: \u691c\u8a3c\u3067\u306f\u306a\u304f\u62bd\u51fa\u304c\u4e3b\u76ee\u7684</p> <p>\u5177\u4f53\u7684\u306a\u62bd\u51fa\u30d1\u30bf\u30fc\u30f3: <pre><code># \u69cb\u9020\u5316\u3055\u308c\u305f\u30c7\u30fc\u30bf\u62bd\u51fa\u4f8b\nextractor = ExtractorAgent(\n    name=\"contact_extractor\",\n    extraction_rules=[\n        EmailRule(pattern=r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'),\n        PhoneRule(pattern=r'\\b\\d{3}-\\d{3}-\\d{4}\\b'),\n        NameRule(llm_prompt=\"Extract person names from the text\"),\n        DateRule(formats=['%Y-%m-%d', '%m/%d/%Y'])\n    ],\n    output_schema=ContactInfo  # Pydantic\u30e2\u30c7\u30eb\n)\n</code></pre></p> <p>\u4f7f\u7528\u4f8b: - \u6587\u66f8\u304b\u3089\u30e1\u30bf\u30c7\u30fc\u30bf\u62bd\u51fa: PDF\u5951\u7d04\u66f8\u304b\u3089\u5951\u7d04\u8005\u540d\u3001\u671f\u9593\u3001\u91d1\u984d - \u30e1\u30fc\u30eb\u304b\u3089\u69cb\u9020\u5316\u60c5\u5831\u62bd\u51fa: \u554f\u3044\u5408\u308f\u305b\u30e1\u30fc\u30eb\u304b\u3089\u9867\u5ba2\u60c5\u5831\u3001\u8981\u4ef6 - \u30ed\u30b0\u304b\u3089\u8a3a\u65ad\u60c5\u5831\u62bd\u51fa: \u30a8\u30e9\u30fc\u30ed\u30b0\u304b\u3089\u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u3001\u30a8\u30e9\u30fc\u30b3\u30fc\u30c9\u3001\u8a73\u7d30 - Web\u30da\u30fc\u30b8\u304b\u3089\u5546\u54c1\u60c5\u5831\u62bd\u51fa: EC\u30b5\u30a4\u30c8\u304b\u3089\u4fa1\u683c\u3001\u4ed5\u69d8\u3001\u5728\u5eab\u72b6\u6cc1 - \u5e33\u7968\u304b\u3089\u30c7\u30fc\u30bf\u62bd\u51fa: \u8acb\u6c42\u66f8\u304b\u3089\u91d1\u984d\u3001\u9805\u76ee\u3001\u652f\u6255\u3044\u671f\u9650</p>"},{"location":"agents/#validatoragent","title":"ValidatorAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u30c7\u30fc\u30bf\u3084\u6761\u4ef6\u306e\u691c\u8a3c\u3092\u884c\u3046</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u5165\u529b\u30c7\u30fc\u30bf\u691c\u8a3c - \u30d3\u30b8\u30cd\u30b9\u30eb\u30fc\u30eb\u9069\u7528 - \u30b9\u30ad\u30fc\u30de\u691c\u8a3c - \u30ab\u30b9\u30bf\u30e0\u691c\u8a3c\u30eb\u30fc\u30eb</p> <p>\u4f7f\u7528\u4f8b: <pre><code>validator = ValidatorAgent(\n    name=\"email_validator\",\n    validation_rules=[\n        EmailFormatRule(),\n        DomainWhitelistRule(allowed_domains)\n    ]\n)\n</code></pre></p>"},{"location":"agents/#aggregatoragent","title":"AggregatorAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u8907\u6570\u306e\u30bd\u30fc\u30b9\u304b\u3089\u30c7\u30fc\u30bf\u3092\u96c6\u7d04\u30fb\u7d71\u5408</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30c7\u30fc\u30bf\u7d50\u5408 - \u91cd\u8907\u6392\u9664 - \u7d71\u8a08\u8a08\u7b97 - \u30ec\u30dd\u30fc\u30c8\u751f\u6210</p> <p>\u4f7f\u7528\u4f8b: - \u8907\u6570API\u7d50\u679c\u7d71\u5408 - \u30c7\u30fc\u30bf\u5206\u6790\u30ec\u30dd\u30fc\u30c8 - \u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u751f\u6210</p>"},{"location":"agents/#2-decision-agents","title":"2. Decision Agents\uff08\u5224\u65ad\u7cfb\uff09","text":""},{"location":"agents/#routeragent","title":"RouterAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u5165\u529b\u3092\u5206\u6790\u3057\u3066\u9069\u5207\u306a\u51e6\u7406\u30d1\u30b9\u306b\u632f\u308a\u5206\u3051</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u610f\u56f3\u691c\u51fa - \u5206\u985e\u30d9\u30fc\u30b9\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0 - \u6761\u4ef6\u30d9\u30fc\u30b9\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0 - \u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af\u51e6\u7406</p> <p>\u4f7f\u7528\u4f8b: <pre><code>router = RouterAgent(\n    name=\"intent_router\",\n    routes={\n        \"question\": \"qa_flow\",\n        \"complaint\": \"support_flow\",\n        \"request\": \"service_flow\"\n    },\n    classifier=IntentClassifier()\n)\n</code></pre></p>"},{"location":"agents/#classifieragent","title":"ClassifierAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u5165\u529b\u3092\u4e8b\u524d\u5b9a\u7fa9\u3055\u308c\u305f\u30ab\u30c6\u30b4\u30ea\u306b\u5206\u985e</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30c6\u30ad\u30b9\u30c8\u5206\u985e - \u611f\u60c5\u5206\u6790 - \u512a\u5148\u5ea6\u5224\u5b9a - \u8a00\u8a9e\u691c\u51fa</p> <p>\u4f7f\u7528\u4f8b: - \u30b5\u30dd\u30fc\u30c8\u30c1\u30b1\u30c3\u30c8\u5206\u985e - \u611f\u60c5\u5206\u6790 - \u30b9\u30d1\u30e0\u691c\u51fa</p>"},{"location":"agents/#decisionagent","title":"DecisionAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u8907\u6570\u306e\u57fa\u6e96\u306b\u57fa\u3065\u3044\u3066\u8907\u96d1\u306a\u5224\u65ad\u3092\u5b9f\u884c</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u591a\u57fa\u6e96\u8a55\u4fa1 - \u91cd\u307f\u4ed8\u3051\u5224\u5b9a - \u30ea\u30b9\u30af\u8a55\u4fa1 - \u627f\u8a8d/\u5374\u4e0b\u5224\u5b9a</p> <p>\u4f7f\u7528\u4f8b: <pre><code>decision = DecisionAgent(\n    name=\"loan_approval\",\n    criteria=[\n        CreditScoreCriteria(weight=0.4),\n        IncomeCriteria(weight=0.3),\n        HistoryCriteria(weight=0.3)\n    ],\n    threshold=0.7\n)\n</code></pre></p>"},{"location":"agents/#prioritizeragent","title":"PrioritizerAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u30bf\u30b9\u30af\u3084\u30a2\u30a4\u30c6\u30e0\u306b\u512a\u5148\u5ea6\u3092\u4ed8\u3051\u3066\u4e26\u3073\u66ff\u3048</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u512a\u5148\u5ea6\u30b9\u30b3\u30a2\u8a08\u7b97 - \u8907\u6570\u57fa\u6e96\u3067\u306e\u4e26\u3073\u66ff\u3048 - \u52d5\u7684\u512a\u5148\u5ea6\u8abf\u6574</p> <p>\u4f7f\u7528\u4f8b: - \u30bf\u30b9\u30af\u7ba1\u7406 - \u30b5\u30dd\u30fc\u30c8\u30c1\u30b1\u30c3\u30c8\u512a\u5148\u5ea6\u4ed8\u3051 - \u30ea\u30bd\u30fc\u30b9\u914d\u5206</p>"},{"location":"agents/#3-communication-agents","title":"3. Communication Agents\uff08\u5bfe\u8a71\u7cfb\uff09","text":""},{"location":"agents/#notificationagent","title":"NotificationAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u5404\u7a2e\u30c1\u30e3\u30cd\u30eb\u3092\u901a\u3058\u3066\u901a\u77e5\u3092\u9001\u4fe1</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30e1\u30fc\u30eb\u9001\u4fe1 - Slack/Teams\u901a\u77e5 - SMS\u9001\u4fe1 - Webhook\u547c\u3073\u51fa\u3057</p> <p>\u4f7f\u7528\u4f8b: <pre><code>notifier = NotificationAgent(\n    name=\"error_notifier\",\n    channels=[\n        EmailChannel(recipients=admin_emails),\n        SlackChannel(webhook_url=slack_webhook)\n    ]\n)\n</code></pre></p>"},{"location":"agents/#chatbotagent","title":"ChatbotAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u5bfe\u8a71\u578b\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306e\u63d0\u4f9b</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u81ea\u7136\u8a00\u8a9e\u7406\u89e3 - \u5bfe\u8a71\u7ba1\u7406 - \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u4fdd\u6301 - \u5fdc\u7b54\u751f\u6210</p> <p>\u4f7f\u7528\u4f8b: - \u30ab\u30b9\u30bf\u30de\u30fc\u30b5\u30dd\u30fc\u30c8 - FAQ\u5bfe\u5fdc - \u60c5\u5831\u691c\u7d22</p>"},{"location":"agents/#interviewagent","title":"InterviewAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u69cb\u9020\u5316\u3055\u308c\u305f\u30a4\u30f3\u30bf\u30d3\u30e5\u30fc\u3084\u8cea\u554f\u7968\u3092\u5b9f\u884c</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u52d5\u7684\u8cea\u554f\u751f\u6210 - \u56de\u7b54\u691c\u8a3c - \u6761\u4ef6\u5206\u5c90 - \u7d50\u679c\u96c6\u7d04</p> <p>\u4f7f\u7528\u4f8b: - \u9867\u5ba2\u8abf\u67fb - \u8a3a\u65ad\u8cea\u554f - \u8a2d\u5b9a\u53ce\u96c6</p>"},{"location":"agents/#4-data-agents","title":"4. Data Agents\uff08\u30c7\u30fc\u30bf\u7cfb\uff09","text":""},{"location":"agents/#collectoragent","title":"CollectorAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u8907\u6570\u306e\u30bd\u30fc\u30b9\u304b\u3089\u30c7\u30fc\u30bf\u3092\u53ce\u96c6</p> <p>\u4e3b\u306a\u6a5f\u80fd: - API\u547c\u3073\u51fa\u3057 - \u30d5\u30a1\u30a4\u30eb\u8aad\u307f\u8fbc\u307f - \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u63a5\u7d9a - Web\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0</p> <p>\u4f7f\u7528\u4f8b: <pre><code>collector = CollectorAgent(\n    name=\"weather_collector\",\n    sources=[\n        APISource(url=\"weather.api.com\"),\n        DatabaseSource(query=\"SELECT * FROM weather\")\n    ]\n)\n</code></pre></p>"},{"location":"agents/#cacheagent","title":"CacheAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u30c7\u30fc\u30bf\u306e\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3068\u9ad8\u901f\u30a2\u30af\u30bb\u30b9</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30e1\u30e2\u30ea\u30ad\u30e3\u30c3\u30b7\u30e5 - \u6c38\u7d9a\u5316\u30ad\u30e3\u30c3\u30b7\u30e5 - TTL\u7ba1\u7406 - \u30ad\u30e3\u30c3\u30b7\u30e5\u6226\u7565</p> <p>\u4f7f\u7528\u4f8b: - API\u5fdc\u7b54\u30ad\u30e3\u30c3\u30b7\u30e5 - \u8a08\u7b97\u7d50\u679c\u4fdd\u5b58 - \u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406</p>"},{"location":"agents/#searchagent","title":"SearchAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u60c5\u5831\u691c\u7d22\u3068\u95a2\u9023\u30c7\u30fc\u30bf\u306e\u53d6\u5f97</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30c6\u30ad\u30b9\u30c8\u691c\u7d22 - \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22 - \u30d9\u30af\u30c8\u30eb\u691c\u7d22 - \u30cf\u30a4\u30d6\u30ea\u30c3\u30c9\u691c\u7d22</p> <p>\u4f7f\u7528\u4f8b: - \u6587\u66f8\u691c\u7d22 - FAQ\u691c\u7d22 - \u985e\u4f3c\u30c7\u30fc\u30bf\u767a\u898b</p>"},{"location":"agents/#5-control-agents","title":"5. Control Agents\uff08\u5236\u5fa1\u7cfb\uff09","text":""},{"location":"agents/#orchestratoragent","title":"OrchestratorAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u8907\u6570\u306eAgent\u3084\u30bf\u30b9\u30af\u306e\u5354\u8abf\u5b9f\u884c</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30bf\u30b9\u30af\u8abf\u6574 - \u5b9f\u884c\u9806\u5e8f\u5236\u5fa1 - \u4f9d\u5b58\u95a2\u4fc2\u7ba1\u7406 - \u30a8\u30e9\u30fc\u51e6\u7406</p> <p>\u4f7f\u7528\u4f8b: <pre><code>orchestrator = OrchestratorAgent(\n    name=\"data_pipeline\",\n    tasks=[\n        (\"collect\", CollectorAgent()),\n        (\"validate\", ValidatorAgent()),\n        (\"transform\", TransformerAgent()),\n        (\"store\", StorageAgent())\n    ]\n)\n</code></pre></p>"},{"location":"agents/#monitoragent","title":"MonitorAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u30b7\u30b9\u30c6\u30e0\u3084\u30d7\u30ed\u30bb\u30b9\u306e\u76e3\u8996</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af - \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u76e3\u8996 - \u30a2\u30e9\u30fc\u30c8\u751f\u6210 - \u30ed\u30b0\u5206\u6790</p> <p>\u4f7f\u7528\u4f8b: - \u30b7\u30b9\u30c6\u30e0\u76e3\u8996 - API\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af - \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u8ffd\u8de1</p>"},{"location":"agents/#scheduleragent","title":"SchedulerAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u30bf\u30b9\u30af\u306e\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u3068\u6642\u9593\u7ba1\u7406</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u5b9a\u671f\u5b9f\u884c - \u9045\u5ef6\u5b9f\u884c - \u6761\u4ef6\u30c8\u30ea\u30ac\u30fc - \u4f9d\u5b58\u95a2\u4fc2\u8003\u616e</p> <p>\u4f7f\u7528\u4f8b: - \u30d0\u30c3\u30c1\u51e6\u7406 - \u5b9a\u671f\u30ec\u30dd\u30fc\u30c8 - \u30ea\u30de\u30a4\u30f3\u30c0\u30fc</p>"},{"location":"agents/#6-security-agents","title":"6. Security Agents\uff08\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u7cfb\uff09","text":""},{"location":"agents/#authagent","title":"AuthAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u8a8d\u8a3c\u3068\u8a8d\u53ef\u306e\u7ba1\u7406</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u30e6\u30fc\u30b6\u30fc\u8a8d\u8a3c - \u30c8\u30fc\u30af\u30f3\u7ba1\u7406 - \u6a29\u9650\u30c1\u30a7\u30c3\u30af - \u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406</p> <p>\u4f7f\u7528\u4f8b: - API\u8a8d\u8a3c - \u30e6\u30fc\u30b6\u30fc\u30ed\u30b0\u30a4\u30f3 - \u6a29\u9650\u78ba\u8a8d</p>"},{"location":"agents/#auditagent","title":"AuditAgent \ud83d\udca1","text":"<p>\u76ee\u7684: \u64cd\u4f5c\u30ed\u30b0\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u76e3\u67fb</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \u64cd\u4f5c\u30ed\u30b0\u8a18\u9332 - \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30a4\u30d9\u30f3\u30c8\u691c\u51fa - \u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u78ba\u8a8d - \u30ec\u30dd\u30fc\u30c8\u751f\u6210</p> <p>\u4f7f\u7528\u4f8b: - \u64cd\u4f5c\u5c65\u6b74\u8ffd\u8de1 - \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u76e3\u67fb - \u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u78ba\u8a8d</p>"},{"location":"agents/#_3","title":"\u5b9f\u88c5\u512a\u5148\u5ea6","text":""},{"location":"agents/#_4","title":"\u9ad8\u512a\u5148\u5ea6\uff08\u6b21\u671f\u30ea\u30ea\u30fc\u30b9\u5019\u88dc\uff09","text":"<ol> <li>RouterAgent - \u6700\u3082\u6c4e\u7528\u7684\u3067\u591a\u304f\u306e\u5834\u9762\u3067\u5fc5\u8981</li> <li>ValidatorAgent - \u30c7\u30fc\u30bf\u54c1\u8cea\u78ba\u4fdd\u306b\u5fc5\u9808</li> <li>ExtractorAgent - \u60c5\u5831\u51e6\u7406\u306e\u57fa\u672c\u6a5f\u80fd</li> <li>NotificationAgent - \u30a2\u30e9\u30fc\u30c8\u3084\u30ec\u30dd\u30fc\u30c8\u914d\u4fe1\u306b\u5fc5\u8981</li> </ol>"},{"location":"agents/#_5","title":"\u4e2d\u512a\u5148\u5ea6\uff08\u5c06\u6765\u7248\u3067\u306e\u5b9f\u88c5\uff09","text":"<ol> <li>ClassifierAgent - \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u3068\u7d44\u307f\u5408\u308f\u305b\u3066\u5f37\u529b</li> <li>TransformerAgent - \u30c7\u30fc\u30bf\u5909\u63db\u306e\u6c4e\u7528\u6027</li> <li>AggregatorAgent - \u30ec\u30dd\u30fc\u30c8\u30fb\u5206\u6790\u6a5f\u80fd</li> <li>SearchAgent - \u60c5\u5831\u691c\u7d22\u6a5f\u80fd</li> </ol>"},{"location":"agents/#_6","title":"\u4f4e\u512a\u5148\u5ea6\uff08\u9577\u671f\u7684\u306a\u62e1\u5f35\uff09","text":"<ol> <li>OrchestratorAgent - \u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u5236\u5fa1</li> <li>MonitorAgent - \u904b\u7528\u76e3\u8996\u6a5f\u80fd</li> <li>AuthAgent - \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5f37\u5316</li> <li>SchedulerAgent - \u9ad8\u5ea6\u306a\u30bf\u30b9\u30af\u7ba1\u7406</li> </ol>"},{"location":"agents/#_7","title":"\u8a2d\u8a08\u539f\u5247","text":""},{"location":"agents/#1-step","title":"1. Step\u30af\u30e9\u30b9\u30d9\u30fc\u30b9","text":"<p>\u5168\u3066\u306eAgent\u306f<code>Step</code>\u30af\u30e9\u30b9\u3092\u7d99\u627f\u3057\u3001Flow\u5185\u3067\u7d71\u4e00\u7684\u306b\u4f7f\u7528\u53ef\u80fd</p>"},{"location":"agents/#2","title":"2. \u8a2d\u5b9a\u99c6\u52d5","text":"<p>\u5404Agent\u306fPydantic\u30e2\u30c7\u30eb\u3067\u8a2d\u5b9a\u3092\u7ba1\u7406\u3057\u3001\u578b\u5b89\u5168\u6027\u3092\u78ba\u4fdd</p>"},{"location":"agents/#3-llmpipeline","title":"3. LLMPipeline\u7d71\u5408","text":"<p>LLM\u3092\u4f7f\u7528\u3059\u308bAgent\u306f<code>LLMPipeline</code>\u307e\u305f\u306f<code>InteractivePipeline</code>\u3092\u6d3b\u7528</p>"},{"location":"agents/#4","title":"4. \u30c4\u30fc\u30eb\u7d71\u5408","text":"<p>OpenAI Function Calling\u3084MCP\u30b5\u30fc\u30d0\u30fc\u3068\u306e\u7d71\u5408\u3092\u30b5\u30dd\u30fc\u30c8</p>"},{"location":"agents/#5","title":"5. \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0","text":"<p>\u9069\u5207\u306a\u30a8\u30e9\u30fc\u51e6\u7406\u3068\u30ea\u30c8\u30e9\u30a4\u6a5f\u80fd\u3092\u6a19\u6e96\u88c5\u5099</p>"},{"location":"agents/#_8","title":"\u4f7f\u7528\u30d1\u30bf\u30fc\u30f3\u4f8b","text":""},{"location":"agents/#1","title":"1. \u30ab\u30b9\u30bf\u30de\u30fc\u30b5\u30dd\u30fc\u30c8\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":"<pre><code>flow = Flow([\n    RouterAgent(name=\"intent_router\"),  # \u554f\u3044\u5408\u308f\u305b\u5206\u985e\n    ClarifyAgent(name=\"detail_collector\"),  # \u8a73\u7d30\u805e\u304d\u53d6\u308a\n    ValidatorAgent(name=\"info_validator\"),  # \u60c5\u5831\u691c\u8a3c\n    NotificationAgent(name=\"ticket_creator\")  # \u30c1\u30b1\u30c3\u30c8\u4f5c\u6210\u901a\u77e5\n])\n</code></pre>"},{"location":"agents/#2_1","title":"2. \u30c7\u30fc\u30bf\u51e6\u7406\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3","text":"<pre><code>flow = Flow([\n    CollectorAgent(name=\"data_collector\"),  # \u30c7\u30fc\u30bf\u53ce\u96c6\n    ValidatorAgent(name=\"data_validator\"),  # \u30c7\u30fc\u30bf\u691c\u8a3c\n    TransformerAgent(name=\"data_transformer\"),  # \u30c7\u30fc\u30bf\u5909\u63db\n    AggregatorAgent(name=\"report_generator\")  # \u30ec\u30dd\u30fc\u30c8\u751f\u6210\n])\n</code></pre>"},{"location":"agents/#3","title":"3. \u627f\u8a8d\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":"<pre><code>flow = Flow([\n    ExtractorAgent(name=\"request_extractor\"),  # \u7533\u8acb\u5185\u5bb9\u62bd\u51fa\n    ClassifierAgent(name=\"urgency_classifier\"),  # \u7dca\u6025\u5ea6\u5206\u985e\n    DecisionAgent(name=\"auto_approver\"),  # \u81ea\u52d5\u627f\u8a8d\u5224\u5b9a\n    NotificationAgent(name=\"result_notifier\")  # \u7d50\u679c\u901a\u77e5\n])\n</code></pre>"},{"location":"agents/#_9","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ol> <li>RouterAgent\u306e\u8a73\u7d30\u8a2d\u8a08\u3068\u5b9f\u88c5</li> <li>\u5404Agent\u306e\u5171\u901a\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u5b9a\u7fa9</li> <li>Agent\u9593\u306e\u9023\u643a\u30d1\u30bf\u30fc\u30f3\u306e\u6a19\u6e96\u5316</li> <li>\u5305\u62ec\u7684\u306a\u30c6\u30b9\u30c8\u30b9\u30a4\u30fc\u30c8\u4f5c\u6210</li> <li>\u4f7f\u7528\u4f8b\u3068\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u5145\u5b9f </li> </ol>"},{"location":"analysis_of_library/","title":"Agents SDK Models: \u6bd4\u8f03\u5206\u6790\u3068\u5c06\u6765\u5c55\u671b","text":""},{"location":"analysis_of_library/#1-langchainlanggraph","title":"1. LangChain\u3084LangGraph\u306a\u3069\u306e\u4ed6\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e\u6bd4\u8f03\u306b\u3088\u308b\u5dee\u5225\u5316","text":"<p>\u4f4e\u3044\u5b66\u7fd2\u30b3\u30b9\u30c8\u3068\u30b7\u30f3\u30d7\u30eb\u3055: Agents SDK Models\u30e9\u30a4\u30d6\u30e9\u30ea\uff08OpenAI\u306eAgents SDK\u4e0a\u306b\u69cb\u7bc9\uff09\u306f\u3001\u6700\u5c0f\u9650\u306e\u62bd\u8c61\u5316\u3092\u91cd\u8996\u3057\u3066\u304a\u308a\u3001\u958b\u767a\u8005\u306b\u3068\u3063\u3066\u975e\u5e38\u306b\u89aa\u3057\u307f\u3084\u3059\u3044\u8a2d\u8a08\u3067\u3059\u3002LangChain\u306e\u5e83\u7bc4\u306a\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3084LangGraph\u306e\u8907\u96d1\u306a\u30b0\u30e9\u30d5\u8a2d\u5b9a\u3068\u306f\u5bfe\u7167\u7684\u306b\u3001Agents SDK\u306f\u8efd\u91cf\u306aAPI\u8a2d\u8a08\u3092\u63a1\u3063\u3066\u3044\u307e\u3059\u3002\u305d\u306e\u305f\u3081\u3001ML\u30a8\u30f3\u30b8\u30cb\u30a2\u306f\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3068\u30c4\u30fc\u30eb\u3092\u6570\u884c\u306e\u30b3\u30fc\u30c9\u3067\u5b9a\u7fa9\u3059\u308b\u3060\u3051\u3067\u5229\u7528\u3092\u958b\u59cb\u3067\u304d\u307e\u3059\u3002LangGraph\u3067\u306f\u8907\u96d1\u306a\u72b6\u614b\u69cb\u6210\u3084\u30ce\u30fc\u30c9\u8a2d\u8a08\u304c\u6c42\u3081\u3089\u308c\u307e\u3059\u304c\u3001\u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u306f\u3001get_llm\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3068AgentPipeline\u306b\u3088\u308a\u3001\u72b6\u614b\u9077\u79fb\u306e\u7ba1\u7406\u3092\u610f\u8b58\u305b\u305a\u306b\u6e08\u3080\u70b9\u304c\u5dee\u5225\u5316\u8981\u7d20\u3067\u3059\u3002</p> <p>\u3053\u306e\u30b7\u30f3\u30d7\u30eb\u3055\u3092\u3055\u3089\u306b\u5f37\u5316\u3059\u308b\u306b\u306f\u3001\u5178\u578b\u7684\u306a\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8a2d\u8a08\u30d1\u30bf\u30fc\u30f3\u306e\u30af\u30c3\u30af\u30d6\u30c3\u30af\u7684\u306a\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u96c6\u3084\u3001LangChain\u306b\u3042\u308b\u4e00\u822c\u7684\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\uff08Q\\&amp;A\u30dc\u30c3\u30c8\u3001\u30c7\u30fc\u30bf\u62bd\u51fa\u306a\u3069\uff09\u306b\u5bfe\u5fdc\u3057\u305f\u7c21\u6f54\u306a\u4f8b\u3092\u7528\u610f\u3059\u308b\u3053\u3068\u3067\u3001\u521d\u5b66\u8005\u306e\u5c0e\u5165\u969c\u58c1\u3092\u3055\u3089\u306b\u4e0b\u3052\u3089\u308c\u307e\u3059\u3002</p> <p>\u6700\u5c0f\u9650\u306e\u4f9d\u5b58\u95a2\u4fc2\u3068\u8efd\u91cf\u8a2d\u8a08: \u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30b3\u30a2\u4f9d\u5b58\u306fOpenAI Python API\u304a\u3088\u3073Agents SDK\u306e\u307f\u3067\u3042\u308a\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066Pydantic\u3092\u4f7f\u7528\u3059\u308b\u8a2d\u8a08\u3067\u3059\u3002LangChain\u3067\u306f\u6570\u591a\u304f\u306e\u4f9d\u5b58\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5c0e\u5165\u3059\u308b\u305f\u3081\u3001\u4f9d\u5b58\u95a2\u4fc2\u306e\u885d\u7a81\u3084\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u554f\u984c\u304c\u8d77\u304d\u3084\u3059\u3044\u3067\u3059\u304c\u3001Agents SDK Models\u306f\u305d\u308c\u3092\u907f\u3051\u3001\u5fc5\u8981\u306a\u6a5f\u80fd\u306b\u5fdc\u3058\u305f\u8ffd\u52a0\u3092extras\u3067\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>\u5c06\u6765\u7684\u306a\u6a5f\u80fd\u62e1\u5f35\u306b\u304a\u3044\u3066\u3082\u3053\u306e\u8a2d\u8a08\u601d\u60f3\u3092\u7dad\u6301\u3059\u308b\u306b\u306f\u3001\u65b0\u6a5f\u80fd\u3092\u30d7\u30e9\u30b0\u30a4\u30f3\u30e2\u30b8\u30e5\u30fc\u30eb\u3068\u3057\u3066\u5206\u96e2\u3057\u3001\u30b3\u30a2\u306f\u8efd\u91cf\u306a\u307e\u307e\u4fdd\u3061\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u5c0e\u5165\u53ef\u80fd\u3068\u3059\u308b\u8a2d\u8a08\u304c\u671b\u307e\u3057\u3044\u3067\u3057\u3087\u3046\u3002</p> <p>\u751f\u6210\u54c1\u8cea\u306e\u4fdd\u8a3c: \u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u6700\u5927\u306e\u5dee\u5225\u5316\u8981\u7d20\u306e\u4e00\u3064\u304c\u3001\u751f\u6210\u54c1\u8cea\u306e\u8a55\u4fa1\u30fb\u4fdd\u8a3c\u3092\u7d44\u307f\u8fbc\u307f\u3067\u63d0\u4f9b\u3057\u3066\u3044\u308b\u3053\u3068\u3067\u3059\u3002get_llm\u3067\u5f97\u3089\u308c\u308bLLM\u306f\u3001Pydantic\u30e2\u30c7\u30eb\u306b\u3088\u308a\u69cb\u9020\u5316\u51fa\u529b\u3092\u30d0\u30ea\u30c7\u30fc\u30c8\u3067\u304d\u307e\u3059\u3002\u307e\u305f\u3001\u5165\u529b\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3084\u51fa\u529b\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3092\u901a\u3058\u3066\u3001\u502b\u7406\u7684\u306a\u5224\u65ad\u3084\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u691c\u8a3c\u306a\u3069\u3082\u7c21\u5358\u306b\u9069\u7528\u3067\u304d\u307e\u3059\u3002LangChain\u306a\u3069\u3067\u306f\u3053\u308c\u3089\u3092\u81ea\u524d\u3067\u69cb\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u306f\u8a2d\u5b9a\u9805\u76ee\u3067\u6307\u5b9a\u3059\u308b\u3060\u3051\u3067\u8a55\u4fa1\u30fb\u518d\u751f\u6210\u3092\u542b\u3080\u30eb\u30fc\u30d7\u51e6\u7406\u307e\u3067\u81ea\u52d5\u3067\u884c\u3048\u307e\u3059\u3002</p> <p>\u3053\u308c\u3092\u3055\u3089\u306b\u5f37\u5316\u3059\u308b\u306b\u306f\u3001\u8a55\u4fa1\u30d7\u30ed\u30f3\u30d7\u30c8\u3084\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u306e\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u5316\u3001\u5185\u5bb9\u5909\u63db\u578b\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff08\u4f8b\uff1a\u6a5f\u5bc6\u60c5\u5831\u3092\u81ea\u52d5\u3067\u30de\u30b9\u30ad\u30f3\u30b0\uff09\u306a\u3069\u306e\u62e1\u5f35\u304c\u6319\u3052\u3089\u308c\u307e\u3059\u3002</p> <p>\u6539\u5584\u30dd\u30a4\u30f3\u30c8\u306e\u8981\u7d04:</p> <ul> <li>\u30b7\u30f3\u30d7\u30eb\u306a\u5c0e\u5165\u652f\u63f4: \u3088\u304f\u3042\u308b\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306b\u5373\u3057\u305f\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3068\u30b3\u30fc\u30c9\u4f8b\u3092\u63d0\u4f9b</li> <li>\u6a5f\u80fd\u306e\u5206\u96e2\u3068\u8efd\u91cf\u6027\u7dad\u6301: \u30d7\u30e9\u30b0\u30a4\u30f3\u69cb\u9020\u306b\u3088\u308a\u5c0e\u5165\u81ea\u7531\u5ea6\u3092\u78ba\u4fdd</li> <li>\u51fa\u529b\u8a55\u4fa1\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u306e\u6a19\u6e96\u5316: \u3088\u304f\u4f7f\u308f\u308c\u308b\u8a55\u4fa1\u6307\u6a19\uff08\u6b63\u78ba\u6027\u3001\u7c21\u6f54\u3055\u306a\u3069\uff09\u3092\u30c7\u30d5\u30a9\u30eb\u30c8\u63d0\u4f9b</li> <li>\u5b89\u5b9a\u6027\u3068\u30d0\u30fc\u30b8\u30e7\u30cb\u30f3\u30b0: \u983b\u7e41\u306a\u4ed5\u69d8\u5909\u66f4\u3092\u907f\u3051\u3001\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30cb\u30f3\u30b0\u3092\u5c0e\u5165</li> </ul>"},{"location":"analysis_of_library/#2-agentpipelinedag","title":"2. AgentPipeline\u306e\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u8a2d\u8a08\u3068DAG\u69cb\u6210\u306e\u6709\u52b9\u6027","text":"<p>AgentPipeline\u306f\u3001\u751f\u6210\u3001\u8a55\u4fa1\u3001\u30c4\u30fc\u30eb\u5b9f\u884c\u3001\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u306a\u3069\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u4e00\u8cab\u3057\u305f\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3068\u3057\u3066\u7d71\u5408\u3059\u308b\u305f\u3081\u306e\u8efd\u91cf\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u30a8\u30f3\u30b8\u30f3\u3067\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001LLM\u547c\u3073\u51fa\u3057\u2192\u51fa\u529b\u8a55\u4fa1\u2192\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u2192\u518d\u751f\u6210\u3068\u3044\u3063\u305f\u4e00\u9023\u306e\u51e6\u7406\u3092\u4e00\u3064\u306e\u95a2\u6570\u547c\u3073\u51fa\u3057\u306b\u307e\u3068\u3081\u308b\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002</p> <p>LangChain\u306e\u3088\u3046\u306a\u30c1\u30a7\u30fc\u30f3\u9023\u643a\u3084LangGraph\u306e\u72b6\u614b\u6a5f\u68b0\u69cb\u7bc9\u3068\u6bd4\u8f03\u3057\u3001\u672c\u8a2d\u8a08\u306f\u30b3\u30fc\u30c9\u91cf\u30fb\u6982\u5ff5\u7406\u89e3\u306e\u4e21\u9762\u3067\u5727\u5012\u7684\u306b\u8ca0\u62c5\u304c\u8efd\u3044\u3067\u3059\u3002\u518d\u8a55\u4fa1\u30ed\u30b8\u30c3\u30af\u3082\u30d1\u30e9\u30e1\u30fc\u30bf\u6307\u5b9a\u3067\u81ea\u52d5\u5316\u3055\u308c\u3066\u304a\u308a\u3001retry\u30eb\u30fc\u30d7\u3092\u81ea\u4f5c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u305b\u3093\u3002</p> <p>\u3053\u306e\u8a2d\u8a08\u306f\u3001\u958b\u767a\u8005\u304c\u81ea\u7136\u306b\u601d\u3044\u63cf\u304f\u554f\u984c\u89e3\u6c7a\u306e\u6d41\u308c\uff08\u4f8b\uff1a\u54c1\u8cea\u78ba\u8a8d\u5f8c\u306b\u518d\u751f\u6210\uff09\u3092\u305d\u306e\u307e\u307ePipeline\u5b9a\u7fa9\u3067\u8a18\u8ff0\u3067\u304d\u308b\u70b9\u304c\u512a\u308c\u3066\u3044\u307e\u3059\u3002\u30e6\u30fc\u30b6\u30fc\u306f\u30b9\u30c6\u30fc\u30b8\u3054\u3068\u306e\u4f4e\u30ec\u30d9\u30eb\u306a\u5236\u5fa1\u3084\u72b6\u614b\u9077\u79fb\u3092\u610f\u8b58\u305b\u305a\u306b\u6e08\u307f\u307e\u3059\u3002</p> <p>\u305f\u3060\u3057\u3001Pipeline\u5185\u90e8\u3067\u4f55\u304c\u8d77\u304d\u3066\u3044\u308b\u304b\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306e\u900f\u660e\u6027\u3082\u91cd\u8981\u3067\u3059\u3002\u305d\u306e\u305f\u3081\u3001\u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u306f\u30c8\u30ec\u30fc\u30b9\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u3001\u8a55\u4fa1\u3084\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u306e\u52d5\u4f5c\u3092\u53ef\u8996\u5316\u53ef\u80fd\u3068\u3057\u3066\u3044\u307e\u3059\u3002\u9ad8\u5ea6\u306a\u30e6\u30fc\u30b6\u30fc\u306f\u3001\u3088\u308a\u4e0b\u4f4d\u306eAgent\u3084Runner\u306b\u76f4\u63a5\u30a2\u30af\u30bb\u30b9\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002</p> <p>\u7d50\u8ad6: AgentPipeline\u306eDAG\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u8a2d\u8a08\u306f\u3001\u30e6\u30fc\u30b6\u30fc\u306e\u30b3\u30fc\u30c9\u91cf\u3068\u6982\u5ff5\u8ca0\u8377\u3092\u52b9\u679c\u7684\u306b\u8efd\u6e1b\u3057\u3066\u304a\u308a\u3001\u591a\u304f\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u3068\u3063\u3066\u5b9f\u88c5\u30b3\u30b9\u30c8\u3068\u4fdd\u5b88\u6027\u306e\u30d0\u30e9\u30f3\u30b9\u304c\u975e\u5e38\u306b\u826f\u597d\u3067\u3059\u3002</p>"},{"location":"analysis_of_library/#3-web-gui","title":"3. \u5bfe\u8a71\u578b\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3078\u306e\u62e1\u5f35\uff08\u30bf\u30fc\u30df\u30ca\u30eb\u2192Web GUI\u2192\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8\uff09","text":"<p>\u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u5bfe\u8a71\u7684\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306b\u62e1\u5f35\u3059\u308b\u306b\u306f\u3001\u4e3b\u306b\u5165\u529b\u3068\u51fa\u529b\u306e\u30c1\u30e3\u30cd\u30eb\u306e\u5909\u66f4\u304c\u6c42\u3081\u3089\u308c\u307e\u3059\u3002\u73fe\u5728\u306ePipeline\u306f\u3001\u72b6\u614b\u3092\u4fdd\u6301\u3057\u306a\u304c\u3089<code>.run(user_input)</code>\u3067\u9010\u6b21\u5165\u529b\u3092\u53d7\u3051\u4ed8\u3051\u308b\u305f\u3081\u3001\u30bf\u30fc\u30df\u30ca\u30eb\u3067\u306f\u3053\u306e\u307e\u307e\u5bfe\u8a71\u53ef\u80fd\u3067\u3059\u3002</p> <p>Web GUI\u306e\u5834\u5408: Flask\u3084FastAPI\u3092\u7528\u3044\u305fAPI\u30b5\u30fc\u30d0\u3067\u3001Pipeline\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30bb\u30c3\u30b7\u30e7\u30f3\u3054\u3068\u306b\u4fdd\u6301\u3057\u3001\u5404\u30e6\u30fc\u30b6\u30fc\u306e\u5165\u529b\u306b\u5fdc\u3058\u3066<code>.run()</code>\u3092\u975e\u540c\u671f\u547c\u3073\u51fa\u3057\u3059\u308b\u69cb\u6210\u304c\u73fe\u5b9f\u7684\u3067\u3059\u3002OpenAI API\u306f\u30c8\u30fc\u30af\u30f3\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u5fdc\u7b54\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u8fd4\u3059\u3053\u3068\u3067UX\u3092\u9ad8\u3081\u3089\u308c\u307e\u3059\u3002\u3053\u308c\u306f\u3001WebSocket\u3084SSE\u3092\u7528\u3044\u305f\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u3068\u3057\u3066\u5b9f\u88c5\u53ef\u80fd\u3067\u3059\u3002</p> <p>\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8\u306e\u5834\u5408: Slack\u3084Discord\u306a\u3069\u3067\u3082\u3001\u30e6\u30fc\u30b6\u30fcID\u3054\u3068\u306bPipeline\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u30de\u30c3\u30d4\u30f3\u30b0\u3057\u3066\u4fdd\u6301\u3059\u308b\u3053\u3068\u3067\u7d99\u7d9a\u7684\u306a\u4f1a\u8a71\u304c\u53ef\u80fd\u3067\u3059\u3002\u52a0\u3048\u3066\u3001\u30dc\u30bf\u30f3\u64cd\u4f5c\u3084\u69cb\u9020\u5316\u5165\u529b\uff08\u30d5\u30a9\u30fc\u30e0\uff09\u3092\u6271\u3046\u306b\u306f\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u5185\u3067\u30c4\u30fc\u30eb\u3068\u3057\u3066\u300c\u30e6\u30fc\u30b6\u30fc\u78ba\u8a8d\u5f85\u3061\u300d\u30a4\u30d9\u30f3\u30c8\u3092\u5b9a\u7fa9\u3057\u3001\u30e6\u30fc\u30b6\u30fc\u304b\u3089\u306e\u5165\u529b\u3092\u53d7\u3051\u305f\u5f8c\u306b\u518d\u958b\u3059\u308b\u4ed5\u7d44\u307f\u304c\u6c42\u3081\u3089\u308c\u307e\u3059\u3002\u3053\u308c\u306fhandoff\uff08\u5236\u5fa1\u306e\u4e00\u6642\u7684\u306a\u4eba\u9593\u5074\u3078\u306e\u59d4\u8b72\uff09\u3068\u3057\u3066\u8a2d\u8a08\u3067\u304d\u307e\u3059\u3002</p> <p>\u3053\u306e\u3068\u304d\u3001\u518d\u958b\u51e6\u7406\u3092\u4fdd\u8a3c\u3059\u308b\u306b\u306f\u3001\u30e6\u30fc\u30b6\u30fc\u5165\u529b\u5f85\u3061\u3092\u793a\u3059\u7279\u5225\u306a\u30c4\u30fc\u30eb\u547c\u3073\u51fa\u3057\u3084\u30c8\u30fc\u30af\u30f3\u3092\u4f7f\u3044\u3001UI\u5074\u3067\u306e\u5165\u529b\u5b8c\u4e86\u5f8c\u306bPipeline\u3092resume\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u591a\u304f\u306e\u5834\u5408\u3001\u901a\u5e38\u306e\u30bf\u30fc\u30f3\u30c6\u30a4\u30ad\u30f3\u30b0\u3067\u3082\u5341\u5206\u5bfe\u8a71\u304c\u53ef\u80fd\u3067\u3042\u308b\u305f\u3081\u3001\u540c\u671f\u7684\u306a\u30dd\u30fc\u30ba\u306f\u9ad8\u5ea6\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u307f\u306b\u9650\u5b9a\u3059\u3079\u304d\u3067\u3057\u3087\u3046\u3002</p> <p>\u30e6\u30fc\u30b6\u30fc\u4f53\u9a13\u3068\u4fdd\u5b88\u6027\u3078\u306e\u5f71\u97ff: \u30bf\u30fc\u30df\u30ca\u30eb\u3067\u306e\u30d7\u30ed\u30c8\u30bf\u30a4\u30d4\u30f3\u30b0\u304b\u3089Web\u3084\u30c1\u30e3\u30c3\u30c8UI\u3078\u306e\u79fb\u884c\u304c\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u884c\u3048\u308b\u8a2d\u8a08\u3068\u306a\u3063\u3066\u3044\u308b\u305f\u3081\u3001\u540c\u4e00\u306ePipeline\u30b3\u30fc\u30c9\u3092\u8907\u6570\u30a4\u30f3\u30bf\u30d5\u30a7\u30fc\u30b9\u3067\u518d\u5229\u7528\u53ef\u80fd\u3068\u3044\u3046\u70b9\u3067\u958b\u767a\u751f\u7523\u6027\u306f\u9ad8\u3044\u3067\u3059\u3002</p> <p>\u6280\u8853\u7684\u5b9f\u73fe\u6027: Python\u306eWeb\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3084\u975e\u540c\u671f\u51e6\u7406\u3001\u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406\u306b\u95a2\u3059\u308b\u77e5\u8b58\u304c\u3042\u308c\u3070\u3001\u4e0a\u8a18\u306e\u8a2d\u8a08\u306f\u6bd4\u8f03\u7684\u5bb9\u6613\u306b\u5b9f\u88c5\u53ef\u80fd\u3067\u3059\u3002\u30e6\u30fc\u30b6\u30fc\u6570\u306e\u5897\u52a0\u306b\u5099\u3048\u3066\u306f\u3001\u30bb\u30c3\u30b7\u30e7\u30f3\u306eGC\u3001\u30e2\u30c7\u30eb\u306e\u5171\u6709\u306a\u3069\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306e\u89b3\u70b9\u3082\u8003\u616e\u3059\u3079\u304d\u3067\u3059\u3002\u307e\u305f\u3001\u30c8\u30ec\u30fc\u30b9\u3084\u30ed\u30b0\u3092UI\u306b\u51fa\u529b\u3059\u308b\u4ed5\u7d44\u307f\uff08\u958b\u767a\u8005\u30e2\u30fc\u30c9\uff09\u3092\u5c0e\u5165\u3059\u308b\u3053\u3068\u3067\u3001\u4fdd\u5b88\u6027\u3068\u4fe1\u983c\u6027\u3082\u9ad8\u3081\u3089\u308c\u307e\u3059\u3002</p> <p>\u7d50\u8ad6: \u5bfe\u8a71\u578b\u62e1\u5f35\u3078\u306e\u9053\u7b4b\u306f\u660e\u78ba\u3067\u3042\u308a\u3001\u8a2d\u8a08\u4e0a\u306e\u969c\u58c1\u306f\u5c11\u306a\u3044\u3067\u3059\u3002Pipeline\u306e\u72b6\u614b\u4fdd\u6301\u8a2d\u8a08\u3084\u4e00\u8cab\u3057\u305fAPI\u69cb\u9020\u306b\u3088\u308a\u3001\u30bf\u30fc\u30df\u30ca\u30eb\u2192Web\u2192\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8\u3068\u3044\u3063\u305f\u5c55\u958b\u304c\u6bb5\u968e\u7684\u306b\u884c\u3048\u308b\u5f37\u307f\u3092\u6d3b\u304b\u3057\u3001\u591a\u69d8\u306a\u30e6\u30fc\u30b6\u30fc\u4f53\u9a13\u306e\u69cb\u7bc9\u304c\u53ef\u80fd\u3067\u3059\u3002</p>"},{"location":"analysis_of_library/#4-workflowdag","title":"4. Workflow/DAG\u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"analysis_of_library/#41","title":"4.1 \u5f37\u307f","text":"<ul> <li>\u5ba3\u8a00\u7684DAG\u5b9a\u7fa9: <code>dag = {\"A\": a, \"B\": b}</code> \u306e\u3088\u3046\u306a\u8f9e\u66f8\u30d9\u30fc\u30b9\u3067\u30b7\u30f3\u30d7\u30eb\u306b\u30d5\u30ed\u30fc\u8a18\u8ff0\u304c\u53ef\u80fd\u3067\u3001\u5b66\u7fd2\u30b3\u30b9\u30c8\u304c\u4f4e\u3044\u3002</li> <li>Pipeline\u518d\u5229\u7528\u6027: <code>AgentPipeline</code> \u3092\u305d\u306e\u307e\u307e\u5404\u30ce\u30fc\u30c9\u3068\u3057\u3066\u914d\u7f6e\u3067\u304d\u308b\u305f\u3081\u3001\u65e2\u5b58\u8cc7\u7523\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u69cb\u7bc9\u3067\u304d\u308b\u3002</li> <li>\u6697\u9ed9\u306e END \u30eb\u30fc\u30eb: \u30b4\u30fc\u30eb\u30ce\u30fc\u30c9\u3092\u660e\u793a\u3057\u306a\u304f\u3066\u3082\u7d42\u4e86\u3067\u304d\u308b\u305f\u3081\u3001\u30a8\u30c3\u30b8\u30b1\u30fc\u30b9\u306e\u5c11\u306a\u3044\u6700\u77ed\u69cb\u6210\u304c\u53ef\u80fd\u3002</li> <li>\u52d5\u7684\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0: <code>router_fn</code> \u306b\u3088\u308b\u6761\u4ef6\u5206\u5c90\u3067\u3001\u8a55\u4fa1\u7d50\u679c\u3084\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u5fdc\u3058\u305f\u30eb\u30fc\u30c8\u5909\u66f4\u304c\u5bb9\u6613\u3002</li> </ul>"},{"location":"analysis_of_library/#42","title":"4.2 \u8ab2\u984c","text":"<ul> <li>\u30b9\u30b1\u30fc\u30eb\u6642\u306e\u53ef\u8aad\u6027: \u30ce\u30fc\u30c9\u6570\u304c\u5897\u3048\u308b\u3068\u8f9e\u66f8\u5b9a\u7fa9\u304c\u7169\u96d1\u5316\u3057\u3001\u5168\u4f53\u50cf\u3092\u628a\u63e1\u3057\u3065\u3089\u3044\u3002</li> <li>\u72b6\u614b\u5171\u6709\u306e\u66d6\u6627\u3055: <code>AgentPipeline</code> \u304c\u5185\u90e8\u3067\u4f1a\u8a71\u5c65\u6b74\u3092\u4fdd\u6301\u3059\u308b\u4e00\u65b9\u3001\u30ce\u30fc\u30c9\u9593\u3067\u5171\u6709\u3057\u305f\u3044\u5909\u6570\u3084\u4e00\u6642\u30c7\u30fc\u30bf\u3092\u3069\u3046\u6271\u3046\u304b\u306e\u6307\u91dd\u304c\u4e0d\u8db3\u3002</li> <li>\u30e6\u30fc\u30b6\u30fc\u5165\u529b\u30ce\u30fc\u30c9\u306e\u6b20\u5982: \u4eba\u9593\u5074\u30a4\u30f3\u30bf\u30e9\u30af\u30b7\u30e7\u30f3\u3092\u5f85\u3064\u30ce\u30fc\u30c9\u30bf\u30a4\u30d7\u304c\u6a19\u6e96\u5316\u3055\u308c\u3066\u304a\u3089\u305a\u3001\u624b\u52d5\u3067\u30c4\u30fc\u30eb\uff0f\u30cf\u30f3\u30c9\u30aa\u30d5\u3092\u66f8\u304f\u5fc5\u8981\u304c\u3042\u308b\u3002</li> <li>\u4e26\u5217\u5b9f\u884c\u306e\u30b5\u30dd\u30fc\u30c8: \u73fe\u72b6\u3067\u306f\u76f4\u5217\u30d5\u30ed\u30fc\u524d\u63d0\u3002LangGraph \u306e\u3088\u3046\u306a\u5206\u5c90\uff0b\u30de\u30fc\u30b8\u3084\u30d5\u30a1\u30f3\u30a2\u30a6\u30c8\u306e\u8a18\u6cd5\u304c\u306a\u3044\u3002</li> </ul>"},{"location":"analysis_of_library/#43","title":"4.3 \u8a55\u4fa1\u307e\u3068\u3081","text":"<p>\u73fe\u6642\u70b9\u306e Workflow/DAG \u6a5f\u80fd\u306f \u300c80% \u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3092\u6700\u77ed\u30b3\u30fc\u30c9\u3067\u89e3\u6c7a\u3059\u308b\u30e9\u30a4\u30c8\u7d1a\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u300d \u3068\u3057\u3066\u9ad8\u8a55\u4fa1\u3002\u305f\u3060\u3057\u3001\u4e0a\u8a18\u8ab2\u984c\u3092\u89e3\u6c7a\u3059\u308b\u3053\u3068\u3067\u3001\u3088\u308a\u5927\u898f\u6a21\u30fb\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u306a\u30b7\u30ca\u30ea\u30aa\u306b\u3082\u8010\u3048\u3046\u308b\u5805\u7262\u6027\u304c\u5f97\u3089\u308c\u308b\u3002</p>"},{"location":"analysis_of_library/#5-workflow","title":"5. Workflow \u62e1\u5f35\u8a2d\u8a08\u63d0\u6848","text":""},{"location":"analysis_of_library/#51","title":"5.1 \u8a2d\u8a08\u76ee\u6a19","text":"<ol> <li>\u5ba3\u8a00\u7684\u3067\u8aad\u307f\u66f8\u304d\u3057\u3084\u3059\u3044 DSL \u3092\u7dad\u6301\u3057\u3064\u3064\u3001\u5927\u898f\u6a21 DAG \u3067\u3082\u53ef\u8996\u6027\u3092\u78ba\u4fdd\u3002</li> <li>\u30e6\u30fc\u30b6\u30fc\u5165\u529b\u30ce\u30fc\u30c9 \u3092\u30d5\u30a1\u30fc\u30b9\u30c8\u30af\u30e9\u30b9\u6982\u5ff5\u3068\u3057\u3066\u8ffd\u52a0\u3057\u3001\u30bf\u30fc\u30df\u30ca\u30eb\uff0fGUI\uff0f\u30c1\u30e3\u30c3\u30c8\u3067\u7d71\u4e00\u7684\u306b\u6271\u3048\u308b\u3088\u3046\u306b\u3059\u308b\u3002</li> <li>\u72b6\u614b\u5171\u6709\u30b9\u30ad\u30fc\u30de \u3092\u5c0e\u5165\u3057\u3066\u3001\u30ce\u30fc\u30c9\u9593\u30c7\u30fc\u30bf\u4ea4\u63db\u3092\u578b\u5b89\u5168\u304b\u3064\u660e\u793a\u7684\u306b\u3059\u308b\u3002</li> <li>\u975e\u540c\u671f\u30fb\u4e26\u5217\u5b9f\u884c \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3057\u3001\u9577\u6642\u9593\u30bf\u30b9\u30af\u3084 I/O \u5f85\u3061\u3092\u52b9\u7387\u5316\u3002</li> <li>\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3\uff08\u30c8\u30ec\u30fc\u30b9\u3001\u30e1\u30c8\u30ea\u30af\u30b9\uff09\u3092\u6a19\u6e96\u88c5\u5099\u3057\u3001\u30c7\u30d0\u30c3\u30b0\u3068\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0\u3092\u5bb9\u6613\u306b\u3002</li> </ol> <p>\u3053\u308c\u306b\u3088\u308a\u3001Agents SDK Models \u4e0a\u3067\u5ba3\u8a00\u7684\u304b\u3064\u62e1\u5f35\u6027\u306e\u9ad8\u3044 Workflow \u6a5f\u80fd\u3092\u5b9f\u73fe\u3057\u3001\u30bf\u30fc\u30df\u30ca\u30eb\u304b\u3089GUI/\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8\u307e\u3067\u4e00\u8cab\u3057\u305f\u958b\u767a\u4f53\u9a13\u3092\u63d0\u4f9b\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"api_reference/","title":"API Reference","text":"<p>This page provides detailed API reference for the Refinire package's main components.</p>"},{"location":"api_reference/#classes-and-functions-overview","title":"Classes and Functions Overview","text":"Name Type Description get_llm Function Get LLM instance from model name and provider create_simple_gen_agent Function Create a simple generation agent create_evaluated_gen_agent Function Create a generation agent with evaluation capabilities Flow Class Central workflow management class GenAgent Class Agent class with generation and evaluation capabilities ClarifyAgent Class Interactive task clarification agent Context Class Context for sharing state between steps ConsoleTracingProcessor Class Console colored trace output processor enable_console_tracing Function Enable console tracing functionality disable_tracing Function Disable all tracing functionality AgentPipeline Class [Deprecated] Integrated pipeline for generation, evaluation, tools, and guardrails"},{"location":"api_reference/#unified-llm-interface","title":"Unified LLM Interface","text":""},{"location":"api_reference/#get_llm","title":"get_llm","text":"<p>Factory function for handling multiple LLM providers with a unified interface.</p> <pre><code>from refinire import get_llm\n\n# OpenAI\nllm = get_llm(\"gpt-4o-mini\")\n\n# Anthropic Claude\nllm = get_llm(\"claude-3-sonnet\")\n\n# Google Gemini\nllm = get_llm(\"gemini-pro\")\n\n# Ollama (Local)\nllm = get_llm(\"llama3.1:8b\")\n</code></pre>"},{"location":"api_reference/#parameters","title":"Parameters","text":"Name Type Required/Optional Default Description model str Required - LLM model name to use provider str Optional None Model provider name (auto-inferred if None) temperature float Optional 0.3 Sampling temperature (0.0-2.0) api_key str Optional None Provider API key base_url str Optional None Provider API base URL thinking bool Optional False Claude model thinking mode tracing bool Optional False Enable Agents SDK tracing"},{"location":"api_reference/#returns","title":"Returns","text":"<ul> <li>LLM Instance: LLM object for the specified provider</li> </ul>"},{"location":"api_reference/#supported-models","title":"Supported Models","text":"<p>OpenAI - gpt-4o, gpt-4o-mini - gpt-4-turbo, gpt-4 - gpt-3.5-turbo</p> <p>Anthropic Claude - claude-3-5-sonnet-20241022 - claude-3-sonnet, claude-3-haiku - claude-3-opus</p> <p>Google Gemini - gemini-pro, gemini-pro-vision - gemini-1.5-pro, gemini-1.5-flash</p> <p>Ollama - llama3.1:8b, llama3.1:70b - mistral:7b - codellama:7b</p>"},{"location":"api_reference/#agent-creation-functions","title":"Agent Creation Functions","text":""},{"location":"api_reference/#create_simple_gen_agent","title":"create_simple_gen_agent","text":"<p>Creates a simple generation agent.</p> <pre><code>from refinire import create_simple_gen_agent\n\nagent = create_simple_gen_agent(\n    name=\"assistant\",\n    instructions=\"You are a helpful assistant.\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"api_reference/#parameters_1","title":"Parameters","text":"Name Type Required/Optional Default Description name str Required - Agent name instructions str Required - System prompt model str Required - Model name to use tools list Optional None List of available tools"},{"location":"api_reference/#create_evaluated_gen_agent","title":"create_evaluated_gen_agent","text":"<p>Creates a generation agent with evaluation capabilities.</p> <pre><code>from refinire import create_evaluated_gen_agent\n\nagent = create_evaluated_gen_agent(\n    name=\"quality_assistant\",\n    generation_instructions=\"Generate helpful responses.\",\n    evaluation_instructions=\"Evaluate accuracy and usefulness.\",\n    threshold=80.0,\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"api_reference/#parameters_2","title":"Parameters","text":"Name Type Required/Optional Default Description name str Required - Agent name generation_instructions str Required - Generation system prompt evaluation_instructions str Required - Evaluation system prompt threshold float Required - Quality threshold (0-100) model str Required - Model name to use tools list Optional None List of available tools"},{"location":"api_reference/#flowstep-architecture","title":"Flow/Step Architecture","text":""},{"location":"api_reference/#flow","title":"Flow","text":"<p>Central workflow management class. Create complex processing flows by combining multiple steps.</p> <pre><code>from refinire import Flow, FunctionStep\nimport asyncio\n\n# Simple Flow\nflow = Flow(steps=gen_agent)\n\n# Multi-step Flow\nflow = Flow([\n    (\"step1\", FunctionStep(\"step1\", func1)),\n    (\"step2\", FunctionStep(\"step2\", func2))\n])\n\n# Execute\nresult = asyncio.run(flow.run(input_data=\"input data\"))\n</code></pre>"},{"location":"api_reference/#main-methods","title":"Main Methods","text":"Method Name Parameters Return Value Description run input_data: Any Context Execute workflow asynchronously run_sync input_data: Any Context Execute workflow synchronously show - None Visualize workflow structure"},{"location":"api_reference/#context","title":"Context","text":"<p>Context class for sharing state between steps.</p> <pre><code>from refinire import Context\n\nctx = Context()\nctx.shared_state[\"key\"] = \"value\"\nctx.finish()  # End workflow\n</code></pre>"},{"location":"api_reference/#main-attributes-and-methods","title":"Main Attributes and Methods","text":"Name Type Description shared_state dict State shared between steps user_input Any User input data finish() Method Signal workflow completion"},{"location":"api_reference/#agent-classes","title":"Agent Classes","text":""},{"location":"api_reference/#genagent","title":"GenAgent","text":"<p>Agent class with generation and evaluation capabilities. Can be used as a step within Flow.</p> <pre><code>from refinire.agents import GenAgent\n\nagent = GenAgent(\n    name=\"generator\",\n    generation_instructions=\"Generate text.\",\n    evaluation_instructions=\"Evaluate quality.\",\n    model=\"gpt-4o-mini\",\n    threshold=75.0\n)\n</code></pre>"},{"location":"api_reference/#main-methods_1","title":"Main Methods","text":"Method Name Parameters Return Value Description run user_input: str, ctx: Context Context Execute agent asynchronously run_sync user_input: str, ctx: Context Context Execute agent synchronously"},{"location":"api_reference/#clarifyagent","title":"ClarifyAgent","text":"<p>Interactive task clarification agent. Asks questions to clarify unclear requests.</p> <pre><code>from refinire.agents import ClarifyAgent\n\nagent = ClarifyAgent(\n    name=\"clarifier\",\n    instructions=\"Clarify user requirements.\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"api_reference/#tracing-functionality","title":"Tracing Functionality","text":""},{"location":"api_reference/#enable_console_tracing","title":"enable_console_tracing","text":"<p>Enable colored console tracing.</p> <pre><code>from refinire import enable_console_tracing\n\nenable_console_tracing()\n</code></pre>"},{"location":"api_reference/#disable_tracing","title":"disable_tracing","text":"<p>Disable all tracing functionality.</p> <pre><code>from refinire import disable_tracing\n\ndisable_tracing()\n</code></pre>"},{"location":"api_reference/#consoletracingprocessor","title":"ConsoleTracingProcessor","text":"<p>Class for custom trace processing.</p> <pre><code>from refinire.tracing import ConsoleTracingProcessor\n\nprocessor = ConsoleTracingProcessor(\n    output_stream=\"console\",\n    simple_mode=True\n)\n</code></pre>"},{"location":"api_reference/#deprecated-apis","title":"Deprecated APIs","text":""},{"location":"api_reference/#agentpipeline-deprecated","title":"AgentPipeline (Deprecated)","text":"<p>\u26a0\ufe0f Important: <code>AgentPipeline</code> will be removed in v0.1.0. Use <code>GenAgent + Flow</code> for new code.</p> <pre><code># Deprecated - Do not use in new code\nfrom refinire import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"example\",\n    generation_instructions=\"Generate text.\",\n    evaluation_instructions=\"Evaluate quality.\",\n    model=\"gpt-4o-mini\",\n    threshold=80\n)\n</code></pre>"},{"location":"api_reference/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>classDiagram\n    class Flow {\n        +run(input_data)\n        +run_sync(input_data)\n        +show()\n    }\n\n    class GenAgent {\n        +run(user_input, ctx)\n        +run_sync(user_input, ctx)\n    }\n\n    class ClarifyAgent {\n        +run(user_input, ctx)\n        +clarify_task(task)\n    }\n\n    class Context {\n        +shared_state: dict\n        +user_input: Any\n        +finish()\n    }\n\n    Flow --&gt; GenAgent\n    Flow --&gt; ClarifyAgent\n    Flow --&gt; Context\n    GenAgent --&gt; Context\n    ClarifyAgent --&gt; Context</code></pre>"},{"location":"api_reference/#usage-examples","title":"Usage Examples","text":""},{"location":"api_reference/#basic-usage-pattern","title":"Basic Usage Pattern","text":"<pre><code>from refinire import create_simple_gen_agent, Flow, Context\nimport asyncio\n\n# 1. Create agent\nagent = create_simple_gen_agent(\n    name=\"assistant\",\n    instructions=\"Respond as a helpful assistant.\",\n    model=\"gpt-4o-mini\"\n)\n\n# 2. Create flow\nflow = Flow(steps=agent)\n\n# 3. Execute\nasync def main():\n    result = await flow.run(input_data=\"Hello\")\n    print(result.shared_state[\"assistant_result\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"api_reference/#complex-workflow-example","title":"Complex Workflow Example","text":"<pre><code>from refinire import Flow, FunctionStep, create_evaluated_gen_agent\nimport asyncio\n\ndef preprocess(user_input: str, ctx: Context) -&gt; Context:\n    ctx.shared_state[\"processed_input\"] = user_input.strip().lower()\n    return ctx\n\nagent = create_evaluated_gen_agent(\n    name=\"analyzer\",\n    generation_instructions=\"Analyze the input.\",\n    evaluation_instructions=\"Evaluate analysis accuracy.\",\n    threshold=80.0,\n    model=\"gpt-4o-mini\"\n)\n\ndef postprocess(user_input: str, ctx: Context) -&gt; Context:\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n    ctx.shared_state[\"final_result\"] = f\"Final result: {result}\"\n    ctx.finish()\n    return ctx\n\nflow = Flow([\n    (\"preprocess\", FunctionStep(\"preprocess\", preprocess)),\n    (\"analyze\", agent),\n    (\"postprocess\", FunctionStep(\"postprocess\", postprocess))\n])\n\nasync def main():\n    result = await flow.run(input_data=\"  Analyze this text  \")\n    print(result.shared_state[\"final_result\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"api_reference/#contextprovider-interface","title":"ContextProvider Interface","text":"Class/Method Description (EN) Arguments / Returns <code>ContextProvider</code> Abstract base for all context providers. <code>provider_name</code> Provider name (class variable). <code>str</code> <code>get_config_schema</code> Returns config schema for the provider. <code>classmethod</code> \u2192 <code>Dict[str, Any]</code> <code>from_config</code> Instantiates provider from config dict. <code>classmethod</code> \u2192 instance <code>get_context</code> Returns context string for a query. <code>query: str, previous_context: Optional[str], **kwargs</code> \u2192 <code>str</code> <code>update</code> Updates provider state with new interaction. <code>interaction: Dict[str, Any]</code> <code>clear</code> Clears provider state."},{"location":"api_reference/#built-in-providers","title":"Built-in Providers","text":""},{"location":"api_reference/#conversationhistoryprovider","title":"ConversationHistoryProvider","text":"<p>Manages conversation history.</p> <p>Configuration Example: <pre><code>{\n    \"type\": \"conversation_history\",\n    \"max_items\": 10\n}\n</code></pre></p> <p>Parameters: - <code>max_items</code> (int): Maximum number of messages to keep (default: 10)</p>"},{"location":"api_reference/#fixedfileprovider","title":"FixedFileProvider","text":"<p>Always provides content from specified files.</p> <p>Configuration Example: <pre><code>{\n    \"type\": \"fixed_file\",\n    \"file_path\": \"config.yaml\",\n    \"encoding\": \"utf-8\",\n    \"check_updates\": True\n}\n</code></pre></p> <p>Parameters: - <code>file_path</code> (str, required): Path to the file to read - <code>encoding</code> (str): File encoding (default: \"utf-8\") - <code>check_updates</code> (bool): Whether to check for file updates (default: True)</p>"},{"location":"api_reference/#sourcecodeprovider","title":"SourceCodeProvider","text":"<p>Automatically searches for source code related to user questions.</p> <p>Configuration Example: <pre><code>{\n    \"type\": \"source_code\",\n    \"base_path\": \".\",\n    \"max_files\": 5,\n    \"max_file_size\": 1000,\n    \"file_extensions\": [\".py\", \".js\", \".ts\"],\n    \"include_patterns\": [\"src/**/*\"],\n    \"exclude_patterns\": [\"tests/**/*\"]\n}\n</code></pre></p> <p>Parameters: - <code>base_path</code> (str): Base directory path for codebase analysis (default: \".\") - <code>max_files</code> (int): Maximum number of files to include in context (default: 50) - <code>max_file_size</code> (int): Maximum file size in bytes to read (default: 10000) - <code>file_extensions</code> (list): List of file extensions to include - <code>include_patterns</code> (list): List of patterns to include - <code>exclude_patterns</code> (list): List of patterns to exclude</p>"},{"location":"api_reference/#cutcontextprovider","title":"CutContextProvider","text":"<p>Compresses context to specified length.</p> <p>Configuration Example: <pre><code>{\n    \"type\": \"cut_context\",\n    \"provider\": {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    \"max_chars\": 3000,\n    \"max_tokens\": None,\n    \"cut_strategy\": \"middle\",\n    \"preserve_sections\": True\n}\n</code></pre></p> <p>Parameters: - <code>provider</code> (dict, required): Configuration for the wrapped context provider - <code>max_chars</code> (int): Maximum character count (None for no limit) - <code>max_tokens</code> (int): Maximum token count (None for no limit) - <code>cut_strategy</code> (str): How to cut the context (\"start\", \"end\", \"middle\") (default: \"end\") - <code>preserve_sections</code> (bool): Whether to preserve complete sections when cutting (default: True)</p>"},{"location":"api_reference/#refinireagent-extensions","title":"RefinireAgent Extensions","text":"Class/Method Description (EN) Arguments / Returns <code>context_providers_config</code> List/dict/YAML string for context provider config. <code>List[dict]</code>/<code>str</code> <code>get_context_provider_schemas</code> Returns schemas for all available providers. <code>classmethod</code> \u2192 <code>Dict[str, Any]</code> <code>clear_context</code> Clears all context providers."},{"location":"api_reference/#example-using-sourcecodeprovider","title":"Example: Using SourceCodeProvider","text":"<pre><code>from refinire.agents.context_provider_factory import ContextProviderFactory\n\nconfig = {\n    \"type\": \"source_code\",\n    \"base_path\": \"src\",\n    \"max_files\": 5\n}\nprovider = ContextProviderFactory.create_provider(config)\ncontext = provider.get_context(\"How does the pipeline work?\")\nprint(context)\n</code></pre>"},{"location":"api_reference/#example-yaml-like-multi-provider","title":"Example: YAML-like Multi-provider","text":"<pre><code>- conversation_history:\n    max_items: 5\n- source_code:\n    base_path: src\n    max_files: 3\n- cut_context:\n    provider:\n      type: conversation_history\n      max_items: 10\n    max_chars: 4000\n    cut_strategy: end\n</code></pre>"},{"location":"api_reference/#see-also","title":"See Also","text":"<ul> <li><code>docs/api_reference_ja.md</code> (Japanese)</li> <li><code>docs/context_management.md</code> (Design)</li> <li><code>examples/context_management_example.py</code> (Usage)</li> </ul>"},{"location":"api_reference_ja/","title":"API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9","text":"<p>\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u3001Refinire \u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u4e3b\u8981API\u306e\u8a73\u7d30\u306a\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"api_reference_ja/#_1","title":"\u30af\u30e9\u30b9\u30fb\u95a2\u6570\u4e00\u89a7","text":"\u540d\u524d \u7a2e\u5225 \u6982\u8981 get_llm \u95a2\u6570 \u30e2\u30c7\u30eb\u540d\u30fb\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u540d\u304b\u3089LLM\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u53d6\u5f97 create_simple_gen_agent \u95a2\u6570 \u30b7\u30f3\u30d7\u30eb\u306a\u751f\u6210\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210 create_evaluated_gen_agent \u95a2\u6570 \u8a55\u4fa1\u6a5f\u80fd\u4ed8\u304d\u751f\u6210\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210 Flow \u30af\u30e9\u30b9 \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7ba1\u7406\u306e\u4e2d\u5fc3\u30af\u30e9\u30b9 GenAgent \u30af\u30e9\u30b9 \u751f\u6210\u30fb\u8a55\u4fa1\u6a5f\u80fd\u3092\u6301\u3064\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u30af\u30e9\u30b9 ClarifyAgent \u30af\u30e9\u30b9 \u5bfe\u8a71\u578b\u30bf\u30b9\u30af\u660e\u78ba\u5316\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 Context \u30af\u30e9\u30b9 \u30b9\u30c6\u30c3\u30d7\u9593\u3067\u306e\u72b6\u614b\u5171\u6709\u7528\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8 ConsoleTracingProcessor \u30af\u30e9\u30b9 \u30b3\u30f3\u30bd\u30fc\u30eb\u8272\u5206\u3051\u30c8\u30ec\u30fc\u30b9\u51fa\u529b\u7528\u30d7\u30ed\u30bb\u30c3\u30b5 enable_console_tracing \u95a2\u6570 \u30b3\u30f3\u30bd\u30fc\u30eb\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u3092\u6709\u52b9\u5316 disable_tracing \u95a2\u6570 \u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u6a5f\u80fd\u3092\u3059\u3079\u3066\u7121\u52b9\u5316 AgentPipeline \u30af\u30e9\u30b9 \u3010\u975e\u63a8\u5968\u3011\u751f\u6210\u30fb\u8a55\u4fa1\u30fb\u30c4\u30fc\u30eb\u30fb\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3092\u7d71\u5408\u3057\u305f\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3"},{"location":"api_reference_ja/#llm","title":"\u7d71\u4e00LLM\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9","text":""},{"location":"api_reference_ja/#get_llm","title":"get_llm","text":"<p>\u8907\u6570\u306eLLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u7d71\u4e00\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3067\u6271\u3046\u305f\u3081\u306e\u30d5\u30a1\u30af\u30c8\u30ea\u95a2\u6570\u3067\u3059\u3002</p> <pre><code>from refinire import get_llm\n\n# OpenAI\nllm = get_llm(\"gpt-4o-mini\")\n\n# Anthropic Claude\nllm = get_llm(\"claude-3-sonnet\")\n\n# Google Gemini\nllm = get_llm(\"gemini-pro\")\n\n# Ollama\uff08\u30ed\u30fc\u30ab\u30eb\uff09\nllm = get_llm(\"llama3.1:8b\")\n</code></pre>"},{"location":"api_reference_ja/#_2","title":"\u5f15\u6570","text":"\u540d\u524d \u578b \u5fc5\u9808/\u30aa\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 \u8aac\u660e model str \u5fc5\u9808 - \u4f7f\u7528\u3059\u308bLLM\u30e2\u30c7\u30eb\u540d provider str \u30aa\u30d7\u30b7\u30e7\u30f3 None \u30e2\u30c7\u30eb\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u540d\uff08\u81ea\u52d5\u63a8\u8ad6\u53ef\uff09 temperature float \u30aa\u30d7\u30b7\u30e7\u30f3 0.3 \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6e29\u5ea6\uff080.0-2.0\uff09 api_key str \u30aa\u30d7\u30b7\u30e7\u30f3 None \u30d7\u30ed\u30d0\u30a4\u30c0\u30fcAPI\u30ad\u30fc base_url str \u30aa\u30d7\u30b7\u30e7\u30f3 None \u30d7\u30ed\u30d0\u30a4\u30c0\u30fcAPI\u30d9\u30fc\u30b9URL thinking bool \u30aa\u30d7\u30b7\u30e7\u30f3 False Claude\u30e2\u30c7\u30eb\u306e\u601d\u8003\u30e2\u30fc\u30c9 tracing bool \u30aa\u30d7\u30b7\u30e7\u30f3 False Agents SDK\u306e\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u3092\u6709\u52b9\u5316\u3059\u308b\u304b"},{"location":"api_reference_ja/#_3","title":"\u623b\u308a\u5024","text":"<ul> <li>LLM\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9: \u6307\u5b9a\u3055\u308c\u305f\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306eLLM\u30aa\u30d6\u30b8\u30a7\u30af\u30c8</li> </ul>"},{"location":"api_reference_ja/#_4","title":"\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u308b\u30e2\u30c7\u30eb","text":"<p>OpenAI - gpt-4o, gpt-4o-mini - gpt-4-turbo, gpt-4 - gpt-3.5-turbo</p> <p>Anthropic Claude - claude-3-5-sonnet-20241022 - claude-3-sonnet, claude-3-haiku - claude-3-opus</p> <p>Google Gemini - gemini-pro, gemini-pro-vision - gemini-1.5-pro, gemini-1.5-flash</p> <p>Ollama - llama3.1:8b, llama3.1:70b - mistral:7b - codellama:7b</p>"},{"location":"api_reference_ja/#_5","title":"\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u4f5c\u6210\u95a2\u6570","text":""},{"location":"api_reference_ja/#create_simple_gen_agent","title":"create_simple_gen_agent","text":"<p>\u30b7\u30f3\u30d7\u30eb\u306a\u751f\u6210\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</p> <pre><code>from refinire import create_simple_gen_agent\n\nagent = create_simple_gen_agent(\n    name=\"assistant\",\n    instructions=\"\u3042\u306a\u305f\u306f\u89aa\u5207\u306a\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"api_reference_ja/#_6","title":"\u5f15\u6570","text":"\u540d\u524d \u578b \u5fc5\u9808/\u30aa\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 \u8aac\u660e name str \u5fc5\u9808 - \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d instructions str \u5fc5\u9808 - \u30b7\u30b9\u30c6\u30e0\u30d7\u30ed\u30f3\u30d7\u30c8 model str \u5fc5\u9808 - \u4f7f\u7528\u3059\u308b\u30e2\u30c7\u30eb\u540d tools list \u30aa\u30d7\u30b7\u30e7\u30f3 None \u4f7f\u7528\u53ef\u80fd\u306a\u30c4\u30fc\u30eb\u306e\u30ea\u30b9\u30c8"},{"location":"api_reference_ja/#create_evaluated_gen_agent","title":"create_evaluated_gen_agent","text":"<p>\u8a55\u4fa1\u6a5f\u80fd\u4ed8\u304d\u306e\u751f\u6210\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</p> <pre><code>from refinire import create_evaluated_gen_agent\n\nagent = create_evaluated_gen_agent(\n    name=\"quality_assistant\",\n    generation_instructions=\"\u5f79\u7acb\u3064\u56de\u7b54\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    evaluation_instructions=\"\u6b63\u78ba\u6027\u3068\u6709\u7528\u6027\u3092\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    threshold=80.0,\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"api_reference_ja/#_7","title":"\u5f15\u6570","text":"\u540d\u524d \u578b \u5fc5\u9808/\u30aa\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 \u8aac\u660e name str \u5fc5\u9808 - \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d generation_instructions str \u5fc5\u9808 - \u751f\u6210\u7528\u30b7\u30b9\u30c6\u30e0\u30d7\u30ed\u30f3\u30d7\u30c8 evaluation_instructions str \u5fc5\u9808 - \u8a55\u4fa1\u7528\u30b7\u30b9\u30c6\u30e0\u30d7\u30ed\u30f3\u30d7\u30c8 threshold float \u5fc5\u9808 - \u54c1\u8cea\u95be\u5024\uff080-100\uff09 model str \u5fc5\u9808 - \u4f7f\u7528\u3059\u308b\u30e2\u30c7\u30eb\u540d tools list \u30aa\u30d7\u30b7\u30e7\u30f3 None \u4f7f\u7528\u53ef\u80fd\u306a\u30c4\u30fc\u30eb\u306e\u30ea\u30b9\u30c8"},{"location":"api_reference_ja/#flowstep","title":"Flow/Step\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"api_reference_ja/#flow","title":"Flow","text":"<p>\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7ba1\u7406\u306e\u4e2d\u5fc3\u30af\u30e9\u30b9\u3067\u3059\u3002\u8907\u6570\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u8907\u96d1\u306a\u51e6\u7406\u30d5\u30ed\u30fc\u3092\u4f5c\u6210\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from refinire import Flow, FunctionStep\nimport asyncio\n\n# \u30b7\u30f3\u30d7\u30eb\u306aFlow\nflow = Flow(steps=gen_agent)\n\n# \u8907\u6570\u30b9\u30c6\u30c3\u30d7\u306eFlow\nflow = Flow([\n    (\"step1\", FunctionStep(\"step1\", func1)),\n    (\"step2\", FunctionStep(\"step2\", func2))\n])\n\n# \u5b9f\u884c\nresult = asyncio.run(flow.run(input_data=\"\u5165\u529b\u30c7\u30fc\u30bf\"))\n</code></pre>"},{"location":"api_reference_ja/#_8","title":"\u4e3b\u8981\u30e1\u30bd\u30c3\u30c9","text":"\u30e1\u30bd\u30c3\u30c9\u540d \u5f15\u6570 \u623b\u308a\u5024 \u8aac\u660e run input_data: Any Context \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u975e\u540c\u671f\u5b9f\u884c run_sync input_data: Any Context \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u540c\u671f\u5b9f\u884c show - None \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u69cb\u9020\u3092\u53ef\u8996\u5316"},{"location":"api_reference_ja/#context","title":"Context","text":"<p>\u30b9\u30c6\u30c3\u30d7\u9593\u3067\u306e\u72b6\u614b\u5171\u6709\u306b\u4f7f\u7528\u3059\u308b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30af\u30e9\u30b9\u3067\u3059\u3002</p> <pre><code>from refinire import Context\n\nctx = Context()\nctx.shared_state[\"key\"] = \"value\"\nctx.finish()  # \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7d42\u4e86\n</code></pre>"},{"location":"api_reference_ja/#_9","title":"\u4e3b\u8981\u5c5e\u6027\u30fb\u30e1\u30bd\u30c3\u30c9","text":"\u540d\u524d \u578b \u8aac\u660e shared_state dict \u30b9\u30c6\u30c3\u30d7\u9593\u3067\u5171\u6709\u3055\u308c\u308b\u72b6\u614b user_input Any \u30e6\u30fc\u30b6\u30fc\u5165\u529b\u30c7\u30fc\u30bf finish() \u30e1\u30bd\u30c3\u30c9 \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7d42\u4e86\u3092\u6307\u793a"},{"location":"api_reference_ja/#_10","title":"\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u30af\u30e9\u30b9","text":""},{"location":"api_reference_ja/#genagent","title":"GenAgent","text":"<p>\u751f\u6210\u30fb\u8a55\u4fa1\u6a5f\u80fd\u3092\u6301\u3064\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u30af\u30e9\u30b9\u3067\u3059\u3002Flow\u5185\u3067\u306e\u30b9\u30c6\u30c3\u30d7\u3068\u3057\u3066\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from refinire.agents import GenAgent\n\nagent = GenAgent(\n    name=\"generator\",\n    generation_instructions=\"\u6587\u7ae0\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    evaluation_instructions=\"\u54c1\u8cea\u3092\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    threshold=75.0\n)\n</code></pre>"},{"location":"api_reference_ja/#_11","title":"\u4e3b\u8981\u30e1\u30bd\u30c3\u30c9","text":"\u30e1\u30bd\u30c3\u30c9\u540d \u5f15\u6570 \u623b\u308a\u5024 \u8aac\u660e run user_input: str, ctx: Context Context \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u975e\u540c\u671f\u5b9f\u884c run_sync user_input: str, ctx: Context Context \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u540c\u671f\u5b9f\u884c"},{"location":"api_reference_ja/#clarifyagent","title":"ClarifyAgent","text":"<p>\u5bfe\u8a71\u578b\u30bf\u30b9\u30af\u660e\u78ba\u5316\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3067\u3059\u3002\u4e0d\u660e\u78ba\u306a\u8981\u6c42\u3092\u660e\u78ba\u5316\u3059\u308b\u305f\u3081\u306e\u8cea\u554f\u3092\u884c\u3044\u307e\u3059\u3002</p> <pre><code>from refinire.agents import ClarifyAgent\n\nagent = ClarifyAgent(\n    name=\"clarifier\",\n    instructions=\"\u30e6\u30fc\u30b6\u30fc\u306e\u8981\u6c42\u3092\u660e\u78ba\u5316\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"api_reference_ja/#_12","title":"\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u6a5f\u80fd","text":""},{"location":"api_reference_ja/#enable_console_tracing","title":"enable_console_tracing","text":"<p>\u30b3\u30f3\u30bd\u30fc\u30eb\u3067\u306e\u8272\u5206\u3051\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u3092\u6709\u52b9\u5316\u3057\u307e\u3059\u3002</p> <pre><code>from refinire import enable_console_tracing\n\nenable_console_tracing()\n</code></pre>"},{"location":"api_reference_ja/#disable_tracing","title":"disable_tracing","text":"<p>\u5168\u3066\u306e\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u6a5f\u80fd\u3092\u7121\u52b9\u5316\u3057\u307e\u3059\u3002</p> <pre><code>from refinire import disable_tracing\n\ndisable_tracing()\n</code></pre>"},{"location":"api_reference_ja/#consoletracingprocessor","title":"ConsoleTracingProcessor","text":"<p>\u30ab\u30b9\u30bf\u30e0\u30c8\u30ec\u30fc\u30b9\u51e6\u7406\u7528\u306e\u30af\u30e9\u30b9\u3067\u3059\u3002</p> <pre><code>from refinire.tracing import ConsoleTracingProcessor\n\nprocessor = ConsoleTracingProcessor(\n    output_stream=\"console\",\n    simple_mode=True\n)\n</code></pre>"},{"location":"api_reference_ja/#api_1","title":"\u975e\u63a8\u5968API","text":""},{"location":"api_reference_ja/#agentpipeline","title":"AgentPipeline\uff08\u975e\u63a8\u5968\uff09","text":"<p>\u26a0\ufe0f \u91cd\u8981: <code>AgentPipeline</code>\u306f v0.1.0 \u3067\u524a\u9664\u3055\u308c\u308b\u4e88\u5b9a\u3067\u3059\u3002\u65b0\u3057\u3044\u30b3\u30fc\u30c9\u3067\u306f <code>GenAgent + Flow</code> \u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code># \u975e\u63a8\u5968 - \u65b0\u3057\u3044\u30b3\u30fc\u30c9\u3067\u306f\u4f7f\u7528\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\nfrom refinire import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"example\",\n    generation_instructions=\"\u6587\u7ae0\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    evaluation_instructions=\"\u54c1\u8cea\u3092\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    threshold=80\n)\n</code></pre>"},{"location":"api_reference_ja/#_13","title":"\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u56f3","text":"<pre><code>classDiagram\n    class Flow {\n        +run(input_data)\n        +run_sync(input_data)\n        +show()\n    }\n\n    class GenAgent {\n        +run(user_input, ctx)\n        +run_sync(user_input, ctx)\n    }\n\n    class ClarifyAgent {\n        +run(user_input, ctx)\n        +clarify_task(task)\n    }\n\n    class Context {\n        +shared_state: dict\n        +user_input: Any\n        +finish()\n    }\n\n    Flow --&gt; GenAgent\n    Flow --&gt; ClarifyAgent\n    Flow --&gt; Context\n    GenAgent --&gt; Context\n    ClarifyAgent --&gt; Context</code></pre>"},{"location":"api_reference_ja/#_14","title":"\u4f7f\u7528\u4f8b","text":""},{"location":"api_reference_ja/#_15","title":"\u57fa\u672c\u7684\u306a\u4f7f\u7528\u30d1\u30bf\u30fc\u30f3","text":"<pre><code>from refinire import create_simple_gen_agent, Flow, Context\nimport asyncio\n\n# 1. \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u4f5c\u6210\nagent = create_simple_gen_agent(\n    name=\"assistant\",\n    instructions=\"\u89aa\u5207\u306a\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u56de\u7b54\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# 2. \u30d5\u30ed\u30fc\u4f5c\u6210\nflow = Flow(steps=agent)\n\n# 3. \u5b9f\u884c\nasync def main():\n    result = await flow.run(input_data=\"\u3053\u3093\u306b\u3061\u306f\")\n    print(result.shared_state[\"assistant_result\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"api_reference_ja/#_16","title":"\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306e\u4f8b","text":"<pre><code>from refinire import Flow, FunctionStep, create_evaluated_gen_agent\nimport asyncio\n\ndef preprocess(user_input: str, ctx: Context) -&gt; Context:\n    ctx.shared_state[\"processed_input\"] = user_input.strip().lower()\n    return ctx\n\nagent = create_evaluated_gen_agent(\n    name=\"analyzer\",\n    generation_instructions=\"\u5165\u529b\u3092\u5206\u6790\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    evaluation_instructions=\"\u5206\u6790\u306e\u6b63\u78ba\u6027\u3092\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    threshold=80.0,\n    model=\"gpt-4o-mini\"\n)\n\ndef postprocess(user_input: str, ctx: Context) -&gt; Context:\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n    ctx.shared_state[\"final_result\"] = f\"\u6700\u7d42\u7d50\u679c: {result}\"\n    ctx.finish()\n    return ctx\n\nflow = Flow([\n    (\"preprocess\", FunctionStep(\"preprocess\", preprocess)),\n    (\"analyze\", agent),\n    (\"postprocess\", FunctionStep(\"postprocess\", postprocess))\n])\n\nasync def main():\n    result = await flow.run(input_data=\"  \u30c6\u30ad\u30b9\u30c8\u3092\u5206\u6790\u3057\u3066  \")\n    print(result.shared_state[\"final_result\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"api_reference_ja/#contextprovider","title":"ContextProvider\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9","text":"\u30af\u30e9\u30b9/\u30e1\u30bd\u30c3\u30c9 \u8aac\u660e \u5f15\u6570 / \u623b\u308a\u5024 <code>ContextProvider</code> \u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u62bd\u8c61\u57fa\u5e95\u30af\u30e9\u30b9\u3002 <code>provider_name</code> \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u540d\uff08\u30af\u30e9\u30b9\u5909\u6570\uff09\u3002 <code>str</code> <code>get_config_schema</code> \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u8fd4\u3059\u3002 <code>classmethod</code> \u2192 <code>Dict[str, Any]</code> <code>from_config</code> \u8a2d\u5b9a\u8f9e\u66f8\u304b\u3089\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u751f\u6210\u3002 <code>classmethod</code> \u2192 \u30a4\u30f3\u30b9\u30bf\u30f3\u30b9 <code>get_context</code> \u30af\u30a8\u30ea\u306b\u5bfe\u3059\u308b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u6587\u5b57\u5217\u3092\u8fd4\u3059\u3002 <code>query: str, previous_context: Optional[str], **kwargs</code> \u2192 <code>str</code> <code>update</code> \u65b0\u3057\u3044\u5bfe\u8a71\u3067\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u72b6\u614b\u3092\u66f4\u65b0\u3002 <code>interaction: Dict[str, Any]</code> <code>clear</code> \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u72b6\u614b\u3092\u30af\u30ea\u30a2\u3002"},{"location":"api_reference_ja/#_17","title":"\u6a19\u6e96\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc","text":""},{"location":"api_reference_ja/#conversationhistoryprovider","title":"ConversationHistoryProvider","text":"<p>\u4f1a\u8a71\u5c65\u6b74\u3092\u7ba1\u7406\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <p>\u8a2d\u5b9a\u4f8b: <pre><code>{\n    \"type\": \"conversation_history\",\n    \"max_items\": 10\n}\n</code></pre></p> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>max_items</code> (int): \u4fdd\u6301\u3059\u308b\u6700\u5927\u30e1\u30c3\u30bb\u30fc\u30b8\u6570\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: 10\uff09</p>"},{"location":"api_reference_ja/#fixedfileprovider","title":"FixedFileProvider","text":"<p>\u6307\u5b9a\u3055\u308c\u305f\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u3092\u5e38\u306b\u63d0\u4f9b\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <p>\u8a2d\u5b9a\u4f8b: <pre><code>{\n    \"type\": \"fixed_file\",\n    \"file_path\": \"config.yaml\",\n    \"encoding\": \"utf-8\",\n    \"check_updates\": True\n}\n</code></pre></p> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>file_path</code> (str, \u5fc5\u9808): \u8aad\u307f\u53d6\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9 - <code>encoding</code> (str): \u30d5\u30a1\u30a4\u30eb\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: \"utf-8\"\uff09 - <code>check_updates</code> (bool): \u30d5\u30a1\u30a4\u30eb\u66f4\u65b0\u3092\u30c1\u30a7\u30c3\u30af\u3059\u308b\u304b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: True\uff09</p>"},{"location":"api_reference_ja/#sourcecodeprovider","title":"SourceCodeProvider","text":"<p>\u30e6\u30fc\u30b6\u30fc\u306e\u8cea\u554f\u306b\u95a2\u9023\u3059\u308b\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u81ea\u52d5\u691c\u7d22\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <p>\u8a2d\u5b9a\u4f8b: <pre><code>{\n    \"type\": \"source_code\",\n    \"base_path\": \".\",\n    \"max_files\": 5,\n    \"max_file_size\": 1000,\n    \"file_extensions\": [\".py\", \".js\", \".ts\"],\n    \"include_patterns\": [\"src/**/*\"],\n    \"exclude_patterns\": [\"tests/**/*\"]\n}\n</code></pre></p> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>base_path</code> (str): \u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u5206\u6790\u306e\u30d9\u30fc\u30b9\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: \".\"\uff09 - <code>max_files</code> (int): \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u542b\u3081\u308b\u6700\u5927\u30d5\u30a1\u30a4\u30eb\u6570\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: 50\uff09 - <code>max_file_size</code> (int): \u8aad\u307f\u8fbc\u3080\u6700\u5927\u30d5\u30a1\u30a4\u30eb\u30b5\u30a4\u30ba\uff08\u30d0\u30a4\u30c8\uff09\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: 10000\uff09 - <code>file_extensions</code> (list): \u542b\u3081\u308b\u30d5\u30a1\u30a4\u30eb\u62e1\u5f35\u5b50\u306e\u30ea\u30b9\u30c8 - <code>include_patterns</code> (list): \u542b\u3081\u308b\u30d5\u30a1\u30a4\u30eb\u30d1\u30bf\u30fc\u30f3\u306e\u30ea\u30b9\u30c8 - <code>exclude_patterns</code> (list): \u9664\u5916\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u30d1\u30bf\u30fc\u30f3\u306e\u30ea\u30b9\u30c8</p>"},{"location":"api_reference_ja/#cutcontextprovider","title":"CutContextProvider","text":"<p>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u5727\u7e2e\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <p>\u8a2d\u5b9a\u4f8b: <pre><code>{\n    \"type\": \"cut_context\",\n    \"provider\": {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    \"max_chars\": 3000,\n    \"max_tokens\": None,\n    \"cut_strategy\": \"middle\",\n    \"preserve_sections\": True\n}\n</code></pre></p> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>provider</code> (dict, \u5fc5\u9808): \u30e9\u30c3\u30d7\u3059\u308b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a - <code>max_chars</code> (int): \u6700\u5927\u6587\u5b57\u6570\uff08None\u3067\u5236\u9650\u306a\u3057\uff09 - <code>max_tokens</code> (int): \u6700\u5927\u30c8\u30fc\u30af\u30f3\u6570\uff08None\u3067\u5236\u9650\u306a\u3057\uff09 - <code>cut_strategy</code> (str): \u30ab\u30c3\u30c8\u6226\u7565\uff08\"start\", \"end\", \"middle\"\uff09\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: \"end\"\uff09 - <code>preserve_sections</code> (bool): \u30ab\u30c3\u30c8\u6642\u306b\u5b8c\u5168\u306a\u30bb\u30af\u30b7\u30e7\u30f3\u3092\u4fdd\u6301\u3059\u308b\u304b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: True\uff09</p>"},{"location":"api_reference_ja/#refinireagent","title":"RefinireAgent\u62e1\u5f35","text":"\u30af\u30e9\u30b9/\u30e1\u30bd\u30c3\u30c9 \u8aac\u660e \u5f15\u6570 / \u623b\u308a\u5024 <code>context_providers_config</code> \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u8a2d\u5b9a\uff08\u30ea\u30b9\u30c8/\u8f9e\u66f8/YAML\u6587\u5b57\u5217\uff09\u3002 <code>List[dict]</code>/<code>str</code> <code>get_context_provider_schemas</code> \u5229\u7528\u53ef\u80fd\u306a\u5168\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b9\u30ad\u30fc\u30de\u3092\u8fd4\u3059\u3002 <code>classmethod</code> \u2192 <code>Dict[str, Any]</code> <code>clear_context</code> \u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u30af\u30ea\u30a2\u3002"},{"location":"api_reference_ja/#sourcecodeprovider_1","title":"\u4f7f\u7528\u4f8b: SourceCodeProvider\u306e\u5229\u7528","text":"<pre><code>from refinire.agents.context_provider_factory import ContextProviderFactory\n\nconfig = {\n    \"type\": \"source_code\",\n    \"base_path\": \"src\",\n    \"max_files\": 5\n}\nprovider = ContextProviderFactory.create_provider(config)\ncontext = provider.get_context(\"\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u4ed5\u7d44\u307f\u306f\uff1f\")\nprint(context)\n</code></pre>"},{"location":"api_reference_ja/#yaml","title":"\u4f7f\u7528\u4f8b: YAML\u30e9\u30a4\u30af\u306a\u8907\u6570\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc","text":"<pre><code>- conversation_history:\n    max_items: 5\n- source_code:\n    base_path: src\n    max_files: 3\n- cut_context:\n    provider:\n      type: conversation_history\n      max_items: 10\n    max_chars: 4000\n    cut_strategy: end\n</code></pre>"},{"location":"api_reference_ja/#_18","title":"\u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li><code>docs/api_reference.md</code>\uff08\u82f1\u8a9e\uff09</li> <li><code>docs/context_management.md</code>\uff08\u8a2d\u8a08\uff09</li> <li><code>examples/context_management_example.py</code>\uff08\u4f7f\u7528\u4f8b\uff09 </li> </ul>"},{"location":"architecture/","title":"\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u8a2d\u8a08\u66f8","text":""},{"location":"architecture/#_2","title":"\u30b7\u30b9\u30c6\u30e0\u69cb\u6210\u30fb\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u6982\u8981","text":"<p>\u672c\u30b7\u30b9\u30c6\u30e0\u306f\u30ec\u30a4\u30e4\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u63a1\u7528\u3057\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u69cb\u6210\u3068\u306a\u3063\u3066\u3044\u307e\u3059\u3002</p> <ul> <li>UI/\u5229\u7528\u4f8b\u5c64\uff08examples/\uff09</li> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u5c64\uff08AgentPipeline\u30af\u30e9\u30b9\uff09</li> <li>\u6a5f\u80fd\u30af\u30e9\u30b9\u5c64\uff08\u30c4\u30fc\u30eb\u95a2\u6570\u3001\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u95a2\u6570\u3001\u8a55\u4fa1\u95a2\u6570\u306a\u3069\uff09</li> <li>\u30c7\u30fc\u30bf\u30af\u30e9\u30b9\u5c64\uff08pydantic\u30e2\u30c7\u30eb\u3001dataclass\u7b49\uff09</li> <li>\u30b2\u30fc\u30c8\u30a6\u30a7\u30a4\u5c64\uff08get_llm\u7b49\u306e\u30e2\u30c7\u30eb\u53d6\u5f97\uff09</li> <li>\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u5c64\uff08\u8a2d\u5b9a\u3001\u30ed\u30b0\u7b49\uff09</li> </ul>"},{"location":"architecture/#_3","title":"\u4e3b\u8981\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9","text":"\u30af\u30e9\u30b9\u540d \u5f79\u5272 \u30ec\u30a4\u30e4\u30fc AgentPipeline \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7d71\u5408\u30fb\u5b9f\u884c \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9 Agent LLM\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u6a5f\u80fd/\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9 function_tool\u3067\u5b9a\u7fa9\u3057\u305f\u95a2\u6570 \u30c4\u30fc\u30eb\u3068\u3057\u3066\u5229\u7528 \u6a5f\u80fd input_guardrail\u3067\u5b9a\u7fa9\u3057\u305f\u95a2\u6570 \u5165\u529b\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb \u6a5f\u80fd get_llm \u30e2\u30c7\u30eb\u53d6\u5f97 \u30b2\u30fc\u30c8\u30a6\u30a7\u30a4 pydantic.BaseModel \u69cb\u9020\u5316\u51fa\u529b \u30c7\u30fc\u30bf"},{"location":"architecture/#_4","title":"\u4e3b\u8981\u30c7\u30fc\u30bf\uff08\u30c7\u30fc\u30bf\u306e\u7a2e\u985e\u3001\u69cb\u9020\uff09","text":"\u30af\u30e9\u30b9\u540d \u4fdd\u6301\u30c7\u30fc\u30bf EvaluationResult score, comment MathHomeworkOutput is_math_homework, reasoning"},{"location":"architecture/#erplantuml","title":"ER\u56f3\uff08PlantUML\uff09","text":"<pre><code>@startuml\nclass AgentPipeline {\n  - name\n  - generation_instructions\n  - evaluation_instructions\n  - ...\n}\nclass Agent {\n  - name\n  - model\n  - instructions\n  - ...\n}\nclass EvaluationResult {\n  score: int\n  comment: List~str~\n}\nclass MathHomeworkOutput {\n  is_math_homework: bool\n  reasoning: str\n}\nAgentPipeline --&gt; Agent\nAgent --&gt; EvaluationResult\nAgent --&gt; MathHomeworkOutput\n@enduml\n</code></pre>"},{"location":"architecture/#_5","title":"\u53c2\u8003","text":"<ul> <li>\u8a73\u7d30\u306a\u4e8b\u4f8b\u30fb\u4f7f\u3044\u65b9\u306f docs/pipeline_examples.md \u3092\u53c2\u7167\u3002 </li> </ul>"},{"location":"autonomous-quality-assurance_ja/","title":"Autonomous Quality Assurance - \u81ea\u5f8b\u54c1\u8cea\u4fdd\u8a3c","text":"<p>Refinire\u306e\u7b2c\u4e8c\u306e\u67f1\u3067\u3042\u308b\u81ea\u5f8b\u54c1\u8cea\u4fdd\u8a3c\u306f\u3001AI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u51fa\u529b\u54c1\u8cea\u3092\u81ea\u52d5\u7684\u306b\u8a55\u4fa1\u3057\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u518d\u751f\u6210\u3092\u884c\u3046\u9769\u65b0\u7684\u306a\u30b7\u30b9\u30c6\u30e0\u3067\u3059\u3002</p>"},{"location":"autonomous-quality-assurance_ja/#_1","title":"\u57fa\u672c\u6982\u5ff5","text":"<p>\u5f93\u6765\u306e\u624b\u52d5\u54c1\u8cea\u7ba1\u7406\u304b\u3089\u8131\u5374\u3057\u3001AI\u304c\u81ea\u3089\u306e\u51fa\u529b\u3092\u8a55\u4fa1\u30fb\u6539\u5584\u3059\u308b\u81ea\u5f8b\u7684\u306a\u54c1\u8cea\u4fdd\u8a3c\u30e1\u30ab\u30cb\u30ba\u30e0\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p> <pre><code>from refinire import create_evaluated_gen_agent, Context\nimport asyncio\n\n# \u54c1\u8cea\u8a55\u4fa1\u4ed8\u304d\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\nagent = create_evaluated_gen_agent(\n    name=\"quality_assistant\",\n    generation_instructions=\"\u5f79\u7acb\u3064\u56de\u7b54\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\",\n    evaluation_instructions=\"\u6b63\u78ba\u6027\u3068\u6709\u7528\u6027\u3092\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\",\n    threshold=85.0,  # 85\u70b9\u4ee5\u4e0a\u3092\u8981\u6c42\n    model=\"gpt-4o-mini\"\n)\n\n# \u81ea\u52d5\u54c1\u8cea\u7ba1\u7406\nresult = asyncio.run(agent.run(\"\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u3092\u8aac\u660e\u3057\u3066\", Context()))\n</code></pre>"},{"location":"autonomous-quality-assurance_ja/#_2","title":"\u7c21\u5358\u306a\u4e8b\u4f8b","text":""},{"location":"autonomous-quality-assurance_ja/#1","title":"1. \u57fa\u672c\u7684\u306a\u54c1\u8cea\u8a55\u4fa1","text":"<pre><code>from refinire import create_evaluated_gen_agent, Context\n\n# \u54c1\u8cea\u3057\u304d\u3044\u5024\u3092\u8a2d\u5b9a\u3057\u305f\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\nagent = create_evaluated_gen_agent(\n    name=\"qa_agent\",\n    generation_instructions=\"\u8a73\u7d30\u3067\u6b63\u78ba\u306a\u56de\u7b54\u3092\u3057\u3066\u304f\u3060\u3055\u3044\",\n    evaluation_instructions=\"\u56de\u7b54\u306e\u6b63\u78ba\u6027\u30921-100\u3067\u8a55\u4fa1\",\n    threshold=80.0,\n    model=\"gpt-4o-mini\"\n)\n\n# \u81ea\u52d5\u8a55\u4fa1\u4ed8\u304d\u5b9f\u884c\nresult = agent.run_sync(\"\u5730\u7403\u6e29\u6696\u5316\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u3066\u304f\u3060\u3055\u3044\", Context())\nprint(f\"\u56de\u7b54: {result.shared_state['qa_agent_result']}\")\n</code></pre>"},{"location":"autonomous-quality-assurance_ja/#2","title":"2. \u54c1\u8cea\u57fa\u6e96\u306e\u30ab\u30b9\u30bf\u30de\u30a4\u30ba","text":"<pre><code># \u3088\u308a\u53b3\u3057\u3044\u8a55\u4fa1\u57fa\u6e96\nstrict_agent = create_evaluated_gen_agent(\n    name=\"strict_agent\",\n    generation_instructions=\"\u79d1\u5b66\u7684\u306b\u6b63\u78ba\u3067\u8a73\u7d30\u306a\u56de\u7b54\u3092\u3057\u3066\u304f\u3060\u3055\u3044\",\n    evaluation_instructions=\"\"\"\n    \u4ee5\u4e0b\u306e\u57fa\u6e96\u3067\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044:\n    - \u79d1\u5b66\u7684\u6b63\u78ba\u6027 (30\u70b9)\n    - \u8a73\u7d30\u5ea6 (25\u70b9)  \n    - \u7406\u89e3\u3057\u3084\u3059\u3055 (25\u70b9)\n    - \u5b8c\u5168\u6027 (20\u70b9)\n    \u5408\u8a08100\u70b9\u6e80\u70b9\u3067\u8a55\u4fa1\n    \"\"\",\n    threshold=90.0,  # 90\u70b9\u4ee5\u4e0a\u8981\u6c42\n    max_retries=3,   # \u6700\u59273\u56de\u518d\u8a66\u884c\n    model=\"gpt-4o\"\n)\n</code></pre>"},{"location":"autonomous-quality-assurance_ja/#_3","title":"\u4e2d\u7d1a\u4e8b\u4f8b","text":""},{"location":"autonomous-quality-assurance_ja/#3","title":"3. \u30c9\u30e1\u30a4\u30f3\u7279\u5316\u54c1\u8cea\u8a55\u4fa1","text":"<pre><code>class MedicalQAAgent:\n    \"\"\"\u533b\u7642\u60c5\u5831\u5c02\u7528\u306e\u54c1\u8cea\u4fdd\u8a3c\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\"\"\"\n\n    def __init__(self):\n        self.agent = create_evaluated_gen_agent(\n            name=\"medical_qa\",\n            generation_instructions=\"\"\"\n            \u533b\u7642\u60c5\u5831\u306b\u3064\u3044\u3066\u6b63\u78ba\u3067\u8cac\u4efb\u3042\u308b\u56de\u7b54\u3092\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n            \u5fc5\u305a\u4ee5\u4e0b\u3092\u542b\u3081\u3066\u304f\u3060\u3055\u3044:\n            1. \u79d1\u5b66\u7684\u6839\u62e0\n            2. \u9069\u7528\u7bc4\u56f2\u3068\u5236\u9650\n            3. \u5c02\u9580\u533b\u3078\u306e\u76f8\u8ac7\u63a8\u5968\n            \"\"\",\n            evaluation_instructions=\"\"\"\n            \u533b\u7642\u60c5\u5831\u306e\u54c1\u8cea\u3092\u4ee5\u4e0b\u3067\u8a55\u4fa1:\n            - \u533b\u5b66\u7684\u6b63\u78ba\u6027 (40\u70b9)\n            - \u5b89\u5168\u6027\u3078\u306e\u914d\u616e (30\u70b9)\n            - \u5c02\u9580\u533b\u76f8\u8ac7\u306e\u63a8\u5968 (20\u70b9)\n            - \u60c5\u5831\u306e\u5b8c\u5168\u6027 (10\u70b9)\n            \"\"\",\n            threshold=95.0,  # \u533b\u7642\u60c5\u5831\u306f\u9ad8\u3044\u57fa\u6e96\n            max_retries=5,\n            model=\"gpt-4o\"\n        )\n\n    def get_medical_info(self, question: str) -&gt; str:\n        result = self.agent.run_sync(question, Context())\n        return result.shared_state[\"medical_qa_result\"]\n\n# \u4f7f\u7528\u4f8b\nmedical_agent = MedicalQAAgent()\nresponse = medical_agent.get_medical_info(\"\u9ad8\u8840\u5727\u306e\u6cbb\u7642\u6cd5\u306b\u3064\u3044\u3066\u6559\u3048\u3066\u304f\u3060\u3055\u3044\")\n</code></pre>"},{"location":"autonomous-quality-assurance_ja/#4","title":"4. \u591a\u5c64\u54c1\u8cea\u8a55\u4fa1\u30b7\u30b9\u30c6\u30e0","text":"<pre><code>class MultiLayerQualitySystem:\n    \"\"\"\u591a\u5c64\u69cb\u9020\u306e\u54c1\u8cea\u8a55\u4fa1\u30b7\u30b9\u30c6\u30e0\"\"\"\n\n    def __init__(self):\n        # \u57fa\u672c\u54c1\u8cea\u30c1\u30a7\u30c3\u30af\n        self.basic_agent = create_evaluated_gen_agent(\n            name=\"basic_check\",\n            generation_instructions=\"\u57fa\u672c\u7684\u306a\u56de\u7b54\u3092\u3057\u3066\u304f\u3060\u3055\u3044\",\n            evaluation_instructions=\"\u57fa\u672c\u7684\u306a\u6b63\u78ba\u6027\u3092\u8a55\u4fa1\",\n            threshold=70.0,\n            model=\"gpt-4o-mini\"\n        )\n\n        # \u8a73\u7d30\u54c1\u8cea\u30c1\u30a7\u30c3\u30af\n        self.detail_agent = create_evaluated_gen_agent(\n            name=\"detail_check\", \n            generation_instructions=\"\u8a73\u7d30\u3067\u9ad8\u54c1\u8cea\u306a\u56de\u7b54\u3092\u3057\u3066\u304f\u3060\u3055\u3044\",\n            evaluation_instructions=\"\"\"\n            \u8a73\u7d30\u54c1\u8cea\u3092\u8a55\u4fa1:\n            - \u5185\u5bb9\u306e\u6df1\u3055 (30\u70b9)\n            - \u8ad6\u7406\u7684\u4e00\u8cab\u6027 (25\u70b9)\n            - \u5b9f\u7528\u6027 (25\u70b9)\n            - \u72ec\u5275\u6027 (20\u70b9)\n            \"\"\",\n            threshold=85.0,\n            model=\"gpt-4o\"\n        )\n\n        # \u6700\u7d42\u54c1\u8cea\u30c1\u30a7\u30c3\u30af\n        self.expert_agent = create_evaluated_gen_agent(\n            name=\"expert_check\",\n            generation_instructions=\"\u5c02\u9580\u5bb6\u30ec\u30d9\u30eb\u306e\u56de\u7b54\u3092\u3057\u3066\u304f\u3060\u3055\u3044\",\n            evaluation_instructions=\"\"\"\n            \u5c02\u9580\u5bb6\u30ec\u30d9\u30eb\u306e\u54c1\u8cea\u8a55\u4fa1:\n            - \u5c02\u9580\u77e5\u8b58\u306e\u6b63\u78ba\u6027 (35\u70b9)\n            - \u6700\u65b0\u6027 (25\u70b9)\n            - \u5305\u62ec\u6027 (25\u70b9) \n            - \u5f15\u7528\u30fb\u6839\u62e0 (15\u70b9)\n            \"\"\",\n            threshold=92.0,\n            model=\"gpt-4o\"\n        )\n\n    def get_quality_response(self, question: str, quality_level: str = \"basic\"):\n        \"\"\"\u54c1\u8cea\u30ec\u30d9\u30eb\u306b\u5fdc\u3058\u305f\u56de\u7b54\u751f\u6210\"\"\"\n        context = Context()\n\n        if quality_level == \"basic\":\n            result = self.basic_agent.run_sync(question, context)\n            return result.shared_state[\"basic_check_result\"]\n        elif quality_level == \"detail\":\n            result = self.detail_agent.run_sync(question, context)\n            return result.shared_state[\"detail_check_result\"]\n        elif quality_level == \"expert\":\n            result = self.expert_agent.run_sync(question, context)\n            return result.shared_state[\"expert_check_result\"]\n        else:\n            raise ValueError(\"Invalid quality level\")\n\n# \u4f7f\u7528\u4f8b\nquality_system = MultiLayerQualitySystem()\n\n# \u30ec\u30d9\u30eb\u5225\u56de\u7b54\u53d6\u5f97\nbasic_answer = quality_system.get_quality_response(\"AI\u3068\u306f\u4f55\u3067\u3059\u304b\uff1f\", \"basic\")\nexpert_answer = quality_system.get_quality_response(\"AI\u3068\u306f\u4f55\u3067\u3059\u304b\uff1f\", \"expert\")\n</code></pre>"},{"location":"autonomous-quality-assurance_ja/#_4","title":"\u9ad8\u5ea6\u306a\u4e8b\u4f8b","text":""},{"location":"autonomous-quality-assurance_ja/#5","title":"5. \u81ea\u9069\u5fdc\u54c1\u8cea\u5b66\u7fd2\u30b7\u30b9\u30c6\u30e0","text":"<pre><code>import json\nfrom datetime import datetime\nfrom typing import Dict, List\n\nclass AdaptiveQualitySystem:\n    \"\"\"\u30e6\u30fc\u30b6\u30fc\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u304b\u3089\u5b66\u7fd2\u3059\u308b\u81ea\u9069\u5fdc\u54c1\u8cea\u30b7\u30b9\u30c6\u30e0\"\"\"\n\n    def __init__(self):\n        self.feedback_history = []\n        self.quality_metrics = {\n            \"accuracy\": 0.8,\n            \"relevance\": 0.8, \n            \"completeness\": 0.8,\n            \"clarity\": 0.8\n        }\n\n        self.agent = create_evaluated_gen_agent(\n            name=\"adaptive_agent\",\n            generation_instructions=self._generate_dynamic_instructions(),\n            evaluation_instructions=self._generate_dynamic_evaluation(),\n            threshold=self._calculate_dynamic_threshold(),\n            model=\"gpt-4o\"\n        )\n\n    def _generate_dynamic_instructions(self) -&gt; str:\n        \"\"\"\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u306b\u57fa\u3065\u3044\u3066\u52d5\u7684\u306b\u751f\u6210\u6307\u793a\u3092\u8abf\u6574\"\"\"\n        base_instructions = \"\u9ad8\u54c1\u8cea\u306a\u56de\u7b54\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\"\n\n        # \u7cbe\u5ea6\u304c\u4f4e\u3044\u5834\u5408\n        if self.quality_metrics[\"accuracy\"] &lt; 0.7:\n            base_instructions += \" \u7279\u306b\u6b63\u78ba\u6027\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\"\n\n        # \u95a2\u9023\u6027\u304c\u4f4e\u3044\u5834\u5408\n        if self.quality_metrics[\"relevance\"] &lt; 0.7:\n            base_instructions += \" \u8cea\u554f\u306b\u76f4\u63a5\u95a2\u9023\u3059\u308b\u5185\u5bb9\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u304f\u3060\u3055\u3044\u3002\"\n\n        # \u5b8c\u5168\u6027\u304c\u4f4e\u3044\u5834\u5408\n        if self.quality_metrics[\"completeness\"] &lt; 0.7:\n            base_instructions += \" \u5305\u62ec\u7684\u3067\u5b8c\u5168\u306a\u56de\u7b54\u3092\u5fc3\u304c\u3051\u3066\u304f\u3060\u3055\u3044\u3002\"\n\n        # \u660e\u78ba\u6027\u304c\u4f4e\u3044\u5834\u5408\n        if self.quality_metrics[\"clarity\"] &lt; 0.7:\n            base_instructions += \" \u660e\u78ba\u3067\u5206\u304b\u308a\u3084\u3059\u3044\u8868\u73fe\u3092\u4f7f\u3063\u3066\u304f\u3060\u3055\u3044\u3002\"\n\n        return base_instructions\n\n    def _generate_dynamic_evaluation(self) -&gt; str:\n        \"\"\"\u52d5\u7684\u8a55\u4fa1\u57fa\u6e96\u306e\u751f\u6210\"\"\"\n        weights = {\n            \"accuracy\": max(20, int(30 * (1 + (0.8 - self.quality_metrics[\"accuracy\"])))),\n            \"relevance\": max(20, int(25 * (1 + (0.8 - self.quality_metrics[\"relevance\"])))),\n            \"completeness\": max(15, int(25 * (1 + (0.8 - self.quality_metrics[\"completeness\"])))),\n            \"clarity\": max(15, int(20 * (1 + (0.8 - self.quality_metrics[\"clarity\"]))))\n        }\n\n        return f\"\"\"\n        \u4ee5\u4e0b\u306e\u57fa\u6e96\u3067\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044:\n        - \u6b63\u78ba\u6027 ({weights[\"accuracy\"]}\u70b9)\n        - \u95a2\u9023\u6027 ({weights[\"relevance\"]}\u70b9)\n        - \u5b8c\u5168\u6027 ({weights[\"completeness\"]}\u70b9)\n        - \u660e\u78ba\u6027 ({weights[\"clarity\"]}\u70b9)\n        \u5408\u8a08100\u70b9\u6e80\u70b9\n        \"\"\"\n\n    def _calculate_dynamic_threshold(self) -&gt; float:\n        \"\"\"\u52d5\u7684\u3057\u304d\u3044\u5024\u8a08\u7b97\"\"\"\n        avg_quality = sum(self.quality_metrics.values()) / len(self.quality_metrics)\n        # \u5e73\u5747\u54c1\u8cea\u304c\u4f4e\u3044\u5834\u5408\u306f\u3057\u304d\u3044\u5024\u3092\u4e0b\u3052\u3066\u6539\u5584\u6a5f\u4f1a\u3092\u5897\u3084\u3059\n        if avg_quality &lt; 0.7:\n            return 75.0\n        elif avg_quality &gt; 0.9:\n            return 90.0\n        else:\n            return 80.0\n\n    def process_feedback(self, question: str, response: str, user_rating: int, \n                        feedback_details: Dict[str, int]):\n        \"\"\"\u30e6\u30fc\u30b6\u30fc\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u3092\u51e6\u7406\u3057\u3066\u5b66\u7fd2\"\"\"\n        # \u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u8a18\u9332\n        feedback_entry = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"question\": question,\n            \"response\": response,\n            \"user_rating\": user_rating,\n            \"details\": feedback_details\n        }\n        self.feedback_history.append(feedback_entry)\n\n        # \u54c1\u8cea\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u66f4\u65b0\uff08\u79fb\u52d5\u5e73\u5747\uff09\n        alpha = 0.1  # \u5b66\u7fd2\u7387\n        for metric, score in feedback_details.items():\n            if metric in self.quality_metrics:\n                normalized_score = score / 100.0\n                self.quality_metrics[metric] = (\n                    (1 - alpha) * self.quality_metrics[metric] + \n                    alpha * normalized_score\n                )\n\n        # \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8a2d\u5b9a\u306e\u66f4\u65b0\n        self.agent = create_evaluated_gen_agent(\n            name=\"adaptive_agent\",\n            generation_instructions=self._generate_dynamic_instructions(),\n            evaluation_instructions=self._generate_dynamic_evaluation(),\n            threshold=self._calculate_dynamic_threshold(),\n            model=\"gpt-4o\"\n        )\n\n    def get_adaptive_response(self, question: str) -&gt; tuple[str, Dict]:\n        \"\"\"\u81ea\u9069\u5fdc\u56de\u7b54\u751f\u6210\"\"\"\n        result = self.agent.run_sync(question, Context())\n        response = result.shared_state[\"adaptive_agent_result\"]\n\n        # \u73fe\u5728\u306e\u54c1\u8cea\u8a2d\u5b9a\u3092\u8fd4\u3059\n        current_settings = {\n            \"threshold\": self._calculate_dynamic_threshold(),\n            \"quality_metrics\": self.quality_metrics.copy(),\n            \"feedback_count\": len(self.feedback_history)\n        }\n\n        return response, current_settings\n\n# \u4f7f\u7528\u4f8b\nadaptive_system = AdaptiveQualitySystem()\n\n# \u521d\u56de\u56de\u7b54\nresponse1, settings1 = adaptive_system.get_adaptive_response(\"\u6a5f\u68b0\u5b66\u7fd2\u3068\u306f\u4f55\u3067\u3059\u304b\uff1f\")\nprint(f\"\u56de\u7b54: {response1}\")\nprint(f\"\u8a2d\u5b9a: {settings1}\")\n\n# \u30e6\u30fc\u30b6\u30fc\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\uff08\u4f4e\u8a55\u4fa1\uff09\nadaptive_system.process_feedback(\n    \"\u6a5f\u68b0\u5b66\u7fd2\u3068\u306f\u4f55\u3067\u3059\u304b\uff1f\",\n    response1,\n    3,  # 5\u6bb5\u968e\u8a55\u4fa1\u30673\n    {\n        \"accuracy\": 60,\n        \"relevance\": 70,\n        \"completeness\": 50,\n        \"clarity\": 80\n    }\n)\n\n# \u5b66\u7fd2\u5f8c\u306e\u56de\u7b54\uff08\u6539\u5584\u3055\u308c\u305f\u306f\u305a\uff09\nresponse2, settings2 = adaptive_system.get_adaptive_response(\"\u6a5f\u68b0\u5b66\u7fd2\u3068\u306f\u4f55\u3067\u3059\u304b\uff1f\")\nprint(f\"\\n\u5b66\u7fd2\u5f8c\u56de\u7b54: {response2}\")\nprint(f\"\u66f4\u65b0\u8a2d\u5b9a: {settings2}\")\n</code></pre>"},{"location":"autonomous-quality-assurance_ja/#6","title":"6. \u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u54c1\u8cea\u76e3\u8996\u30b7\u30b9\u30c6\u30e0","text":"<pre><code>import threading\nimport time\nfrom collections import deque\nfrom typing import Optional\n\nclass RealTimeQualityMonitor:\n    \"\"\"\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u54c1\u8cea\u76e3\u8996\u30b7\u30b9\u30c6\u30e0\"\"\"\n\n    def __init__(self, window_size: int = 10):\n        self.window_size = window_size\n        self.quality_scores = deque(maxlen=window_size)\n        self.monitoring_active = False\n        self.monitor_thread: Optional[threading.Thread] = None\n        self.quality_alerts = []\n\n        self.agent = create_evaluated_gen_agent(\n            name=\"monitored_agent\",\n            generation_instructions=\"\u76e3\u8996\u4e0b\u3067\u306e\u9ad8\u54c1\u8cea\u56de\u7b54\u3092\u751f\u6210\",\n            evaluation_instructions=\"\u54c1\u8cea\u3092\u53b3\u683c\u306b\u8a55\u4fa1\",\n            threshold=80.0,\n            model=\"gpt-4o-mini\"\n        )\n\n    def start_monitoring(self):\n        \"\"\"\u54c1\u8cea\u76e3\u8996\u958b\u59cb\"\"\"\n        self.monitoring_active = True\n        self.monitor_thread = threading.Thread(target=self._monitor_loop)\n        self.monitor_thread.daemon = True\n        self.monitor_thread.start()\n        print(\"\u54c1\u8cea\u76e3\u8996\u958b\u59cb\")\n\n    def stop_monitoring(self):\n        \"\"\"\u54c1\u8cea\u76e3\u8996\u505c\u6b62\"\"\"\n        self.monitoring_active = False\n        if self.monitor_thread:\n            self.monitor_thread.join()\n        print(\"\u54c1\u8cea\u76e3\u8996\u505c\u6b62\")\n\n    def _monitor_loop(self):\n        \"\"\"\u76e3\u8996\u30eb\u30fc\u30d7\"\"\"\n        while self.monitoring_active:\n            if len(self.quality_scores) &gt;= 3:\n                avg_quality = sum(self.quality_scores) / len(self.quality_scores)\n\n                # \u54c1\u8cea\u4f4e\u4e0b\u30a2\u30e9\u30fc\u30c8\n                if avg_quality &lt; 70:\n                    alert = {\n                        \"timestamp\": datetime.now().isoformat(),\n                        \"type\": \"QUALITY_DROP\",\n                        \"avg_score\": avg_quality,\n                        \"recent_scores\": list(self.quality_scores)\n                    }\n                    self.quality_alerts.append(alert)\n                    print(f\"\u26a0\ufe0f \u54c1\u8cea\u4f4e\u4e0b\u30a2\u30e9\u30fc\u30c8: \u5e73\u5747\u30b9\u30b3\u30a2 {avg_quality:.1f}\")\n\n                # \u54c1\u8cea\u5411\u4e0a\u901a\u77e5\n                elif avg_quality &gt; 90:\n                    print(f\"\u2705 \u9ad8\u54c1\u8cea\u7dad\u6301: \u5e73\u5747\u30b9\u30b3\u30a2 {avg_quality:.1f}\")\n\n            time.sleep(5)  # 5\u79d2\u9593\u9694\u3067\u76e3\u8996\n\n    def get_monitored_response(self, question: str) -&gt; str:\n        \"\"\"\u76e3\u8996\u4ed8\u304d\u56de\u7b54\u751f\u6210\"\"\"\n        result = self.agent.run_sync(question, Context())\n        response = result.shared_state[\"monitored_agent_result\"]\n\n        # \u54c1\u8cea\u30b9\u30b3\u30a2\u3092\u8a18\u9332\uff08\u5b9f\u969b\u306e\u5b9f\u88c5\u3067\u306f\u8a55\u4fa1\u30b9\u30b3\u30a2\u3092\u53d6\u5f97\uff09\n        # \u3053\u3053\u3067\u306f\u7c21\u6613\u7684\u306b\u30e9\u30f3\u30c0\u30e0\u306a\u30b9\u30b3\u30a2\u3092\u4f7f\u7528\n        import random\n        quality_score = random.uniform(60, 95)\n        self.quality_scores.append(quality_score)\n\n        print(f\"\u54c1\u8cea\u30b9\u30b3\u30a2: {quality_score:.1f}\")\n        return response\n\n    def get_quality_report(self) -&gt; Dict:\n        \"\"\"\u54c1\u8cea\u30ec\u30dd\u30fc\u30c8\u751f\u6210\"\"\"\n        if not self.quality_scores:\n            return {\"message\": \"\u30c7\u30fc\u30bf\u4e0d\u8db3\"}\n\n        scores = list(self.quality_scores)\n        return {\n            \"average_quality\": sum(scores) / len(scores),\n            \"min_quality\": min(scores),\n            \"max_quality\": max(scores),\n            \"recent_scores\": scores,\n            \"total_alerts\": len(self.quality_alerts),\n            \"trend\": \"improving\" if len(scores) &gt;= 2 and scores[-1] &gt; scores[0] else \"declining\"\n        }\n\n# \u4f7f\u7528\u4f8b\nmonitor = RealTimeQualityMonitor()\nmonitor.start_monitoring()\n\n# \u8907\u6570\u306e\u8cea\u554f\u3067\u54c1\u8cea\u76e3\u8996\nquestions = [\n    \"AI\u306e\u6b74\u53f2\u306b\u3064\u3044\u3066\u6559\u3048\u3066\u304f\u3060\u3055\u3044\",\n    \"\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u306e\u5fdc\u7528\u306f\uff1f\",\n    \"\u6c17\u5019\u5909\u52d5\u5bfe\u7b56\u306b\u3064\u3044\u3066\",\n    \"\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u306e\u9078\u3073\u65b9\"\n]\n\nfor question in questions:\n    response = monitor.get_monitored_response(question)\n    print(f\"Q: {question}\")\n    print(f\"A: {response[:100]}...\")\n    print(\"-\" * 50)\n    time.sleep(2)\n\n# \u54c1\u8cea\u30ec\u30dd\u30fc\u30c8\u78ba\u8a8d\nreport = monitor.get_quality_report()\nprint(f\"\\n\u54c1\u8cea\u30ec\u30dd\u30fc\u30c8: {report}\")\n\nmonitor.stop_monitoring()\n</code></pre>"},{"location":"autonomous-quality-assurance_ja/#_5","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u81ea\u52d5\u54c1\u8cea\u7ba1\u7406: \u4eba\u624b\u306b\u3088\u308b\u54c1\u8cea\u30c1\u30a7\u30c3\u30af\u304c\u4e0d\u8981</li> <li>\u4e00\u8cab\u3057\u305f\u54c1\u8cea: \u8a2d\u5b9a\u3057\u305f\u57fa\u6e96\u3092\u81ea\u52d5\u7684\u306b\u7dad\u6301</li> <li>\u7d99\u7d9a\u7684\u6539\u5584: \u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u306b\u3088\u308b\u81ea\u52d5\u5b66\u7fd2</li> <li>\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u76e3\u8996: \u54c1\u8cea\u4f4e\u4e0b\u306e\u5373\u5ea7\u306a\u691c\u51fa</li> </ul> <p>\u81ea\u5f8b\u54c1\u8cea\u4fdd\u8a3c\u306b\u3088\u308a\u3001\u958b\u767a\u8005\u306f\u54c1\u8cea\u7ba1\u7406\u306e\u8ca0\u62c5\u304b\u3089\u89e3\u653e\u3055\u308c\u3001\u3088\u308a\u5275\u9020\u7684\u306a\u958b\u767a\u306b\u96c6\u4e2d\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"composable-flow-architecture/","title":"Composable Flow Architecture - \u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":"<p>Refinire\u306e\u7b2c\u4e09\u306e\u67f1\u3067\u3042\u308b\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306f\u3001\u8907\u96d1\u306aAI\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u67d4\u8edf\u3067\u518d\u5229\u7528\u53ef\u80fd\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304b\u3089\u69cb\u7bc9\u3067\u304d\u308b\u9769\u65b0\u7684\u306a\u30b7\u30b9\u30c6\u30e0\u3067\u3059\u3002</p>"},{"location":"composable-flow-architecture/#_1","title":"\u57fa\u672c\u6982\u5ff5","text":"<p>\u5f93\u6765\u306e\u7dda\u5f62\u51e6\u7406\u304b\u3089\u8131\u5374\u3057\u3001\u6761\u4ef6\u5206\u5c90\u3001\u30eb\u30fc\u30d7\u3001\u4e26\u5217\u51e6\u7406\u3092\u542b\u3080\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u76f4\u611f\u7684\u306b\u5b9a\u7fa9\u30fb\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from refinire import Flow, FunctionStep, Context\nimport asyncio\n\n# \u30b7\u30f3\u30d7\u30eb\u306a\u30d5\u30ed\u30fc\u5b9a\u7fa9\ndef analyze_input(user_input, ctx):\n    ctx.shared_state[\"analysis\"] = f\"\u5206\u6790\u6e08\u307f: {user_input}\"\n    return ctx\n\ndef generate_response(user_input, ctx):\n    analysis = ctx.shared_state[\"analysis\"]\n    ctx.shared_state[\"response\"] = f\"{analysis}\u306b\u57fa\u3065\u304f\u56de\u7b54\"\n    ctx.finish()\n    return ctx\n\n# \u30d5\u30ed\u30fc\u69cb\u7bc9\nflow = Flow([\n    (\"analyze\", FunctionStep(\"analyze\", analyze_input)),\n    (\"respond\", FunctionStep(\"respond\", generate_response))\n])\n\n# \u5b9f\u884c\nresult = asyncio.run(flow.run(input_data=\"\u30e6\u30fc\u30b6\u30fc\u30ea\u30af\u30a8\u30b9\u30c8\"))\n</code></pre>"},{"location":"composable-flow-architecture/#_2","title":"\u7c21\u5358\u306a\u4e8b\u4f8b","text":""},{"location":"composable-flow-architecture/#1","title":"1. \u57fa\u672c\u7684\u306a\u9806\u6b21\u30d5\u30ed\u30fc","text":"<pre><code>from refinire import Flow, FunctionStep, Context\n\ndef step1(input_data, context):\n    context.shared_state[\"step1_result\"] = f\"\u51e6\u74061: {input_data}\"\n    print(f\"\u30b9\u30c6\u30c3\u30d71\u5b9f\u884c: {input_data}\")\n    return context\n\ndef step2(input_data, context):\n    previous = context.shared_state[\"step1_result\"]\n    context.shared_state[\"step2_result\"] = f\"\u51e6\u74062: {previous}\"\n    print(f\"\u30b9\u30c6\u30c3\u30d72\u5b9f\u884c: {previous}\")\n    context.finish()  # \u30d5\u30ed\u30fc\u5b8c\u4e86\n    return context\n\n# \u9806\u6b21\u5b9f\u884c\u30d5\u30ed\u30fc\nsequential_flow = Flow([\n    (\"first\", FunctionStep(\"first\", step1)),\n    (\"second\", FunctionStep(\"second\", step2))\n])\n\n# \u5b9f\u884c\nresult = sequential_flow.run_sync(input_data=\"\u958b\u59cb\u30c7\u30fc\u30bf\")\nprint(f\"\u6700\u7d42\u7d50\u679c: {result.shared_state}\")\n</code></pre>"},{"location":"composable-flow-architecture/#2","title":"2. \u6761\u4ef6\u5206\u5c90\u30d5\u30ed\u30fc","text":"<pre><code>from refinire import Flow, FunctionStep, ConditionStep\n\ndef check_input_length(context):\n    \"\"\"\u5165\u529b\u306e\u9577\u3055\u3067\u5206\u5c90\u5224\u5b9a\"\"\"\n    return len(context.user_input) &gt; 10\n\ndef simple_process(input_data, context):\n    context.shared_state[\"result\"] = f\"\u7c21\u5358\u51e6\u7406: {input_data}\"\n    context.finish()\n    return context\n\ndef complex_process(input_data, context):\n    context.shared_state[\"result\"] = f\"\u8907\u96d1\u51e6\u7406: {input_data[:10]}...\"\n    context.finish()\n    return context\n\n# \u6761\u4ef6\u5206\u5c90\u30d5\u30ed\u30fc\nconditional_flow = Flow({\n    \"start\": ConditionStep(\"start\", check_input_length, \"complex\", \"simple\"),\n    \"simple\": FunctionStep(\"simple\", simple_process),\n    \"complex\": FunctionStep(\"complex\", complex_process)\n})\n\n# \u30c6\u30b9\u30c8\nshort_result = conditional_flow.run_sync(\"\u77ed\u3044\")\nlong_result = conditional_flow.run_sync(\"\u3053\u308c\u306f\u975e\u5e38\u306b\u9577\u3044\u5165\u529b\u30c7\u30fc\u30bf\u3067\u3059\")\n\nprint(f\"\u77ed\u3044\u5165\u529b: {short_result.shared_state['result']}\")\nprint(f\"\u9577\u3044\u5165\u529b: {long_result.shared_state['result']}\")\n</code></pre>"},{"location":"composable-flow-architecture/#_3","title":"\u4e2d\u7d1a\u4e8b\u4f8b","text":""},{"location":"composable-flow-architecture/#3-ai","title":"3. AI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u7d44\u307f\u8fbc\u307f\u30d5\u30ed\u30fc","text":"<pre><code>from refinire import Flow, FunctionStep, create_simple_gen_agent\n\ndef create_ai_workflow():\n    \"\"\"AI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u7d44\u307f\u8fbc\u3093\u3060\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\"\"\"\n\n    # AI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u4f5c\u6210\n    analyzer = create_simple_gen_agent(\n        \"analyzer\", \n        \"\u5165\u529b\u3092\u5206\u6790\u3057\u3066\u8981\u70b9\u3092\u62bd\u51fa\u3057\u3066\u304f\u3060\u3055\u3044\",\n        \"gpt-4o-mini\"\n    )\n\n    responder = create_simple_gen_agent(\n        \"responder\",\n        \"\u5206\u6790\u7d50\u679c\u306b\u57fa\u3065\u3044\u3066\u89aa\u5207\u306a\u56de\u7b54\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\", \n        \"gpt-4o-mini\"\n    )\n\n    def ai_analysis_step(input_data, context):\n        \"\"\"AI\u5206\u6790\u30b9\u30c6\u30c3\u30d7\"\"\"\n        analysis_result = analyzer.run_sync(input_data, context)\n        analysis = analysis_result.shared_state[\"analyzer_result\"]\n        context.shared_state[\"analysis\"] = analysis\n        print(f\"AI\u5206\u6790\u5b8c\u4e86: {analysis}\")\n        return context\n\n    def ai_response_step(input_data, context):\n        \"\"\"AI\u56de\u7b54\u751f\u6210\u30b9\u30c6\u30c3\u30d7\"\"\"\n        analysis = context.shared_state[\"analysis\"]\n        prompt = f\"\u4ee5\u4e0b\u306e\u5206\u6790\u306b\u57fa\u3065\u3044\u3066\u56de\u7b54\u3057\u3066\u304f\u3060\u3055\u3044: {analysis}\"\n        response_result = responder.run_sync(prompt, context)\n        response = response_result.shared_state[\"responder_result\"]\n        context.shared_state[\"final_response\"] = response\n        context.finish()\n        return context\n\n    # AI\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u69cb\u7bc9\n    ai_flow = Flow([\n        (\"analyze\", FunctionStep(\"analyze\", ai_analysis_step)),\n        (\"respond\", FunctionStep(\"respond\", ai_response_step))\n    ])\n\n    return ai_flow\n\n# \u4f7f\u7528\u4f8b\nai_workflow = create_ai_workflow()\nresult = ai_workflow.run_sync(\"\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u5b66\u7fd2\u306b\u3064\u3044\u3066\u76f8\u8ac7\u304c\u3042\u308a\u307e\u3059\")\nprint(f\"\u6700\u7d42\u56de\u7b54: {result.shared_state['final_response']}\")\n</code></pre>"},{"location":"composable-flow-architecture/#4-dag","title":"4. DAG\u4e26\u5217\u51e6\u7406\u30d5\u30ed\u30fc","text":"<pre><code>from refinire import Flow, FunctionStep, create_simple_gen_agent\n\ndef create_parallel_analysis_flow():\n    \"\"\"\u8907\u6570\u306e\u5206\u6790\u3092\u4e26\u5217\u5b9f\u884c\u3059\u308b\u30d5\u30ed\u30fc\"\"\"\n\n    # \u524d\u51e6\u7406\u30b9\u30c6\u30c3\u30d7\n    def preprocess_step(input_data, context):\n        context.shared_state[\"preprocessed_data\"] = f\"\u524d\u51e6\u7406\u6e08\u307f: {input_data}\"\n        print(f\"\u524d\u51e6\u7406\u5b8c\u4e86: {input_data}\")\n        return context\n\n    # \u4e26\u5217\u5206\u6790\u30b9\u30c6\u30c3\u30d7\n    def sentiment_analysis(input_data, context):\n        data = context.shared_state[\"preprocessed_data\"]\n        # \u5b9f\u969b\u306b\u306fAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f7f\u7528\n        context.shared_state[\"sentiment\"] = f\"\u611f\u60c5\u5206\u6790\u7d50\u679c: \u30dd\u30b8\u30c6\u30a3\u30d6 ({data})\"\n        print(\"\u611f\u60c5\u5206\u6790\u5b8c\u4e86\")\n        return context\n\n    def keyword_extraction(input_data, context):\n        data = context.shared_state[\"preprocessed_data\"]\n        context.shared_state[\"keywords\"] = f\"\u30ad\u30fc\u30ef\u30fc\u30c9: AI, \u6280\u8853, \u9032\u6b69 ({data})\"\n        print(\"\u30ad\u30fc\u30ef\u30fc\u30c9\u62bd\u51fa\u5b8c\u4e86\")\n        return context\n\n    def category_classification(input_data, context):\n        data = context.shared_state[\"preprocessed_data\"]\n        context.shared_state[\"category\"] = f\"\u30ab\u30c6\u30b4\u30ea: \u6280\u8853 ({data})\"\n        print(\"\u30ab\u30c6\u30b4\u30ea\u5206\u985e\u5b8c\u4e86\")\n        return context\n\n    # \u7d50\u679c\u7d71\u5408\u30b9\u30c6\u30c3\u30d7\n    def aggregate_results(input_data, context):\n        sentiment = context.shared_state.get(\"sentiment\", \"\")\n        keywords = context.shared_state.get(\"keywords\", \"\")\n        category = context.shared_state.get(\"category\", \"\")\n\n        final_result = f\"\"\"\n        \u5206\u6790\u7d50\u679c\u7d71\u5408:\n        - {sentiment}\n        - {keywords}\n        - {category}\n        \"\"\"\n        context.shared_state[\"final_analysis\"] = final_result\n        context.finish()\n        return context\n\n    # DAG\u69cb\u9020\u3067\u4e26\u5217\u51e6\u7406\u3092\u5b9a\u7fa9\n    parallel_flow = Flow({\n        \"preprocess\": FunctionStep(\"preprocess\", preprocess_step),\n        \"parallel_analysis\": {\n            \"parallel\": [\n                FunctionStep(\"sentiment\", sentiment_analysis),\n                FunctionStep(\"keywords\", keyword_extraction),\n                FunctionStep(\"category\", category_classification)\n            ]\n        },\n        \"aggregate\": FunctionStep(\"aggregate\", aggregate_results)\n    })\n\n    return parallel_flow\n\n# \u4f7f\u7528\u4f8b\nparallel_analysis = create_parallel_analysis_flow()\nresult = parallel_analysis.run_sync(\"AI\u6280\u8853\u306b\u3064\u3044\u3066\u8003\u3048\u3066\u3044\u307e\u3059\")\nprint(result.shared_state[\"final_analysis\"])\n</code></pre>"},{"location":"composable-flow-architecture/#5","title":"5. \u52d5\u7684\u30d5\u30ed\u30fc\u751f\u6210","text":"<pre><code>class DynamicFlowBuilder:\n    \"\"\"\u52d5\u7684\u306b\u30d5\u30ed\u30fc\u3092\u69cb\u7bc9\u3059\u308b\u30d3\u30eb\u30c0\u30fc\"\"\"\n\n    def __init__(self):\n        self.steps = []\n        self.step_count = 0\n\n    def add_processing_step(self, name: str, process_func):\n        \"\"\"\u51e6\u7406\u30b9\u30c6\u30c3\u30d7\u3092\u8ffd\u52a0\"\"\"\n        self.steps.append((name, FunctionStep(name, process_func)))\n        self.step_count += 1\n        return self\n\n    def add_validation_step(self, name: str, validation_func):\n        \"\"\"\u691c\u8a3c\u30b9\u30c6\u30c3\u30d7\u3092\u8ffd\u52a0\"\"\"\n        def validation_wrapper(input_data, context):\n            if validation_func(input_data, context):\n                print(f\"\u2713 \u691c\u8a3c\u6210\u529f: {name}\")\n                return context\n            else:\n                context.shared_state[\"error\"] = f\"\u691c\u8a3c\u5931\u6557: {name}\"\n                context.finish()\n                return context\n\n        self.steps.append((name, FunctionStep(name, validation_wrapper)))\n        return self\n\n    def add_ai_agent_step(self, name: str, instructions: str, model: str = \"gpt-4o-mini\"):\n        \"\"\"AI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u30b9\u30c6\u30c3\u30d7\u3092\u8ffd\u52a0\"\"\"\n        agent = create_simple_gen_agent(name, instructions, model)\n\n        def ai_step(input_data, context):\n            result = agent.run_sync(input_data, context)\n            context.shared_state[f\"{name}_result\"] = result.shared_state[f\"{name}_result\"]\n            return context\n\n        self.steps.append((name, FunctionStep(name, ai_step)))\n        return self\n\n    def build(self) -&gt; Flow:\n        \"\"\"\u30d5\u30ed\u30fc\u3092\u69cb\u7bc9\"\"\"\n        if not self.steps:\n            raise ValueError(\"\u30b9\u30c6\u30c3\u30d7\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u307e\u305b\u3093\")\n\n        # \u6700\u5f8c\u306e\u30b9\u30c6\u30c3\u30d7\u3067 finish() \u3092\u547c\u3076\u3088\u3046\u306b\u8abf\u6574\n        if self.steps:\n            last_step_name, last_step = self.steps[-1]\n            original_func = last_step.func\n\n            def finishing_wrapper(input_data, context):\n                context = original_func(input_data, context)\n                if not context.finished:\n                    context.finish()\n                return context\n\n            self.steps[-1] = (last_step_name, FunctionStep(last_step_name, finishing_wrapper))\n\n        return Flow(self.steps)\n\n# \u4f7f\u7528\u4f8b\nbuilder = DynamicFlowBuilder()\n\n# \u30d5\u30ed\u30fc\u3092\u52d5\u7684\u306b\u69cb\u7bc9\ncomplex_flow = (builder\n    .add_processing_step(\"preprocess\", lambda data, ctx: ctx.update({\"preprocessed\": f\"\u524d\u51e6\u7406\u6e08\u307f: {data}\"}))\n    .add_validation_step(\"validate\", lambda data, ctx: len(data) &gt; 5)\n    .add_ai_agent_step(\"analyze\", \"\u5165\u529b\u3092\u8a73\u7d30\u306b\u5206\u6790\u3057\u3066\u304f\u3060\u3055\u3044\")\n    .add_ai_agent_step(\"summarize\", \"\u5206\u6790\u7d50\u679c\u3092\u7c21\u6f54\u306b\u307e\u3068\u3081\u3066\u304f\u3060\u3055\u3044\")\n    .build())\n\n# \u5b9f\u884c\nresult = complex_flow.run_sync(\"\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u51e6\u7406\u30bf\u30b9\u30af\")\nprint(f\"\u51e6\u7406\u7d50\u679c: {result.shared_state}\")\n</code></pre>"},{"location":"composable-flow-architecture/#_4","title":"\u9ad8\u5ea6\u306a\u4e8b\u4f8b","text":""},{"location":"composable-flow-architecture/#5_1","title":"5. \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u4ed8\u304d\u5fa9\u65e7\u30d5\u30ed\u30fc","text":"<pre><code>class ResilientFlowSystem:\n    \"\"\"\u30a8\u30e9\u30fc\u56de\u5fa9\u6a5f\u80fd\u4ed8\u304d\u30d5\u30ed\u30fc\u30b7\u30b9\u30c6\u30e0\"\"\"\n\n    def __init__(self):\n        self.error_handlers = {}\n        self.retry_configs = {}\n\n    def add_error_handler(self, step_name: str, handler_func):\n        \"\"\"\u30b9\u30c6\u30c3\u30d7\u5c02\u7528\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u3092\u8ffd\u52a0\"\"\"\n        self.error_handlers[step_name] = handler_func\n        return self\n\n    def add_retry_config(self, step_name: str, max_retries: int = 3, delay: float = 1.0):\n        \"\"\"\u30ea\u30c8\u30e9\u30a4\u8a2d\u5b9a\u3092\u8ffd\u52a0\"\"\"\n        self.retry_configs[step_name] = {\n            \"max_retries\": max_retries,\n            \"delay\": delay\n        }\n        return self\n\n    def create_resilient_step(self, name: str, step_func):\n        \"\"\"\u30a8\u30e9\u30fc\u56de\u5fa9\u6a5f\u80fd\u4ed8\u304d\u30b9\u30c6\u30c3\u30d7\u4f5c\u6210\"\"\"\n\n        def resilient_wrapper(input_data, context):\n            \"\"\"\u30a8\u30e9\u30fc\u56de\u5fa9\u30e9\u30c3\u30d1\u30fc\"\"\"\n            retry_config = self.retry_configs.get(name, {\"max_retries\": 1, \"delay\": 0})\n            max_retries = retry_config[\"max_retries\"]\n            delay = retry_config[\"delay\"]\n\n            for attempt in range(max_retries):\n                try:\n                    # \u30b9\u30c6\u30c3\u30d7\u5b9f\u884c\n                    result = step_func(input_data, context)\n                    if attempt &gt; 0:\n                        print(f\"\u2713 {name}: {attempt + 1}\u56de\u76ee\u306e\u8a66\u884c\u3067\u6210\u529f\")\n                    return result\n\n                except Exception as e:\n                    error_info = {\n                        \"step\": name,\n                        \"attempt\": attempt + 1,\n                        \"error\": str(e),\n                        \"max_retries\": max_retries\n                    }\n\n                    # \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u306e\u5b9f\u884c\n                    if name in self.error_handlers:\n                        try:\n                            recovery_result = self.error_handlers[name](error_info, context)\n                            if recovery_result:\n                                print(f\"\u2713 {name}: \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u3067\u5fa9\u65e7\u6210\u529f\")\n                                return recovery_result\n                        except Exception as handler_error:\n                            print(f\"\u2717 {name}: \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u3082\u5931\u6557 - {handler_error}\")\n\n                    # \u6700\u5f8c\u306e\u8a66\u884c\u3067\u306a\u3044\u5834\u5408\u306f\u30ea\u30c8\u30e9\u30a4\n                    if attempt &lt; max_retries - 1:\n                        print(f\"\u26a0\ufe0f {name}: \u8a66\u884c{attempt + 1}\u5931\u6557\u3001{delay}\u79d2\u5f8c\u306b\u30ea\u30c8\u30e9\u30a4 - {e}\")\n                        import time\n                        time.sleep(delay)\n                    else:\n                        # \u6700\u7d42\u7684\u306b\u5931\u6557\n                        context.shared_state[\"error\"] = error_info\n                        context.shared_state[\"failed_step\"] = name\n                        print(f\"\u2717 {name}: \u5168\u3066\u306e\u8a66\u884c\u304c\u5931\u6557 - {e}\")\n                        raise e\n\n            return context\n\n        return FunctionStep(name, resilient_wrapper)\n\n    def create_fault_tolerant_flow(self, step_definitions: List[Dict]) -&gt; Flow:\n        \"\"\"\u30d5\u30a9\u30eb\u30c8\u30c8\u30ec\u30e9\u30f3\u30c8\u30d5\u30ed\u30fc\u4f5c\u6210\"\"\"\n        steps = []\n\n        for step_def in step_definitions:\n            name = step_def[\"name\"]\n            func = step_def[\"func\"]\n\n            # \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u8a2d\u5b9a\n            if \"error_handler\" in step_def:\n                self.add_error_handler(name, step_def[\"error_handler\"])\n\n            # \u30ea\u30c8\u30e9\u30a4\u8a2d\u5b9a\n            if \"retry_config\" in step_def:\n                retry_config = step_def[\"retry_config\"]\n                self.add_retry_config(\n                    name, \n                    retry_config.get(\"max_retries\", 3),\n                    retry_config.get(\"delay\", 1.0)\n                )\n\n            # \u30a8\u30e9\u30fc\u56de\u5fa9\u6a5f\u80fd\u4ed8\u304d\u30b9\u30c6\u30c3\u30d7\u3092\u4f5c\u6210\n            resilient_step = self.create_resilient_step(name, func)\n            steps.append((name, resilient_step))\n\n        return Flow(steps)\n\n# \u4f7f\u7528\u4f8b\nresilient_system = ResilientFlowSystem()\n\n# \u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b\u53ef\u80fd\u6027\u306e\u3042\u308b\u51e6\u7406\u95a2\u6570\ndef unreliable_data_fetch(input_data, context):\n    \"\"\"\u4e0d\u5b89\u5b9a\u306a\u30c7\u30fc\u30bf\u53d6\u5f97\uff08\u30e9\u30f3\u30c0\u30e0\u306b\u5931\u6557\uff09\"\"\"\n    import random\n    if random.random() &lt; 0.7:  # 70%\u306e\u78ba\u7387\u3067\u5931\u6557\n        raise Exception(\"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a8\u30e9\u30fc\")\n\n    context.shared_state[\"fetched_data\"] = f\"\u53d6\u5f97\u30c7\u30fc\u30bf: {input_data}\"\n    return context\n\ndef unreliable_ai_processing(input_data, context):\n    \"\"\"\u4e0d\u5b89\u5b9a\u306aAI\u51e6\u7406\uff08\u30e9\u30f3\u30c0\u30e0\u306b\u5931\u6557\uff09\"\"\"\n    import random\n    if random.random() &lt; 0.5:  # 50%\u306e\u78ba\u7387\u3067\u5931\u6557\n        raise Exception(\"AI\u51e6\u7406\u30a8\u30e9\u30fc\")\n\n    data = context.shared_state.get(\"fetched_data\", input_data)\n    context.shared_state[\"ai_result\"] = f\"AI\u51e6\u7406\u7d50\u679c: {data}\"\n    context.finish()\n    return context\n\n# \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u5b9a\u7fa9\ndef data_fetch_error_handler(error_info, context):\n    \"\"\"\u30c7\u30fc\u30bf\u53d6\u5f97\u30a8\u30e9\u30fc\u306e\u30cf\u30f3\u30c9\u30e9\u30fc\"\"\"\n    print(f\"\u30c7\u30fc\u30bf\u53d6\u5f97\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u5b9f\u884c: {error_info['error']}\")\n    # \u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af\u30c7\u30fc\u30bf\u3092\u8a2d\u5b9a\n    context.shared_state[\"fetched_data\"] = \"\u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af\u30c7\u30fc\u30bf\"\n    return context\n\ndef ai_processing_error_handler(error_info, context):\n    \"\"\"AI\u51e6\u7406\u30a8\u30e9\u30fc\u306e\u30cf\u30f3\u30c9\u30e9\u30fc\"\"\"\n    print(f\"AI\u51e6\u7406\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30e9\u30fc\u5b9f\u884c: {error_info['error']}\")\n    # \u7c21\u6613\u51e6\u7406\u3067\u4ee3\u66ff\n    data = context.shared_state.get(\"fetched_data\", \"\u30c7\u30d5\u30a9\u30eb\u30c8\u30c7\u30fc\u30bf\")\n    context.shared_state[\"ai_result\"] = f\"\u7c21\u6613\u51e6\u7406\u7d50\u679c: {data}\"\n    context.finish()\n    return context\n\n# \u30d5\u30a9\u30eb\u30c8\u30c8\u30ec\u30e9\u30f3\u30c8\u30d5\u30ed\u30fc\u5b9a\u7fa9\nfault_tolerant_steps = [\n    {\n        \"name\": \"data_fetch\",\n        \"func\": unreliable_data_fetch,\n        \"retry_config\": {\"max_retries\": 3, \"delay\": 0.5},\n        \"error_handler\": data_fetch_error_handler\n    },\n    {\n        \"name\": \"ai_process\", \n        \"func\": unreliable_ai_processing,\n        \"retry_config\": {\"max_retries\": 2, \"delay\": 1.0},\n        \"error_handler\": ai_processing_error_handler\n    }\n]\n\n# \u30d5\u30ed\u30fc\u4f5c\u6210\u30fb\u5b9f\u884c\nfault_tolerant_flow = resilient_system.create_fault_tolerant_flow(fault_tolerant_steps)\n\ntry:\n    result = fault_tolerant_flow.run_sync(\"\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\")\n    print(f\"\\n\u6700\u7d42\u7d50\u679c: {result.shared_state}\")\nexcept Exception as e:\n    print(f\"\\n\u30d5\u30ed\u30fc\u5b9f\u884c\u5931\u6557: {e}\")\n</code></pre>"},{"location":"composable-flow-architecture/#_5","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u67d4\u8edf\u6027: \u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u76f4\u611f\u7684\u306b\u5b9a\u7fa9</li> <li>\u518d\u5229\u7528\u6027: \u30b9\u30c6\u30c3\u30d7\u306e\u7d44\u307f\u5408\u308f\u305b\u3067\u591a\u69d8\u306a\u30d5\u30ed\u30fc\u3092\u69cb\u7bc9</li> <li>\u62e1\u5f35\u6027: \u65b0\u3057\u3044\u30b9\u30c6\u30c3\u30d7\u30bf\u30a4\u30d7\u306e\u7c21\u5358\u306a\u8ffd\u52a0</li> <li>\u30c7\u30d0\u30c3\u30b0\u6027: \u5404\u30b9\u30c6\u30c3\u30d7\u306e\u72b6\u614b\u3068\u30c7\u30fc\u30bf\u30d5\u30ed\u30fc\u304c\u900f\u660e</li> </ul> <p>\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306b\u3088\u308a\u3001\u958b\u767a\u8005\u306f\u8907\u96d1\u306aAI\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u52b9\u7387\u7684\u306b\u69cb\u7bc9\u30fb\u4fdd\u5b88\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"composable-flow-architecture_ja/","title":"Composable Flow Architecture - \u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":"<p>Refinire\u306e\u7b2c\u4e09\u306e\u67f1\u3067\u3042\u308b\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306f\u3001\u8907\u96d1\u306aAI\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u67d4\u8edf\u3067\u518d\u5229\u7528\u53ef\u80fd\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304b\u3089\u69cb\u7bc9\u3067\u304d\u308b\u9769\u65b0\u7684\u306a\u30b7\u30b9\u30c6\u30e0\u3067\u3059\u3002</p>"},{"location":"composable-flow-architecture_ja/#_1","title":"\u57fa\u672c\u6982\u5ff5","text":"<p>\u5f93\u6765\u306e\u7dda\u5f62\u51e6\u7406\u304b\u3089\u8131\u5374\u3057\u3001\u6761\u4ef6\u5206\u5c90\u3001\u30eb\u30fc\u30d7\u3001\u4e26\u5217\u51e6\u7406\u3092\u542b\u3080\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u76f4\u611f\u7684\u306b\u5b9a\u7fa9\u30fb\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from refinire import Flow, FunctionStep, create_simple_gen_agent\nimport asyncio\n\n# \u8d85\u30b7\u30f3\u30d7\u30eb\u306aFlow - \u30a8\u30fc\u30b8\u30a7\u30f3\u30c81\u3064\u3060\u3051\nflow = Flow(steps=gen_agent)\n\n# \u8907\u6570\u30b9\u30c6\u30c3\u30d7\u306eFlow - \u81ea\u52d5\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u5b9f\u884c\nflow = Flow([\n    (\"preprocess\", FunctionStep(\"preprocess\", preprocess_func)),\n    (\"generate\", gen_agent),\n    (\"postprocess\", FunctionStep(\"postprocess\", postprocess_func))\n])\n\n# \u8907\u96d1\u306a\u6761\u4ef6\u5206\u5c90Flow\nflow = Flow({\n    \"input_analysis\": FunctionStep(\"analyze\", analyze_input),\n    \"simple_case\": {\n        \"condition\": lambda ctx: len(ctx.user_input) &lt; 50,\n        \"step\": simple_agent,\n        \"next_step\": \"output\"\n    },\n    \"complex_case\": {\n        \"condition\": lambda ctx: len(ctx.user_input) &gt;= 50,\n        \"step\": complex_agent, \n        \"next_step\": \"output\"\n    },\n    \"output\": FunctionStep(\"format\", format_output)\n})\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_2","title":"\u6838\u3068\u306a\u308b\u8a2d\u8a08\u539f\u5247","text":""},{"location":"composable-flow-architecture_ja/#1-composability","title":"1. \u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u6027 (Composability)","text":"<p>\u5404\u30b9\u30c6\u30c3\u30d7\u306f\u72ec\u7acb\u3057\u305f\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3068\u3057\u3066\u8a2d\u8a08\u3055\u308c\u3001\u81ea\u7531\u306b\u7d44\u307f\u5408\u308f\u305b\u3067\u304d\u307e\u3059\u3002</p> <pre><code># \u57fa\u672c\u30b9\u30c6\u30c3\u30d7\u3092\u5b9a\u7fa9\npreprocess_step = FunctionStep(\"preprocess\", preprocess_data)\nanalysis_step = create_simple_gen_agent(\"analyzer\", \"\u30c7\u30fc\u30bf\u3092\u5206\u6790\u3057\u3066\u304f\u3060\u3055\u3044\", \"gpt-4o-mini\")\nformat_step = FunctionStep(\"format\", format_results)\n\n# \u7570\u306a\u308b\u7d44\u307f\u5408\u308f\u305b\u3067\u518d\u5229\u7528\nquick_flow = Flow([(\"analyze\", analysis_step)])\ndetailed_flow = Flow([\n    (\"preprocess\", preprocess_step),\n    (\"analyze\", analysis_step), \n    (\"format\", format_step)\n])\n</code></pre>"},{"location":"composable-flow-architecture_ja/#2-declarative-configuration","title":"2. \u5ba3\u8a00\u7684\u8a2d\u5b9a (Declarative Configuration)","text":"<p>\u51e6\u7406\u306e\u300c\u624b\u9806\u300d\u3067\u306f\u306a\u304f\u300c\u69cb\u9020\u300d\u3092\u5ba3\u8a00\u7684\u306b\u5b9a\u7fa9\u3057\u307e\u3059\u3002</p> <pre><code># \u547d\u4ee4\u7684\u306a\u66f8\u304d\u65b9\uff08\u5f93\u6765\uff09\ndef process_text(input_text):\n    if len(input_text) &lt; 100:\n        return simple_processor(input_text)\n    else:\n        preprocessed = preprocess(input_text)\n        analyzed = complex_analysis(preprocessed)\n        return postprocess(analyzed)\n\n# \u5ba3\u8a00\u7684\u306a\u66f8\u304d\u65b9\uff08Refinire\uff09\nflow = Flow({\n    \"route\": ConditionStep(\"router\", \n        condition=lambda ctx: \"simple\" if len(ctx.user_input) &lt; 100 else \"complex\",\n        branches={\"simple\": simple_agent, \"complex\": complex_pipeline}\n    )\n})\n</code></pre>"},{"location":"composable-flow-architecture_ja/#3-separated-state-management","title":"3. \u72b6\u614b\u7ba1\u7406\u306e\u5206\u96e2 (Separated State Management)","text":"<p>\u30b9\u30c6\u30c3\u30d7\u9593\u306e\u72b6\u614b\u5171\u6709\u306f <code>Context</code> \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u3088\u3063\u3066\u660e\u793a\u7684\u306b\u7ba1\u7406\u3055\u308c\u307e\u3059\u3002</p> <pre><code>def step1(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u6700\u521d\u306e\u30b9\u30c6\u30c3\u30d7 - \u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3057\u3066\u6b21\u30b9\u30c6\u30c3\u30d7\u306b\u6e21\u3059\"\"\"\n    # English: First step - process data and pass to next step\n    processed_data = preprocess(user_input)\n    ctx.shared_state[\"processed\"] = processed_data\n    ctx.shared_state[\"timestamp\"] = datetime.now()\n    return ctx\n\ndef step2(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"2\u756a\u76ee\u306e\u30b9\u30c6\u30c3\u30d7 - \u524d\u30b9\u30c6\u30c3\u30d7\u306e\u7d50\u679c\u3092\u4f7f\u7528\"\"\"\n    # English: Second step - use results from previous step\n    previous_result = ctx.shared_state[\"processed\"]\n    result = analyze(previous_result)\n    ctx.shared_state[\"analysis\"] = result\n    return ctx\n</code></pre>"},{"location":"composable-flow-architecture_ja/#flow","title":"Flow\u4f5c\u6210\u30d1\u30bf\u30fc\u30f3","text":""},{"location":"composable-flow-architecture_ja/#1-flow","title":"\u30d1\u30bf\u30fc\u30f31: \u5358\u4e00\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8Flow\uff08\u6700\u3082\u30b7\u30f3\u30d7\u30eb\uff09","text":"<pre><code>from refinire import create_simple_gen_agent, Flow\n\n# \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u4f5c\u6210\nagent = create_simple_gen_agent(\n    name=\"assistant\",\n    instructions=\"\u30e6\u30fc\u30b6\u30fc\u306e\u8cea\u554f\u306b\u89aa\u5207\u306b\u56de\u7b54\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# \u8d85\u30b7\u30f3\u30d7\u30eb\u306aFlow - 1\u884c\u3067\u5b8c\u6210\nflow = Flow(steps=agent)\n\n# \u5b9f\u884c\nresult = await flow.run(input_data=\"AI\u306b\u3064\u3044\u3066\u6559\u3048\u3066\")\nprint(result.shared_state[\"assistant_result\"])\n</code></pre>"},{"location":"composable-flow-architecture_ja/#2-flow","title":"\u30d1\u30bf\u30fc\u30f32: \u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30ebFlow\uff08\u81ea\u52d5\u9806\u6b21\u5b9f\u884c\uff09","text":"<pre><code>from refinire import Flow, FunctionStep, create_simple_gen_agent\n\ndef validate_input(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u5165\u529b\u30c7\u30fc\u30bf\u306e\u691c\u8a3c\u3092\u884c\u3046\"\"\"\n    # English: Validate input data\n    if not user_input.strip():\n        raise ValueError(\"\u7a7a\u306e\u5165\u529b\u306f\u8a31\u53ef\u3055\u308c\u3066\u3044\u307e\u305b\u3093\")\n    ctx.shared_state[\"validated_input\"] = user_input.strip()\n    return ctx\n\ndef preprocess_text(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30c6\u30ad\u30b9\u30c8\u306e\u524d\u51e6\u7406\u3092\u5b9f\u884c\"\"\"\n    # English: Execute text preprocessing\n    validated = ctx.shared_state[\"validated_input\"]\n    processed = validated.lower().replace('\\n', ' ')\n    ctx.shared_state[\"preprocessed\"] = processed\n    return ctx\n\n# \u751f\u6210\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\ngenerator = create_simple_gen_agent(\n    name=\"content_gen\",\n    instructions=\"\u524d\u51e6\u7406\u3055\u308c\u305f\u30c6\u30ad\u30b9\u30c8\u306b\u57fa\u3065\u3044\u3066\u3001\u6709\u7528\u306a\u5185\u5bb9\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\ndef format_output(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u51fa\u529b\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u6574\u3048\u308b\"\"\"\n    # English: Format the output\n    generated = ctx.shared_state[\"content_gen_result\"]\n    formatted = f\"=== \u751f\u6210\u7d50\u679c ===\\n{generated}\\n=== \u7d42\u4e86 ===\"\n    ctx.shared_state[\"final_output\"] = formatted\n    ctx.finish()  # \u30d5\u30ed\u30fc\u7d42\u4e86\u3092\u660e\u793a\n    return ctx\n\n# \u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30ebFlow\uff08\u81ea\u52d5\u3067\u9806\u6b21\u5b9f\u884c\uff09\nflow = Flow([\n    (\"validate\", FunctionStep(\"validate\", validate_input)),\n    (\"preprocess\", FunctionStep(\"preprocess\", preprocess_text)),\n    (\"generate\", generator),\n    (\"format\", FunctionStep(\"format\", format_output))\n])\n\n# \u5b9f\u884c\nresult = await flow.run(input_data=\"AI\u306e\u672a\u6765\u306b\u3064\u3044\u3066\")\nprint(result.shared_state[\"final_output\"])\n</code></pre>"},{"location":"composable-flow-architecture_ja/#3-flow","title":"\u30d1\u30bf\u30fc\u30f33: \u6761\u4ef6\u5206\u5c90Flow","text":"<pre><code>from refinire import Flow, ConditionStep, FunctionStep\n\ndef analyze_complexity(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u5165\u529b\u306e\u8907\u96d1\u3055\u3092\u5206\u6790\"\"\"\n    # English: Analyze input complexity\n    word_count = len(user_input.split())\n    ctx.shared_state[\"word_count\"] = word_count\n    ctx.shared_state[\"complexity\"] = \"simple\" if word_count &lt; 20 else \"complex\"\n    return ctx\n\ndef route_by_complexity(ctx: Context) -&gt; str:\n    \"\"\"\u8907\u96d1\u3055\u306b\u57fa\u3065\u3044\u3066\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\"\"\"\n    # English: Route based on complexity\n    return ctx.shared_state[\"complexity\"]\n\n# \u5358\u7d14\u306a\u51e6\u7406\u7528\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\nsimple_agent = create_simple_gen_agent(\n    name=\"simple_processor\",\n    instructions=\"\u7c21\u6f54\u306b\u56de\u7b54\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# \u8907\u96d1\u306a\u51e6\u7406\u7528\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\ncomplex_agent = create_simple_gen_agent(\n    name=\"complex_processor\", \n    instructions=\"\u8a73\u7d30\u3067\u5305\u62ec\u7684\u306a\u5206\u6790\u3092\u884c\u3044\u3001\u6bb5\u968e\u7684\u306b\u8aac\u660e\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# \u6761\u4ef6\u5206\u5c90Flow\nflow = Flow({\n    \"analyze\": FunctionStep(\"analyze\", analyze_complexity),\n    \"router\": ConditionStep(\"router\", route_by_complexity, \"simple\", \"complex\"),\n    \"simple\": simple_agent,\n    \"complex\": complex_agent\n})\n\n# \u5b9f\u884c\nresult = await flow.run(input_data=\"\u3053\u3093\u306b\u3061\u306f\")  # \u2192 simple_agent\nresult = await flow.run(input_data=\"\u4eba\u5de5\u77e5\u80fd\u306e\u502b\u7406\u7684\u554f\u984c\u306b\u3064\u3044\u3066\u8a73\u3057\u304f\u6559\u3048\u3066\")  # \u2192 complex_agent\n</code></pre>"},{"location":"composable-flow-architecture_ja/#4-flow39","title":"\u30d1\u30bf\u30fc\u30f34: \u4e26\u5217\u51e6\u7406Flow\uff083.9\u500d\u9ad8\u901f\u5316\uff09","text":"<pre><code>from refinire import Flow, FunctionStep\nimport asyncio\n\ndef preprocess_text(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30c6\u30ad\u30b9\u30c8\u306e\u524d\u51e6\u7406\"\"\"\n    # English: Text preprocessing\n    ctx.shared_state[\"processed_text\"] = user_input.strip().lower()\n    return ctx\n\ndef sentiment_analysis(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u611f\u60c5\u5206\u6790\"\"\"\n    # English: Sentiment analysis\n    # \u5b9f\u969b\u306e\u5206\u6790\u51e6\u7406\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\n    import time\n    time.sleep(0.5)  # 0.5\u79d2\u306e\u51e6\u7406\u6642\u9593\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\n    ctx.shared_state[\"sentiment\"] = \"positive\"\n    return ctx\n\ndef keyword_extraction(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30ad\u30fc\u30ef\u30fc\u30c9\u62bd\u51fa\"\"\"\n    # English: Keyword extraction\n    import time\n    time.sleep(0.5)  # 0.5\u79d2\u306e\u51e6\u7406\u6642\u9593\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\n    text = ctx.shared_state[\"processed_text\"]\n    ctx.shared_state[\"keywords\"] = text.split()[:5]\n    return ctx\n\ndef topic_classification(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30c8\u30d4\u30c3\u30af\u5206\u985e\"\"\"\n    # English: Topic classification\n    import time\n    time.sleep(0.5)  # 0.5\u79d2\u306e\u51e6\u7406\u6642\u9593\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\n    ctx.shared_state[\"topic\"] = \"technology\"\n    return ctx\n\ndef readability_check(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u53ef\u8aad\u6027\u30c1\u30a7\u30c3\u30af\"\"\"\n    # English: Readability check\n    import time\n    time.sleep(0.5)  # 0.5\u79d2\u306e\u51e6\u7406\u6642\u9593\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\n    ctx.shared_state[\"readability_score\"] = 85\n    return ctx\n\ndef aggregate_results(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u7d50\u679c\u3092\u7d71\u5408\"\"\"\n    # English: Aggregate results\n    sentiment = ctx.shared_state.get(\"sentiment\", \"unknown\")\n    keywords = ctx.shared_state.get(\"keywords\", [])\n    topic = ctx.shared_state.get(\"topic\", \"unknown\")\n    readability = ctx.shared_state.get(\"readability_score\", 0)\n\n    summary = {\n        \"sentiment\": sentiment,\n        \"keywords\": keywords,\n        \"topic\": topic,\n        \"readability\": readability\n    }\n    ctx.shared_state[\"analysis_summary\"] = summary\n    ctx.finish()\n    return ctx\n\n# \u4e26\u5217\u51e6\u7406Flow\nflow = Flow({\n    \"preprocess\": FunctionStep(\"preprocess\", preprocess_text),\n    \"parallel_analysis\": {\n        \"parallel\": [\n            FunctionStep(\"sentiment\", sentiment_analysis),\n            FunctionStep(\"keywords\", keyword_extraction),\n            FunctionStep(\"topic\", topic_classification),\n            FunctionStep(\"readability\", readability_check)\n        ],\n        \"next_step\": \"aggregate\",\n        \"max_workers\": 4  # \u6700\u59274\u3064\u306e\u4e26\u5217\u5b9f\u884c\n    },\n    \"aggregate\": FunctionStep(\"aggregate\", aggregate_results)\n})\n\n# \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6bd4\u8f03\nimport time\n\n# \u9806\u6b21\u5b9f\u884c: \u7d042.0\u79d2\uff080.5 \u00d7 4\uff09\nstart_time = time.time()\nresult_sequential = await flow.run(input_data=\"This is a comprehensive analysis test.\")\nsequential_time = time.time() - start_time\n\n# \u4e26\u5217\u5b9f\u884c: \u7d040.5\u79d2\uff083.9\u500d\u9ad8\u901f\u5316\uff09\nstart_time = time.time()\nresult_parallel = await flow.run(input_data=\"This is a comprehensive analysis test.\")\nparallel_time = time.time() - start_time\n\nprint(f\"\u9806\u6b21\u5b9f\u884c: {sequential_time:.2f}\u79d2\")\nprint(f\"\u4e26\u5217\u5b9f\u884c: {parallel_time:.2f}\u79d2\")\nprint(f\"\u901f\u5ea6\u5411\u4e0a: {sequential_time/parallel_time:.1f}\u500d\")\n</code></pre>"},{"location":"composable-flow-architecture_ja/#5-flow","title":"\u30d1\u30bf\u30fc\u30f35: \u8907\u5408Flow\uff08\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8+\u95a2\u6570+\u6761\u4ef6\u5206\u5c90\uff09","text":"<pre><code>from refinire import Flow, FunctionStep, ConditionStep, create_evaluated_gen_agent\n\n# \u5165\u529b\u5206\u6790\ndef analyze_request(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30ea\u30af\u30a8\u30b9\u30c8\u306e\u7a2e\u985e\u3092\u5206\u6790\"\"\"\n    # English: Analyze request type\n    if \"\u30b3\u30fc\u30c9\" in user_input or \"\u30d7\u30ed\u30b0\u30e9\u30e0\" in user_input:\n        ctx.shared_state[\"request_type\"] = \"coding\"\n    elif \"\u8aac\u660e\" in user_input or \"\u6559\u3048\u3066\" in user_input:\n        ctx.shared_state[\"request_type\"] = \"explanation\"\n    else:\n        ctx.shared_state[\"request_type\"] = \"general\"\n    return ctx\n\n# \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u95a2\u6570\ndef route_request(ctx: Context) -&gt; str:\n    \"\"\"\u30ea\u30af\u30a8\u30b9\u30c8\u30bf\u30a4\u30d7\u306b\u57fa\u3065\u304f\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\"\"\"\n    # English: Route based on request type\n    return ctx.shared_state[\"request_type\"]\n\n# \u5c02\u9580\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\uff08\u8a55\u4fa1\u6a5f\u80fd\u4ed8\u304d\uff09\ncoding_agent = create_evaluated_gen_agent(\n    name=\"coding_expert\",\n    generation_instructions=\"\"\"\n    \u3042\u306a\u305f\u306f\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306e\u5c02\u9580\u5bb6\u3067\u3059\u3002\n    \u5b9f\u884c\u53ef\u80fd\u3067\u54c1\u8cea\u306e\u9ad8\u3044\u30b3\u30fc\u30c9\u3092\u751f\u6210\u3057\u3001\u8a73\u7d30\u306a\u8aac\u660e\u3092\u4ed8\u3051\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    evaluation_instructions=\"\"\"\n    \u751f\u6210\u3055\u308c\u305f\u30b3\u30fc\u30c9\u3092\u4ee5\u4e0b\u306e\u89b3\u70b9\u3067\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\uff1a\n    - \u6b63\u78ba\u6027\uff0840\u70b9\uff09\n    - \u53ef\u8aad\u6027\uff0830\u70b9\uff09\n    - \u52b9\u7387\u6027\uff0830\u70b9\uff09\n    \"\"\",\n    threshold=80.0,\n    model=\"gpt-4o-mini\"\n)\n\nexplanation_agent = create_evaluated_gen_agent(\n    name=\"explanation_expert\",\n    generation_instructions=\"\"\"\n    \u3042\u306a\u305f\u306f\u6559\u80b2\u306e\u5c02\u9580\u5bb6\u3067\u3059\u3002\n    \u5206\u304b\u308a\u3084\u3059\u304f\u6bb5\u968e\u7684\u306b\u8aac\u660e\u3057\u3001\u5177\u4f53\u4f8b\u3092\u542b\u3081\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    evaluation_instructions=\"\"\"\n    \u8aac\u660e\u306e\u54c1\u8cea\u3092\u4ee5\u4e0b\u306e\u89b3\u70b9\u3067\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\uff1a\n    - \u5206\u304b\u308a\u3084\u3059\u3055\uff0850\u70b9\uff09\n    - \u6b63\u78ba\u6027\uff0830\u70b9\uff09\n    - \u5b8c\u5168\u6027\uff0820\u70b9\uff09\n    \"\"\",\n    threshold=75.0,\n    model=\"gpt-4o-mini\"\n)\n\ngeneral_agent = create_simple_gen_agent(\n    name=\"general_assistant\",\n    instructions=\"\u89aa\u5207\u3067\u4e01\u5be7\u306a\u4e00\u822c\u7684\u306a\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u56de\u7b54\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# \u5f8c\u51e6\u7406\ndef format_response(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\"\"\"\n    # English: Format response\n    request_type = ctx.shared_state[\"request_type\"]\n\n    if request_type == \"coding\":\n        result = ctx.shared_state.get(\"coding_expert_result\", \"\")\n        evaluation = ctx.shared_state.get(\"coding_expert_evaluation\", {})\n    elif request_type == \"explanation\":\n        result = ctx.shared_state.get(\"explanation_expert_result\", \"\")\n        evaluation = ctx.shared_state.get(\"explanation_expert_evaluation\", {})\n    else:\n        result = ctx.shared_state.get(\"general_assistant_result\", \"\")\n        evaluation = None\n\n    formatted = f\"\"\"\n=== {request_type.upper()} \u30ec\u30b9\u30dd\u30f3\u30b9 ===\n{result}\n\n{f\"\u54c1\u8cea\u30b9\u30b3\u30a2: {evaluation.get('score', 'N/A')}\" if evaluation else \"\"}\n=== \u7d42\u4e86 ===\n    \"\"\".strip()\n\n    ctx.shared_state[\"final_response\"] = formatted\n    ctx.finish()\n    return ctx\n\n# \u8907\u5408Flow\nflow = Flow({\n    \"analyze\": FunctionStep(\"analyze\", analyze_request),\n    \"router\": ConditionStep(\"router\", route_request, \"coding\", \"explanation\", \"general\"),\n    \"coding\": coding_agent,\n    \"explanation\": explanation_agent,\n    \"general\": general_agent,\n    \"format\": FunctionStep(\"format\", format_response)\n})\n\n# \u5b9f\u884c\u4f8b\nexamples = [\n    \"Python\u3067\u30d5\u30a3\u30dc\u30ca\u30c3\u30c1\u6570\u5217\u3092\u751f\u6210\u3059\u308b\u30b3\u30fc\u30c9\u3092\u66f8\u3044\u3066\",\n    \"\u6a5f\u68b0\u5b66\u7fd2\u3068\u306f\u4f55\u304b\u8a73\u3057\u304f\u8aac\u660e\u3057\u3066\",\n    \"\u4eca\u65e5\u306e\u5929\u6c17\u306f\u3069\u3046\u3067\u3059\u304b\uff1f\"\n]\n\nfor example in examples:\n    result = await flow.run(input_data=example)\n    print(f\"\u5165\u529b: {example}\")\n    print(result.shared_state[\"final_response\"])\n    print(\"-\" * 50)\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_3","title":"\u72b6\u614b\u7ba1\u7406\u3068\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8","text":""},{"location":"composable-flow-architecture_ja/#context","title":"Context \u30af\u30e9\u30b9\u306e\u6d3b\u7528","text":"<pre><code>from refinire import Context\n\ndef step_with_state(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30b9\u30c6\u30c3\u30d7\u9593\u3067\u306e\u30c7\u30fc\u30bf\u5171\u6709\u4f8b\"\"\"\n    # English: Example of data sharing between steps\n\n    # \u524d\u306e\u30b9\u30c6\u30c3\u30d7\u306e\u7d50\u679c\u3092\u53d6\u5f97\n    previous_data = ctx.shared_state.get(\"previous_result\", None)\n\n    # \u73fe\u5728\u306e\u30b9\u30c6\u30c3\u30d7\u3067\u51e6\u7406\n    current_result = process_data(user_input, previous_data)\n\n    # \u6b21\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u7d50\u679c\u3092\u6e21\u3059\n    ctx.shared_state[\"current_result\"] = current_result\n\n    # \u30e6\u30fc\u30b6\u30fc\u5165\u529b\u3082\u4fdd\u6301\n    ctx.shared_state[\"original_input\"] = ctx.user_input\n\n    # \u30e1\u30bf\u30c7\u30fc\u30bf\u306e\u8ffd\u52a0\n    ctx.shared_state[\"processing_time\"] = time.time()\n\n    return ctx\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_4","title":"\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0","text":"<pre><code>def safe_processing_step(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u3092\u542b\u3080\u30b9\u30c6\u30c3\u30d7\"\"\"\n    # English: Step with error handling\n    try:\n        result = risky_operation(user_input)\n        ctx.shared_state[\"result\"] = result\n        ctx.shared_state[\"status\"] = \"success\"\n    except Exception as e:\n        ctx.shared_state[\"error\"] = str(e)\n        ctx.shared_state[\"status\"] = \"error\"\n        # \u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u3066\u3082\u30d5\u30ed\u30fc\u3092\u7d99\u7d9a\n\n    return ctx\n\ndef error_recovery_step(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30a8\u30e9\u30fc\u56de\u5fa9\u51e6\u7406\"\"\"\n    # English: Error recovery processing\n    if ctx.shared_state.get(\"status\") == \"error\":\n        # \u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af\u51e6\u7406\n        ctx.shared_state[\"result\"] = \"\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u56de\u7b54\u3092\u4f7f\u7528\u3057\u307e\u3059\"\n        ctx.shared_state[\"status\"] = \"recovered\"\n\n    return ctx\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_5","title":"\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316","text":""},{"location":"composable-flow-architecture_ja/#_6","title":"\u4e26\u5217\u51e6\u7406\u306b\u3088\u308b\u9ad8\u901f\u5316","text":"<p>\u4e26\u5217\u51e6\u7406\u3092\u4f7f\u3046\u3053\u3068\u3067\u3001\u72ec\u7acb\u3057\u305f\u30bf\u30b9\u30af\u3092\u540c\u6642\u5b9f\u884c\u3057\u3001\u5927\u5e45\u306a\u6027\u80fd\u5411\u4e0a\u3092\u5b9f\u73fe\u3067\u304d\u307e\u3059\u3002</p> <pre><code># \u9806\u6b21\u5b9f\u884c\uff08\u5f93\u6765\uff09: 4\u3064\u306e\u30bf\u30b9\u30af \u00d7 0.5\u79d2 = 2.0\u79d2\n# \u4e26\u5217\u5b9f\u884c\uff08Refinire\uff09: max(0.5\u79d2) = 0.5\u79d2\uff083.9\u500d\u9ad8\u901f\u5316\uff09\n\nflow = Flow({\n    \"preprocess\": FunctionStep(\"prep\", preprocess_data),\n    \"parallel_tasks\": {\n        \"parallel\": [\n            FunctionStep(\"task1\", time_consuming_task1),  # 0.5\u79d2\n            FunctionStep(\"task2\", time_consuming_task2),  # 0.5\u79d2  \n            FunctionStep(\"task3\", time_consuming_task3),  # 0.5\u79d2\n            FunctionStep(\"task4\", time_consuming_task4),  # 0.5\u79d2\n        ],\n        \"max_workers\": 4,\n        \"next_step\": \"aggregate\"\n    },\n    \"aggregate\": FunctionStep(\"agg\", combine_results)\n})\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_7","title":"\u30e1\u30e2\u30ea\u52b9\u7387\u7684\u306a\u51e6\u7406","text":"<pre><code>def memory_efficient_step(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30e1\u30e2\u30ea\u52b9\u7387\u3092\u8003\u616e\u3057\u305f\u30b9\u30c6\u30c3\u30d7\"\"\"\n    # English: Memory-efficient step\n\n    # \u5927\u304d\u306a\u30c7\u30fc\u30bf\u306f\u9069\u5207\u306b\u7ba1\u7406\n    large_data = process_large_dataset(user_input)\n\n    # \u5fc5\u8981\u306a\u90e8\u5206\u306e\u307f\u4fdd\u6301\n    ctx.shared_state[\"summary\"] = summarize(large_data)\n\n    # \u5927\u304d\u306a\u30c7\u30fc\u30bf\u306f\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\n    del large_data\n\n    return ctx\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_8","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"composable-flow-architecture_ja/#1","title":"1. \u30b9\u30c6\u30c3\u30d7\u306e\u5358\u4e00\u8cac\u52d9\u539f\u5247","text":"<p>\u5404\u30b9\u30c6\u30c3\u30d7\u306f\u4e00\u3064\u306e\u660e\u78ba\u306a\u8cac\u52d9\u3092\u6301\u3064\u3079\u304d\u3067\u3059\u3002</p> <pre><code># \u826f\u3044\u4f8b\uff1a\u8cac\u52d9\u304c\u660e\u78ba\ndef validate_input(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u5165\u529b\u691c\u8a3c\u306e\u307f\u3092\u884c\u3046\"\"\"\n    # English: Only perform input validation\n    if not user_input.strip():\n        raise ValueError(\"\u5165\u529b\u304c\u7a7a\u3067\u3059\")\n    ctx.shared_state[\"validated\"] = True\n    return ctx\n\ndef process_data(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30c7\u30fc\u30bf\u51e6\u7406\u306e\u307f\u3092\u884c\u3046\"\"\"\n    # English: Only perform data processing\n    processed = user_input.lower().strip()\n    ctx.shared_state[\"processed_data\"] = processed\n    return ctx\n\n# \u60aa\u3044\u4f8b\uff1a\u8907\u6570\u306e\u8cac\u52d9\u3092\u6301\u3064\ndef validate_and_process(user_input: str, ctx: Context) -&gt; Context:\n    # \u691c\u8a3c\u3068\u51e6\u7406\u3092\u4e00\u3064\u306e\u30b9\u30c6\u30c3\u30d7\u3067\u884c\u3046\uff08\u63a8\u5968\u3055\u308c\u306a\u3044\uff09\n    if not user_input.strip():\n        raise ValueError(\"\u5165\u529b\u304c\u7a7a\u3067\u3059\")\n    processed = user_input.lower().strip()\n    ctx.shared_state[\"result\"] = processed\n    return ctx\n</code></pre>"},{"location":"composable-flow-architecture_ja/#2","title":"2. \u660e\u793a\u7684\u306a\u30d5\u30ed\u30fc\u7d42\u4e86","text":"<p>\u30d5\u30ed\u30fc\u306e\u7d42\u4e86\u306f\u660e\u793a\u7684\u306b\u793a\u3059\u3079\u304d\u3067\u3059\u3002</p> <pre><code>def final_step(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u6700\u7d42\u30b9\u30c6\u30c3\u30d7\u3067\u306f\u660e\u793a\u7684\u306b\u7d42\u4e86\"\"\"\n    # English: Explicitly end in final step\n    ctx.shared_state[\"final_result\"] = \"\u51e6\u7406\u5b8c\u4e86\"\n    ctx.finish()  # \u660e\u793a\u7684\u306a\u7d42\u4e86\n    return ctx\n</code></pre>"},{"location":"composable-flow-architecture_ja/#3","title":"3. \u518d\u5229\u7528\u53ef\u80fd\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u8a2d\u8a08","text":"<pre><code># \u518d\u5229\u7528\u53ef\u80fd\u306a\u691c\u8a3c\u30b9\u30c6\u30c3\u30d7\ndef create_validation_step(validation_func, error_message):\n    \"\"\"\u691c\u8a3c\u30b9\u30c6\u30c3\u30d7\u306e\u30d5\u30a1\u30af\u30c8\u30ea\u95a2\u6570\"\"\"\n    # English: Factory function for validation steps\n    def validate(user_input: str, ctx: Context) -&gt; Context:\n        if not validation_func(user_input):\n            raise ValueError(error_message)\n        ctx.shared_state[\"validated\"] = True\n        return ctx\n    return FunctionStep(\"validate\", validate)\n\n# \u4f7f\u7528\u4f8b\nemail_validator = create_validation_step(\n    lambda x: \"@\" in x, \n    \"\u6709\u52b9\u306a\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044\"\n)\n\nphone_validator = create_validation_step(\n    lambda x: x.replace(\"-\", \"\").isdigit(),\n    \"\u6709\u52b9\u306a\u96fb\u8a71\u756a\u53f7\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044\"\n)\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_9","title":"\u5b9f\u4e16\u754c\u3067\u306e\u5fdc\u7528\u4f8b","text":""},{"location":"composable-flow-architecture_ja/#_10","title":"\u30ab\u30b9\u30bf\u30de\u30fc\u30b5\u30dd\u30fc\u30c8\u30b7\u30b9\u30c6\u30e0","text":"<pre><code># \u9867\u5ba2\u554f\u3044\u5408\u308f\u305b\u51e6\u7406\u30d5\u30ed\u30fc\ncustomer_support_flow = Flow({\n    \"classify\": FunctionStep(\"classify\", classify_inquiry),\n    \"router\": ConditionStep(\"route\", route_by_category, \n                          \"technical\", \"billing\", \"general\"),\n    \"technical\": technical_support_agent,\n    \"billing\": billing_support_agent,\n    \"general\": general_support_agent,\n    \"quality_check\": quality_assurance_step,\n    \"escalate\": ConditionStep(\"escalate\", \n                            lambda ctx: \"manager\" if ctx.shared_state[\"quality_score\"] &lt; 80 else \"complete\",\n                            \"manager\", \"complete\"),\n    \"manager\": manager_review_agent,\n    \"complete\": finalize_response\n})\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_11","title":"\u30b3\u30f3\u30c6\u30f3\u30c4\u751f\u6210\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3","text":"<pre><code># \u30d6\u30ed\u30b0\u8a18\u4e8b\u751f\u6210\u30d5\u30ed\u30fc\ncontent_generation_flow = Flow({\n    \"research\": research_agent,\n    \"outline\": outline_generator_agent,\n    \"parallel_writing\": {\n        \"parallel\": [\n            FunctionStep(\"intro\", write_introduction),\n            FunctionStep(\"body\", write_body),\n            FunctionStep(\"conclusion\", write_conclusion)\n        ],\n        \"next_step\": \"assemble\"\n    },\n    \"assemble\": FunctionStep(\"assemble\", combine_sections),\n    \"review\": editorial_review_agent,\n    \"publish\": FunctionStep(\"publish\", publish_content)\n})\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_12","title":"\u30c7\u30fc\u30bf\u5206\u6790\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3","text":"<pre><code># \u30c7\u30fc\u30bf\u5206\u6790\u30d5\u30ed\u30fc\ndata_analysis_flow = Flow({\n    \"validate\": data_validation_step,\n    \"clean\": data_cleaning_step,\n    \"parallel_analysis\": {\n        \"parallel\": [\n            FunctionStep(\"stats\", statistical_analysis),\n            FunctionStep(\"trends\", trend_analysis),\n            FunctionStep(\"patterns\", pattern_recognition),\n            FunctionStep(\"anomalies\", anomaly_detection)\n        ],\n        \"max_workers\": 4,\n        \"next_step\": \"correlate\"\n    },\n    \"correlate\": correlation_analysis_step,\n    \"visualize\": visualization_step,\n    \"report\": report_generation_agent\n})\n</code></pre>"},{"location":"composable-flow-architecture_ja/#_13","title":"\u307e\u3068\u3081","text":"<p>Refinire\u306e\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306f\uff1a</p> <ol> <li>\u30b7\u30f3\u30d7\u30eb\u3055: <code>Flow(steps=agent)</code> \u3067\u59cb\u307e\u308a\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u8907\u96d1\u5316</li> <li>\u67d4\u8edf\u6027: \u6761\u4ef6\u5206\u5c90\u3001\u4e26\u5217\u51e6\u7406\u3001\u30eb\u30fc\u30d7\u306a\u3069\u8c4a\u5bcc\u306a\u5236\u5fa1\u69cb\u9020</li> <li>\u518d\u5229\u7528\u6027: \u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u30d9\u30fc\u30b9\u306e\u8a2d\u8a08\u3067\u9ad8\u3044\u518d\u5229\u7528\u6027</li> <li>\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9: \u4e26\u5217\u51e6\u7406\u30673.9\u500d\u306e\u9ad8\u901f\u5316\u3092\u5b9f\u73fe</li> <li>\u4fdd\u5b88\u6027: \u5ba3\u8a00\u7684\u8a2d\u5b9a\u3068\u660e\u78ba\u306a\u72b6\u614b\u7ba1\u7406</li> </ol> <p>\u5f93\u6765\u306e\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u69cb\u7bc9\u304b\u3089\u3001\u76f4\u611f\u7684\u3067\u4fdd\u5b88\u53ef\u80fd\u306a\u8a2d\u8a08\u3078\u306e\u30d1\u30e9\u30c0\u30a4\u30e0\u30b7\u30d5\u30c8\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002 </p>"},{"location":"concept/","title":"\u5bfe\u5fdc\u3059\u308b\u8ab2\u984c","text":"<p>OpenAI Agents SDK\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u306f\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u308b\u306e\u306f\u3001OpenAI\u304c\u63d0\u4f9b\u3059\u308bLLM\u306e\u307f\u3067\u3042\u308b\u3002\u305d\u306e\u305f\u3081\u3001Ollama\u3084Anthropic,Google\u306a\u3069\u306e\u6709\u529b\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002</p> <p>\u305d\u3053\u3067\u3001OpenAI Agents\u3067\u52d5\u4f5c\u3059\u308b\u5404LLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u3055\u307d\u30fc\u3068\u3067\u304d\u308b\u3088\u3046\u306b\u3059\u308b\u3082\u306e\u3067\u3042\u308b\u3002</p>"},{"location":"concept/#_2","title":"\u5bfe\u5fdc\u30d7\u30ed\u30d0\u30a4\u30c0","text":"<ul> <li>Ollama</li> <li>Gemini</li> <li>Claude</li> </ul>"},{"location":"concept/#_3","title":"\u5bfe\u5fdc\u65b9\u6cd5","text":"<p>OpenAI Agents\u3067\u306f\u5404\u30c1\u30e3\u30c3\u30c8\u30e2\u30c7\u30eb\u306fModel\u30af\u30e9\u30b9\u3068ModelFactory\u30af\u30e9\u30b9\u3092\u63d0\u4f9b\u3057\u3066\u304a\u308a\u3001\u4e0b\u8a18\u3001URL\u306e\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306b\u306a\u3089\u3063\u305f\u30af\u30e9\u30b9\u3092\u63d0\u4f9b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>@https://github.com/openai/openai-agents-python/blob/main/src/agents/models/interface.py</p> <p>Model\u30af\u30e9\u30b9\u306f\u7279\u306bOpenAI\u306e\u30e2\u30c7\u30eb\u3068\u5165\u51fa\u529b\u3092\u63c3\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u3001\u4e0b\u8a18\u306e\u5165\u51fa\u529b\u306b\u5b8c\u5168\u306b\u5408\u308f\u305b\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>@https://github.com/openai/openai-agents-python/blob/main/src/agents/models/openai_chatcompletions.py</p>"},{"location":"context_management/","title":"\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u8a2d\u8a08\u66f8","text":""},{"location":"context_management/#_2","title":"\u6982\u8981","text":"<p>RefinireAgent\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u6a5f\u80fd\u306f\u3001AI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u52b9\u7387\u7684\u304b\u3064\u52b9\u679c\u7684\u306b\u4f1a\u8a71\u5c65\u6b74\u3001\u6587\u8108\u60c5\u5831\u3001\u9577\u671f\u8a18\u61b6\u3092\u7ba1\u7406\u3057\u3001\u9069\u5207\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092LLM\u306b\u63d0\u4f9b\u3059\u308b\u305f\u3081\u306e\u30b7\u30b9\u30c6\u30e0\u3067\u3059\u3002</p>"},{"location":"context_management/#_3","title":"\u8a2d\u8a08\u539f\u5247","text":""},{"location":"context_management/#_4","title":"\u6975\u9650\u307e\u3067\u7d5e\u3063\u305f\u8a2d\u8a08\u601d\u60f3","text":"<ol> <li>\u5358\u4e00\u8cac\u4efb: \u5404\u30af\u30e9\u30b9\u306f\u4e00\u3064\u306e\u5f79\u5272\u306e\u307f\u3092\u6301\u3064</li> <li>\u6700\u5c0f\u9650\u306e\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9: \u5fc5\u8981\u6700\u5c0f\u9650\u306e\u30e1\u30bd\u30c3\u30c9\u306e\u307f</li> <li>\u76f4\u611f\u7684\u306a\u7d71\u5408: RefinireAgent\u3078\u306e\u5909\u66f4\u3092\u6700\u5c0f\u9650\u306b</li> <li>\u62e1\u5f35\u3057\u3084\u3059\u3044: \u65b0\u3057\u3044\u6a5f\u80fd\u306e\u8ffd\u52a0\u304c\u5bb9\u6613</li> <li>\u7406\u89e3\u3057\u3084\u3059\u3044: \u8907\u96d1\u306a\u62bd\u8c61\u5316\u3092\u907f\u3051\u308b</li> <li>\u6587\u5b57\u5217\u6307\u5b9a: YAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u3067\u76f4\u611f\u7684\u306b\u8a2d\u5b9a</li> <li>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u9023\u9396: \u524d\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u4f9d\u5b58\u3059\u308b\u52d5\u4f5c\u3092\u30b5\u30dd\u30fc\u30c8</li> </ol>"},{"location":"context_management/#_5","title":"\u73fe\u5728\u306e\u5b9f\u88c5\u72b6\u6cc1","text":""},{"location":"context_management/#_6","title":"\u65e2\u5b58\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u6a5f\u80fd","text":"\u6a5f\u80fd \u5b9f\u88c5\u72b6\u6cc1 \u8aac\u660e \u30bb\u30c3\u30b7\u30e7\u30f3\u5c65\u6b74 \u2705 \u5b9f\u88c5\u6e08\u307f <code>session_history</code>\u3067\u4f1a\u8a71\u5c65\u6b74\u3092\u7ba1\u7406 \u5c65\u6b74\u30b5\u30a4\u30ba\u5236\u9650 \u2705 \u5b9f\u88c5\u6e08\u307f <code>history_size</code>\u3067\u5c65\u6b74\u306e\u6700\u5927\u6570\u3092\u5236\u9650 \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u5c65\u6b74 \u2705 \u5b9f\u88c5\u6e08\u307f <code>_pipeline_history</code>\u3067\u8a73\u7d30\u306a\u5b9f\u884c\u5c65\u6b74\u3092\u7ba1\u7406 \u30d7\u30ed\u30f3\u30d7\u30c8\u69cb\u7bc9 \u2705 \u5b9f\u88c5\u6e08\u307f <code>_build_prompt</code>\u3067\u6307\u793a\u6587\u3068\u5c65\u6b74\u3092\u7d44\u307f\u5408\u308f\u305b"},{"location":"context_management/#_7","title":"\u73fe\u5728\u306e\u5236\u9650\u4e8b\u9805","text":"<ol> <li>\u5358\u7d14\u306a\u5c65\u6b74\u7ba1\u7406: \u6642\u7cfb\u5217\u9806\u306e\u5358\u7d14\u306a\u5c65\u6b74\u306e\u307f</li> <li>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u5727\u7e2e\u306a\u3057: \u9577\u3044\u4f1a\u8a71\u3067\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u9577\u3092\u8d85\u904e\u3059\u308b\u53ef\u80fd\u6027</li> <li>\u6587\u8108\u95a2\u9023\u6027\u306e\u8003\u616e\u306a\u3057: \u73fe\u5728\u306e\u8cea\u554f\u306b\u95a2\u9023\u3059\u308b\u5c65\u6b74\u306e\u9078\u629e\u6a5f\u80fd\u306a\u3057</li> <li>\u5916\u90e8\u60c5\u5831\u306e\u7d71\u5408\u306a\u3057: \u30d5\u30a1\u30a4\u30eb\u3001\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3001\u9577\u671f\u8a18\u61b6\u306e\u7d71\u5408\u6a5f\u80fd\u306a\u3057</li> </ol>"},{"location":"context_management/#_8","title":"\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u30b1\u30fc\u30b9","text":""},{"location":"context_management/#1","title":"1. \u4f1a\u8a71\u5c65\u6b74\u306e\u7ba1\u7406","text":"<p>\u76ee\u7684: \u904e\u53bb\u306e\u4f1a\u8a71\u3092\u73fe\u5728\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u8ffd\u52a0</p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u4ee5\u524d\u306e\u4f1a\u8a71\u3067\u6c7a\u5b9a\u3057\u305f\u5185\u5bb9\u3092\u53c2\u7167 - \u7d99\u7d9a\u7684\u306a\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u6587\u8108\u3092\u7dad\u6301 - \u30e6\u30fc\u30b6\u30fc\u306e\u597d\u307f\u3084\u8a2d\u5b9a\u306e\u8a18\u61b6</p>"},{"location":"context_management/#2","title":"2. \u56fa\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u7d71\u5408","text":"<p>\u76ee\u7684: \u7279\u5b9a\u306e\u30d5\u30a1\u30a4\u30eb\u5185\u5bb9\u3092\u5e38\u306b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u542b\u3081\u308b</p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb - \u30b7\u30b9\u30c6\u30e0\u306e\u4ed5\u69d8\u66f8 - \u30e6\u30fc\u30b6\u30fc\u306e\u30d7\u30ed\u30d5\u30a3\u30fc\u30eb\u60c5\u5831</p>"},{"location":"context_management/#3","title":"3. \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306e\u691c\u7d22","text":"<p>\u76ee\u7684: \u73fe\u5728\u306e\u4f1a\u8a71\u306b\u95a2\u9023\u3059\u308b\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u81ea\u52d5\u691c\u7d22</p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30b3\u30fc\u30c9\u30ec\u30d3\u30e5\u30fc\u306e\u969b\u306e\u95a2\u9023\u30d5\u30a1\u30a4\u30eb\u53c2\u7167 - \u30d0\u30b0\u4fee\u6b63\u6642\u306e\u95a2\u9023\u30b3\u30fc\u30c9\u7279\u5b9a - \u6a5f\u80fd\u8ffd\u52a0\u6642\u306e\u65e2\u5b58\u5b9f\u88c5\u78ba\u8a8d</p>"},{"location":"context_management/#4","title":"4. \u9577\u671f\u8a18\u61b6\u306e\u7d71\u5408","text":"<p>\u76ee\u7684: \u6c38\u7d9a\u7684\u306a\u8a18\u61b6\u30b7\u30b9\u30c6\u30e0\u3068\u306e\u7d71\u5408</p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30e6\u30fc\u30b6\u30fc\u306e\u5b66\u7fd2\u5c65\u6b74 - \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u91cd\u8981\u306a\u6c7a\u5b9a\u4e8b\u9805 - \u30b7\u30b9\u30c6\u30e0\u306e\u8a2d\u5b9a\u5909\u66f4\u5c65\u6b74</p>"},{"location":"context_management/#5","title":"5. \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u5727\u7e2e","text":"<p>\u76ee\u7684: \u30e2\u30c7\u30eb\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u9577\u306b\u5408\u308f\u305b\u3066\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u5727\u7e2e</p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u9577\u3044\u4f1a\u8a71\u5c65\u6b74\u306e\u8981\u7d04 - \u91cd\u8981\u306a\u60c5\u5831\u306e\u62bd\u51fa - \u30c8\u30fc\u30af\u30f3\u6570\u306e\u6700\u9069\u5316</p>"},{"location":"context_management/#6","title":"6. \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0","text":"<p>\u76ee\u7684: \u524d\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u57fa\u306b\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0</p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u95a2\u9023\u6027\u306e\u4f4e\u3044\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306e\u9664\u53bb - \u91cd\u8981\u5ea6\u306b\u57fa\u3065\u304f\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u9078\u629e - \u91cd\u8907\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306e\u9664\u53bb</p>"},{"location":"context_management/#api","title":"\u6975\u9650\u307e\u3067\u7d5e\u3063\u305fAPI\u8a2d\u8a08","text":""},{"location":"context_management/#contextprovider","title":"ContextProvider \u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\uff08\u552f\u4e00\u306e\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\uff09","text":"<pre><code>from abc import ABC, abstractmethod\nfrom typing import Dict, Any, ClassVar, Optional\n\nclass ContextProvider(ABC):\n    \"\"\"Single interface for all context providers\n    \u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u552f\u4e00\u306e\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\n    \"\"\"\n\n    # Class variable for provider name\n    # \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u540d\u306e\u30af\u30e9\u30b9\u5909\u6570\n    provider_name: ClassVar[str] = \"base\"\n\n    @classmethod\n    def get_config_schema(cls) -&gt; Dict[str, Any]:\n        \"\"\"Get configuration schema for this provider\n        \u3053\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n\n        Returns:\n            Dict[str, Any]: Configuration schema with parameter descriptions\n            Dict[str, Any]: \u30d1\u30e9\u30e1\u30fc\u30bf\u8aac\u660e\u3092\u542b\u3080\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\n        \"\"\"\n        return {\n            \"description\": \"Base context provider\",\n            \"parameters\": {},\n            \"example\": \"base: {}\"\n        }\n\n    @classmethod\n    def from_config(cls, config: Dict[str, Any]) -&gt; 'ContextProvider':\n        \"\"\"Create provider instance from configuration\n        \u8a2d\u5b9a\u304b\u3089\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n\n        Args:\n            config: Configuration dictionary / \u8a2d\u5b9a\u8f9e\u66f8\n\n        Returns:\n            ContextProvider: Provider instance / \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n        \"\"\"\n        return cls(**config)\n\n    @abstractmethod\n    def get_context(self, query: str, previous_context: Optional[str] = None, **kwargs) -&gt; str:\n        \"\"\"Get context for the given query\n        \u4e0e\u3048\u3089\u308c\u305f\u30af\u30a8\u30ea\u7528\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u53d6\u5f97\n\n        Args:\n            query: Current user query / \u73fe\u5728\u306e\u30e6\u30fc\u30b6\u30fc\u30af\u30a8\u30ea\n            previous_context: Context provided by previous providers / \u524d\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u304c\u63d0\u4f9b\u3057\u305f\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\n            **kwargs: Additional parameters / \u8ffd\u52a0\u30d1\u30e9\u30e1\u30fc\u30bf\n\n        Returns:\n            str: Context string (empty string if no context) / \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u6587\u5b57\u5217\uff08\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304c\u306a\u3044\u5834\u5408\u306f\u7a7a\u6587\u5b57\u5217\uff09\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update(self, interaction: Dict[str, Any]) -&gt; None:\n        \"\"\"Update provider with new interaction\n        \u65b0\u3057\u3044\u5bfe\u8a71\u3067\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u66f4\u65b0\n\n        Args:\n            interaction: Interaction data / \u5bfe\u8a71\u30c7\u30fc\u30bf\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def clear(self) -&gt; None:\n        \"\"\"Clear all stored context\n        \u4fdd\u5b58\u3055\u308c\u305f\u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u30af\u30ea\u30a2\n        \"\"\"\n        pass\n</code></pre>"},{"location":"context_management/#_9","title":"\u5177\u4f53\u7684\u306a\u5b9f\u88c5","text":""},{"location":"context_management/#conversationhistoryprovider","title":"ConversationHistoryProvider","text":"<pre><code>from typing import List, Dict, Any, ClassVar, Optional\n\nclass ConversationHistoryProvider(ContextProvider):\n    \"\"\"Provides conversation history context\n    \u4f1a\u8a71\u5c65\u6b74\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u63d0\u4f9b\n    \"\"\"\n\n    provider_name: ClassVar[str] = \"conversation\"\n\n    def __init__(self, history: List[str] = None, max_items: int = 10):\n        self.history = history or []\n        self.max_items = max_items\n\n    @classmethod\n    def get_config_schema(cls) -&gt; Dict[str, Any]:\n        \"\"\"Get configuration schema for conversation history provider\n        \u4f1a\u8a71\u5c65\u6b74\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n        \"\"\"\n        return {\n            \"description\": \"Provides conversation history context\",\n            \"parameters\": {\n                \"max_items\": {\n                    \"type\": \"int\",\n                    \"default\": 10,\n                    \"description\": \"Maximum number of conversation items to keep\"\n                }\n            },\n            \"example\": \"\"\"\nconversation:\n  max_items: 5\n            \"\"\".strip()\n        }\n\n    def get_context(self, query: str, previous_context: Optional[str] = None, **kwargs) -&gt; str:\n        \"\"\"Get relevant conversation history\n        \u95a2\u9023\u3059\u308b\u4f1a\u8a71\u5c65\u6b74\u3092\u53d6\u5f97\n        \"\"\"\n        if not self.history:\n            return \"\"\n\n        # Simple implementation: return recent history\n        recent_history = self.history[-self.max_items:]\n        return \"\\n\".join(recent_history)\n\n    def update(self, interaction: Dict[str, Any]) -&gt; None:\n        \"\"\"Add new interaction to history\n        \u65b0\u3057\u3044\u5bfe\u8a71\u3092\u5c65\u6b74\u306b\u8ffd\u52a0\n        \"\"\"\n        user_input = interaction.get(\"user_input\", \"\")\n        result = interaction.get(\"result\", \"\")\n\n        if user_input and result:\n            entry = f\"User: {user_input}\\nAssistant: {result}\"\n            self.history.append(entry)\n\n            # Keep only recent items\n            if len(self.history) &gt; self.max_items:\n                self.history = self.history[-self.max_items:]\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear conversation history\n        \u4f1a\u8a71\u5c65\u6b74\u3092\u30af\u30ea\u30a2\n        \"\"\"\n        self.history.clear()\n</code></pre>"},{"location":"context_management/#fixedfileprovider","title":"FixedFileProvider","text":"<pre><code>class FixedFileProvider(ContextProvider):\n    \"\"\"Provides fixed file content as context\n    \u56fa\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u3092\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3068\u3057\u3066\u63d0\u4f9b\n    \"\"\"\n\n    provider_name: ClassVar[str] = \"fixed_file\"\n\n    def __init__(self, file_path: str, description: str = \"\"):\n        self.file_path = file_path\n        self.description = description\n        self._content = \"\"\n        self._load_content()\n\n    @classmethod\n    def get_config_schema(cls) -&gt; Dict[str, Any]:\n        \"\"\"Get configuration schema for fixed file provider\n        \u56fa\u5b9a\u30d5\u30a1\u30a4\u30eb\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n        \"\"\"\n        return {\n            \"description\": \"Provides fixed file content as context\",\n            \"parameters\": {\n                \"file_path\": {\n                    \"type\": \"str\",\n                    \"required\": True,\n                    \"description\": \"Path to the file to include in context\"\n                },\n                \"description\": {\n                    \"type\": \"str\",\n                    \"default\": \"\",\n                    \"description\": \"Description of the file content\"\n                }\n            },\n            \"example\": \"\"\"\nfixed_file:\n  file_path: \"project_config.json\"\n  description: \"Project Configuration\"\n            \"\"\".strip()\n        }\n\n    def _load_content(self) -&gt; None:\n        \"\"\"Load file content\n        \u30d5\u30a1\u30a4\u30eb\u5185\u5bb9\u3092\u8aad\u307f\u8fbc\u307f\n        \"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                self._content = f.read()\n        except Exception as e:\n            self._content = f\"Error loading file: {e}\"\n\n    def get_context(self, query: str, previous_context: Optional[str] = None, **kwargs) -&gt; str:\n        \"\"\"Get fixed file content\n        \u56fa\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u3092\u53d6\u5f97\n        \"\"\"\n        if not self._content:\n            return \"\"\n\n        context = f\"Fixed Context ({self.description}):\\n{self._content}\"\n        return context\n\n    def update(self, interaction: Dict[str, Any]) -&gt; None:\n        \"\"\"Reload file content\n        \u30d5\u30a1\u30a4\u30eb\u5185\u5bb9\u3092\u518d\u8aad\u307f\u8fbc\u307f\n        \"\"\"\n        self._load_content()\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear file content\n        \u30d5\u30a1\u30a4\u30eb\u5185\u5bb9\u3092\u30af\u30ea\u30a2\n        \"\"\"\n        self._content = \"\"\n</code></pre>"},{"location":"context_management/#sourcecodeprovider","title":"SourceCodeProvider","text":"<pre><code>import os\nfrom typing import List, ClassVar, Optional\n\nclass SourceCodeProvider(ContextProvider):\n    \"\"\"Provides relevant source code as context\n    \u95a2\u9023\u3059\u308b\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3068\u3057\u3066\u63d0\u4f9b\n    \"\"\"\n\n    provider_name: ClassVar[str] = \"source_code\"\n\n    def __init__(self, codebase_path: str = \"./src\", max_files: int = 5):\n        self.codebase_path = codebase_path\n        self.max_files = max_files\n\n    @classmethod\n    def get_config_schema(cls) -&gt; Dict[str, Any]:\n        \"\"\"Get configuration schema for source code provider\n        \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n        \"\"\"\n        return {\n            \"description\": \"Provides relevant source code as context\",\n            \"parameters\": {\n                \"codebase_path\": {\n                    \"type\": \"str\",\n                    \"default\": \"./src\",\n                    \"description\": \"Path to the codebase to search\"\n                },\n                \"max_files\": {\n                    \"type\": \"int\",\n                    \"default\": 5,\n                    \"description\": \"Maximum number of files to include\"\n                }\n            },\n            \"example\": \"\"\"\nsource_code:\n  codebase_path: \"./src\"\n  max_files: 3\n            \"\"\".strip()\n        }\n\n    def get_context(self, query: str, previous_context: Optional[str] = None, **kwargs) -&gt; str:\n        \"\"\"Get relevant source code\n        \u95a2\u9023\u3059\u308b\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u53d6\u5f97\n        \"\"\"\n        relevant_files = self._find_relevant_files(query)\n\n        if not relevant_files:\n            return \"\"\n\n        context_parts = [\"Relevant Source Code:\"]\n        for file_path in relevant_files[:self.max_files]:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                    context_parts.append(f\"File: {file_path}\\n{content}\")\n            except Exception:\n                continue\n\n        return \"\\n\\n\".join(context_parts)\n\n    def _find_relevant_files(self, query: str) -&gt; List[str]:\n        \"\"\"Find files relevant to the query\n        \u30af\u30a8\u30ea\u306b\u95a2\u9023\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u691c\u7d22\n        \"\"\"\n        relevant_files = []\n        search_terms = query.lower().split()\n\n        for root, dirs, files in os.walk(self.codebase_path):\n            for file in files:\n                if file.endswith(('.py', '.js', '.ts', '.java', '.cpp', '.h')):\n                    file_path = os.path.join(root, file)\n                    file_lower = file.lower()\n\n                    if any(term in file_lower for term in search_terms):\n                        relevant_files.append(file_path)\n\n        return relevant_files\n\n    def update(self, interaction: Dict[str, Any]) -&gt; None:\n        \"\"\"No update needed for source code provider\n        \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u306f\u66f4\u65b0\u306f\u4e0d\u8981\n        \"\"\"\n        pass\n\n    def clear(self) -&gt; None:\n        \"\"\"No clear needed for source code provider\n        \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u306f\u30af\u30ea\u30a2\u306f\u4e0d\u8981\n        \"\"\"\n        pass\n</code></pre>"},{"location":"context_management/#contextcompressorprovider","title":"ContextCompressorProvider","text":"<pre><code>import re\nfrom typing import ClassVar, Optional\n\nclass ContextCompressorProvider(ContextProvider):\n    \"\"\"Compresses context to fit within token limits\n    \u30c8\u30fc\u30af\u30f3\u5236\u9650\u5185\u306b\u53ce\u3081\u308b\u305f\u3081\u306b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u5727\u7e2e\n    \"\"\"\n\n    provider_name: ClassVar[str] = \"compressor\"\n\n    def __init__(self, max_tokens: int = 8000, compression_ratio: float = 0.7):\n        self.max_tokens = max_tokens\n        self.compression_ratio = compression_ratio\n\n    @classmethod\n    def get_config_schema(cls) -&gt; Dict[str, Any]:\n        \"\"\"Get configuration schema for context compressor provider\n        \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u5727\u7e2e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n        \"\"\"\n        return {\n            \"description\": \"Compresses context to fit within token limits\",\n            \"parameters\": {\n                \"max_tokens\": {\n                    \"type\": \"int\",\n                    \"default\": 8000,\n                    \"description\": \"Maximum number of tokens to allow\"\n                },\n                \"compression_ratio\": {\n                    \"type\": \"float\",\n                    \"default\": 0.7,\n                    \"description\": \"Compression ratio (0.0 to 1.0)\"\n                }\n            },\n            \"example\": \"\"\"\ncompressor:\n  max_tokens: 6000\n  compression_ratio: 0.8\n            \"\"\".strip()\n        }\n\n    def get_context(self, query: str, previous_context: Optional[str] = None, **kwargs) -&gt; str:\n        \"\"\"Compress previous context to fit within token limits\n        \u524d\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u30c8\u30fc\u30af\u30f3\u5236\u9650\u5185\u306b\u53ce\u3081\u308b\u3088\u3046\u306b\u5727\u7e2e\n        \"\"\"\n        if not previous_context:\n            return \"\"\n\n        # Simple token estimation (rough approximation)\n        estimated_tokens = len(previous_context.split()) * 1.3\n\n        if estimated_tokens &lt;= self.max_tokens:\n            return previous_context\n\n        # Compress context by keeping important parts\n        compressed_context = self._compress_context(previous_context)\n        return compressed_context\n\n    def _compress_context(self, context: str) -&gt; str:\n        \"\"\"Compress context by keeping important parts\n        \u91cd\u8981\u306a\u90e8\u5206\u3092\u4fdd\u6301\u3057\u3066\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u5727\u7e2e\n        \"\"\"\n        lines = context.split('\\n')\n        compressed_lines = []\n\n        # Keep first and last parts, compress middle\n        if len(lines) &lt;= 10:\n            return context\n\n        # Keep first 30% and last 30%\n        first_count = int(len(lines) * 0.3)\n        last_count = int(len(lines) * 0.3)\n\n        compressed_lines.extend(lines[:first_count])\n        compressed_lines.append(\"... (compressed content) ...\")\n        compressed_lines.extend(lines[-last_count:])\n\n        return '\\n'.join(compressed_lines)\n\n    def update(self, interaction: Dict[str, Any]) -&gt; None:\n        \"\"\"No update needed for compressor provider\n        \u5727\u7e2e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u306f\u66f4\u65b0\u306f\u4e0d\u8981\n        \"\"\"\n        pass\n\n    def clear(self) -&gt; None:\n        \"\"\"No clear needed for compressor provider\n        \u5727\u7e2e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u306f\u30af\u30ea\u30a2\u306f\u4e0d\u8981\n        \"\"\"\n        pass\n</code></pre>"},{"location":"context_management/#contextfilterprovider","title":"ContextFilterProvider","text":"<pre><code>import re\nfrom typing import ClassVar, Optional, List\n\nclass ContextFilterProvider(ContextProvider):\n    \"\"\"Filters context based on relevance to query\n    \u30af\u30a8\u30ea\u3068\u306e\u95a2\u9023\u6027\u306b\u57fa\u3065\u3044\u3066\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\n    \"\"\"\n\n    provider_name: ClassVar[str] = \"filter\"\n\n    def __init__(self, relevance_threshold: float = 0.3, max_sections: int = 5):\n        self.relevance_threshold = relevance_threshold\n        self.max_sections = max_sections\n\n    @classmethod\n    def get_config_schema(cls) -&gt; Dict[str, Any]:\n        \"\"\"Get configuration schema for context filter provider\n        \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d5\u30a3\u30eb\u30bf\u30fc\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n        \"\"\"\n        return {\n            \"description\": \"Filters context based on relevance to query\",\n            \"parameters\": {\n                \"relevance_threshold\": {\n                    \"type\": \"float\",\n                    \"default\": 0.3,\n                    \"description\": \"Minimum relevance score to keep context\"\n                },\n                \"max_sections\": {\n                    \"type\": \"int\",\n                    \"default\": 5,\n                    \"description\": \"Maximum number of context sections to keep\"\n                }\n            },\n            \"example\": \"\"\"\nfilter:\n  relevance_threshold: 0.5\n  max_sections: 3\n            \"\"\".strip()\n        }\n\n    def get_context(self, query: str, previous_context: Optional[str] = None, **kwargs) -&gt; str:\n        \"\"\"Filter previous context based on relevance to query\n        \u30af\u30a8\u30ea\u3068\u306e\u95a2\u9023\u6027\u306b\u57fa\u3065\u3044\u3066\u524d\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\n        \"\"\"\n        if not previous_context:\n            return \"\"\n\n        # Split context into sections\n        sections = self._split_into_sections(previous_context)\n\n        # Calculate relevance for each section\n        relevant_sections = []\n        for section in sections:\n            relevance = self._calculate_relevance(section, query)\n            if relevance &gt;= self.relevance_threshold:\n                relevant_sections.append((section, relevance))\n\n        # Sort by relevance and keep top sections\n        relevant_sections.sort(key=lambda x: x[1], reverse=True)\n        filtered_sections = [section for section, _ in relevant_sections[:self.max_sections]]\n\n        return '\\n\\n'.join(filtered_sections)\n\n    def _split_into_sections(self, context: str) -&gt; List[str]:\n        \"\"\"Split context into logical sections\n        \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u8ad6\u7406\u7684\u306a\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u5206\u5272\n        \"\"\"\n        # Split by double newlines or section headers\n        sections = re.split(r'\\n\\s*\\n', context)\n        return [section.strip() for section in sections if section.strip()]\n\n    def _calculate_relevance(self, section: str, query: str) -&gt; float:\n        \"\"\"Calculate relevance score between section and query\n        \u30bb\u30af\u30b7\u30e7\u30f3\u3068\u30af\u30a8\u30ea\u306e\u9593\u306e\u95a2\u9023\u6027\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\n        \"\"\"\n        query_words = set(query.lower().split())\n        section_words = set(section.lower().split())\n\n        if not query_words:\n            return 0.0\n\n        # Simple word overlap calculation\n        overlap = len(query_words.intersection(section_words))\n        return overlap / len(query_words)\n\n    def update(self, interaction: Dict[str, Any]) -&gt; None:\n        \"\"\"No update needed for filter provider\n        \u30d5\u30a3\u30eb\u30bf\u30fc\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u306f\u66f4\u65b0\u306f\u4e0d\u8981\n        \"\"\"\n        pass\n\n    def clear(self) -&gt; None:\n        \"\"\"No clear needed for filter provider\n        \u30d5\u30a3\u30eb\u30bf\u30fc\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u306f\u30af\u30ea\u30a2\u306f\u4e0d\u8981\n        \"\"\"\n        pass\n</code></pre>"},{"location":"context_management/#_10","title":"\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u30d5\u30a1\u30af\u30c8\u30ea\u30fc","text":""},{"location":"context_management/#contextproviderfactory","title":"ContextProviderFactory","text":"<pre><code>import yaml\nfrom typing import List, Dict, Any, Type\nfrom .context_providers import (\n    ConversationHistoryProvider,\n    FixedFileProvider,\n    SourceCodeProvider,\n    ContextCompressorProvider,\n    ContextFilterProvider\n)\n\nclass ContextProviderFactory:\n    \"\"\"Factory for creating context providers from configuration\n    \u8a2d\u5b9a\u304b\u3089\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u4f5c\u6210\u3059\u308b\u30d5\u30a1\u30af\u30c8\u30ea\u30fc\n    \"\"\"\n\n    _providers: Dict[str, Type[ContextProvider]] = {\n        \"conversation\": ConversationHistoryProvider,\n        \"fixed_file\": FixedFileProvider,\n        \"source_code\": SourceCodeProvider,\n        \"compressor\": ContextCompressorProvider,\n        \"filter\": ContextFilterProvider,\n    }\n\n    @classmethod\n    def register_provider(cls, name: str, provider_class: Type[ContextProvider]) -&gt; None:\n        \"\"\"Register a new context provider\n        \u65b0\u3057\u3044\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u767b\u9332\n        \"\"\"\n        cls._providers[name] = provider_class\n\n    @classmethod\n    def get_available_providers(cls) -&gt; Dict[str, Dict[str, Any]]:\n        \"\"\"Get available providers and their schemas\n        \u5229\u7528\u53ef\u80fd\u306a\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068\u305d\u306e\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n        \"\"\"\n        schemas = {}\n        for name, provider_class in cls._providers.items():\n            schemas[name] = provider_class.get_config_schema()\n        return schemas\n\n    @classmethod\n    def create_from_yaml(cls, yaml_config: str) -&gt; List[ContextProvider]:\n        \"\"\"Create context providers from YAML configuration string\n        YAML\u8a2d\u5b9a\u6587\u5b57\u5217\u304b\u3089\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u4f5c\u6210\n        \"\"\"\n        try:\n            config = yaml.safe_load(yaml_config)\n            return cls.create_from_config(config)\n        except yaml.YAMLError as e:\n            raise ValueError(f\"Invalid YAML configuration: {e}\")\n\n    @classmethod\n    def create_from_config(cls, config: List[Dict[str, Any]]) -&gt; List[ContextProvider]:\n        \"\"\"Create context providers from configuration list\n        \u8a2d\u5b9a\u30ea\u30b9\u30c8\u304b\u3089\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u4f5c\u6210\n        \"\"\"\n        providers = []\n\n        for item in config:\n            if not isinstance(item, dict):\n                raise ValueError(f\"Invalid configuration item: {item}\")\n\n            for provider_name, provider_config in item.items():\n                if provider_name not in cls._providers:\n                    raise ValueError(f\"Unknown provider: {provider_name}\")\n\n                provider_class = cls._providers[provider_name]\n                provider = provider_class.from_config(provider_config or {})\n                providers.append(provider)\n\n        return providers\n</code></pre>"},{"location":"context_management/#refinireagent","title":"RefinireAgent\u3078\u306e\u7d71\u5408","text":""},{"location":"context_management/#refinireagent_1","title":"RefinireAgent\u306e\u62e1\u5f35","text":"<p>RefinireAgent\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u306b<code>context_providers_config</code>\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8ffd\u52a0\u3057\u3001YAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u3067\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u6307\u5b9a\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002</p> <pre><code>from typing import List, Optional, Union\nfrom .pipeline.llm_pipeline import RefinireAgent, LLMResult\nfrom .context_provider_factory import ContextProviderFactory\n\nclass RefinireAgent:\n    \"\"\"\n    Refinire Agent - AI agent with automatic evaluation and tool integration\n    Refinire\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 - \u81ea\u52d5\u8a55\u4fa1\u3068\u30c4\u30fc\u30eb\u7d71\u5408\u3092\u5099\u3048\u305fAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        generation_instructions: str,\n        evaluation_instructions: Optional[str] = None,\n        *,\n        model: str = \"gpt-4o-mini\",\n        evaluation_model: Optional[str] = None,\n        output_model: Optional[Type[BaseModel]] = None,\n        temperature: float = 0.7,\n        max_tokens: Optional[int] = None,\n        timeout: float = 30.0,\n        threshold: float = 85.0,\n        max_retries: int = 3,\n        input_guardrails: Optional[List[Callable[[str], bool]]] = None,\n        output_guardrails: Optional[List[Callable[[Any], bool]]] = None,\n        session_history: Optional[List[str]] = None,\n        history_size: int = 10,\n        improvement_callback: Optional[Callable[[LLMResult, EvaluationResult], str]] = None,\n        locale: str = \"en\",\n        tools: Optional[List[Callable]] = None,\n        mcp_servers: Optional[List[str]] = None,\n        context_providers: Optional[List[ContextProvider]] = None,\n        context_providers_config: Optional[str] = None  # \u65b0\u898f\u8ffd\u52a0\n    ) -&gt; None:\n        \"\"\"\n        Initialize Refinire Agent\n        Refinire\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u521d\u671f\u5316\u3059\u308b\n\n        Args:\n            name: Agent name / \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\n            generation_instructions: Instructions for generation / \u751f\u6210\u7528\u6307\u793a\n            evaluation_instructions: Instructions for evaluation / \u8a55\u4fa1\u7528\u6307\u793a\n            model: OpenAI model name / OpenAI\u30e2\u30c7\u30eb\u540d\n            evaluation_model: Model for evaluation / \u8a55\u4fa1\u7528\u30e2\u30c7\u30eb\n            output_model: Pydantic model for structured output / \u69cb\u9020\u5316\u51fa\u529b\u7528Pydantic\u30e2\u30c7\u30eb\n            temperature: Sampling temperature / \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6e29\u5ea6\n            max_tokens: Maximum tokens / \u6700\u5927\u30c8\u30fc\u30af\u30f3\u6570\n            timeout: Request timeout / \u30ea\u30af\u30a8\u30b9\u30c8\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\n            threshold: Evaluation threshold / \u8a55\u4fa1\u95be\u5024\n            max_retries: Maximum retry attempts / \u6700\u5927\u30ea\u30c8\u30e9\u30a4\u56de\u6570\n            input_guardrails: Input validation functions / \u5165\u529b\u691c\u8a3c\u95a2\u6570\n            output_guardrails: Output validation functions / \u51fa\u529b\u691c\u8a3c\u95a2\u6570\n            session_history: Session history / \u30bb\u30c3\u30b7\u30e7\u30f3\u5c65\u6b74\n            history_size: History size limit / \u5c65\u6b74\u30b5\u30a4\u30ba\u5236\u9650\n            improvement_callback: Callback for improvement suggestions / \u6539\u5584\u63d0\u6848\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\n            locale: Locale for messages / \u30e1\u30c3\u30bb\u30fc\u30b8\u7528\u30ed\u30b1\u30fc\u30eb\n            tools: OpenAI function tools / OpenAI\u95a2\u6570\u30c4\u30fc\u30eb\n            mcp_servers: MCP server identifiers / MCP\u30b5\u30fc\u30d0\u30fc\u8b58\u5225\u5b50\n            context_providers: List of context providers / \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u30ea\u30b9\u30c8\n            context_providers_config: YAML-like string configuration for context providers / \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u7528\u306eYAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u8a2d\u5b9a\n        \"\"\"\n        # \u65e2\u5b58\u306e\u521d\u671f\u5316\u51e6\u7406...\n\n        # Context providers initialization\n        # \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u521d\u671f\u5316\n        if context_providers_config:\n            self.context_providers = ContextProviderFactory.create_from_yaml(context_providers_config)\n        else:\n            self.context_providers = context_providers or []\n\n        # OpenAI Agents SDK Agent\u3092\u521d\u671f\u5316\n        self._sdk_agent = Agent(\n            name=f\"{name}_sdk_agent\",\n            instructions=self.generation_instructions,\n            tools=self.tools\n        )\n\n    @classmethod\n    def get_context_provider_schemas(cls) -&gt; Dict[str, Dict[str, Any]]:\n        \"\"\"Get available context provider schemas\n        \u5229\u7528\u53ef\u80fd\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b9\u30ad\u30fc\u30de\u3092\u53d6\u5f97\n        \"\"\"\n        return ContextProviderFactory.get_available_providers()\n\n    def _build_prompt(self, user_input: str, include_instructions: bool = True) -&gt; str:\n        \"\"\"\n        Build complete prompt with instructions, history, and context providers\n        \u6307\u793a\u3001\u5c65\u6b74\u3001\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u542b\u3080\u5b8c\u5168\u306a\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u69cb\u7bc9\n\n        Args:\n            user_input: User input / \u30e6\u30fc\u30b6\u30fc\u5165\u529b\n            include_instructions: Whether to include instructions (for OpenAI Agents SDK, set to False)\n            include_instructions: \u6307\u793a\u6587\u3092\u542b\u3081\u308b\u304b\u3069\u3046\u304b\uff08OpenAI Agents SDK\u306e\u5834\u5408\u306fFalse\uff09\n        \"\"\"\n        prompt_parts = []\n\n        # Add instructions only if requested (not for OpenAI Agents SDK)\n        # \u8981\u6c42\u3055\u308c\u305f\u5834\u5408\u306e\u307f\u6307\u793a\u6587\u3092\u8ffd\u52a0\uff08OpenAI Agents SDK\u306e\u5834\u5408\u306f\u9664\u304f\uff09\n        if include_instructions:\n            prompt_parts.append(self.generation_instructions)\n\n        # Add context from context providers with chaining\n        # \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u304b\u3089\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u9023\u9396\u7684\u306b\u8ffd\u52a0\n        current_context = \"\"\n        for provider in self.context_providers:\n            try:\n                context = provider.get_context(user_input, previous_context=current_context, agent_name=self.name)\n                if context:\n                    current_context = context\n            except Exception as e:\n                logger.warning(f\"Context provider {provider.__class__.__name__} failed: {e}\")\n\n        if current_context:\n            prompt_parts.append(\"Context:\\n\" + current_context)\n\n        # Add history if available (existing functionality)\n        # \u5c65\u6b74\u304c\u5229\u7528\u53ef\u80fd\u306a\u5834\u5408\u306f\u8ffd\u52a0\uff08\u65e2\u5b58\u6a5f\u80fd\uff09\n        if self.session_history:\n            history_text = \"\\n\".join(self.session_history[-self.history_size:])\n            prompt_parts.append(f\"Previous context:\\n{history_text}\")\n\n        prompt_parts.append(f\"User input: {user_input}\")\n\n        return \"\\n\\n\".join(prompt_parts)\n\n    def _store_in_history(self, user_input: str, result: LLMResult) -&gt; None:\n        \"\"\"Store interaction in history and update context providers\n        \u5bfe\u8a71\u3092\u5c65\u6b74\u306b\u4fdd\u5b58\u3057\u3001\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u66f4\u65b0\n        \"\"\"\n        # Existing history storage logic\n        # \u65e2\u5b58\u306e\u5c65\u6b74\u4fdd\u5b58\u30ed\u30b8\u30c3\u30af\n        interaction = {\n            \"user_input\": user_input,\n            \"result\": result.content,\n            \"success\": result.success,\n            \"metadata\": result.metadata,\n            \"timestamp\": json.dumps({\"pipeline\": self.name}, ensure_ascii=False)\n        }\n\n        self._pipeline_history.append(interaction)\n\n        # Add to session history for context\n        session_entry = f\"User: {user_input}\\nAssistant: {result.content}\"\n        self.session_history.append(session_entry)\n\n        # Trim history if needed\n        if len(self.session_history) &gt; self.history_size:\n            self.session_history = self.session_history[-self.history_size:]\n\n        # Update context providers\n        # \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u66f4\u65b0\n        for provider in self.context_providers:\n            try:\n                provider.update(interaction)\n            except Exception as e:\n                logger.warning(f\"Failed to update context provider {provider.__class__.__name__}: {e}\")\n\n    def clear_context(self) -&gt; None:\n        \"\"\"Clear all context providers\n        \u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u30af\u30ea\u30a2\n        \"\"\"\n        for provider in self.context_providers:\n            try:\n                provider.clear()\n            except Exception as e:\n                logger.warning(f\"Failed to clear context provider {provider.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"context_management/#_11","title":"\u4f7f\u7528\u4f8b","text":""},{"location":"context_management/#yaml","title":"YAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u6307\u5b9a\uff08\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u9023\u9396\uff09","text":"<pre><code># YAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u3067\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u6307\u5b9a\uff08\u9023\u9396\u7684\u306a\u51e6\u7406\uff09\ncontext_config = \"\"\"\n- conversation:\n    max_items: 10\n- source_code:\n    codebase_path: \"./src\"\n    max_files: 5\n- filter:\n    relevance_threshold: 0.4\n    max_sections: 3\n- compressor:\n    max_tokens: 6000\n    compression_ratio: 0.8\n\"\"\"\n\nagent = RefinireAgent(\n    name=\"AdvancedContextAgent\",\n    generation_instructions=\"You are a coding assistant with intelligent context management.\",\n    context_providers_config=context_config\n)\n\nresult = agent.run(\"How should I implement the new feature?\")\n</code></pre>"},{"location":"context_management/#_12","title":"\u57fa\u672c\u7684\u306a\u4f7f\u7528\u4f8b","text":"<pre><code># \u4f1a\u8a71\u5c65\u6b74\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u4ed8\u304d\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\ncontext_config = \"\"\"\n- conversation:\n    max_items: 5\n\"\"\"\n\nagent = RefinireAgent(\n    name=\"HistoryAwareAgent\",\n    generation_instructions=\"You are a helpful assistant with conversation history.\",\n    context_providers_config=context_config\n)\n\nresult = agent.run(\"What did we discuss about the project?\")\n</code></pre>"},{"location":"context_management/#refinireagent_2","title":"\u65e2\u5b58\u306eRefinireAgent\u3068\u306e\u4e92\u63db\u6027","text":"<pre><code># \u65e2\u5b58\u306e\u4f7f\u7528\u65b9\u6cd5\uff08\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306a\u3057\uff09\nagent = RefinireAgent(\n    name=\"SimpleAgent\",\n    generation_instructions=\"You are a helpful assistant.\"\n)\n\n# \u65b0\u3057\u3044\u4f7f\u7528\u65b9\u6cd5\uff08YAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u6307\u5b9a\uff09\ncontext_config = \"\"\"\n- conversation:\n    max_items: 5\n\"\"\"\n\nagent = RefinireAgent(\n    name=\"EnhancedAgent\",\n    generation_instructions=\"You are a helpful assistant.\",\n    context_providers_config=context_config\n)\n</code></pre>"},{"location":"context_management/#_13","title":"\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u78ba\u8a8d","text":"<pre><code># \u5229\u7528\u53ef\u80fd\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068\u305d\u306e\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de\u3092\u78ba\u8a8d\nschemas = RefinireAgent.get_context_provider_schemas()\nfor provider_name, schema in schemas.items():\n    print(f\"Provider: {provider_name}\")\n    print(f\"Description: {schema['description']}\")\n    print(f\"Parameters: {schema['parameters']}\")\n    print(f\"Example:\\n{schema['example']}\")\n    print()\n</code></pre>"},{"location":"context_management/#_14","title":"\u5b9f\u88c5\u8a08\u753b","text":""},{"location":"context_management/#phase-1","title":"Phase 1: \u57fa\u672c\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc","text":"<ul> <li>[ ] ContextProvider \u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306e\u5b9f\u88c5</li> <li>[ ] ConversationHistoryProvider\u306e\u5b9f\u88c5</li> <li>[ ] FixedFileProvider\u306e\u5b9f\u88c5</li> <li>[ ] ContextProviderFactory\u306e\u5b9f\u88c5</li> <li>[ ] RefinireAgent\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u62e1\u5f35</li> </ul>"},{"location":"context_management/#phase-2","title":"Phase 2: \u9ad8\u5ea6\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc","text":"<ul> <li>[ ] SourceCodeProvider\u306e\u5b9f\u88c5</li> <li>[ ] ContextCompressorProvider\u306e\u5b9f\u88c5</li> <li>[ ] ContextFilterProvider\u306e\u5b9f\u88c5</li> <li>[ ] LongTermMemoryProvider\u306e\u5b9f\u88c5</li> </ul>"},{"location":"context_management/#phase-3","title":"Phase 3: \u6700\u9069\u5316\u3068\u62e1\u5f35","text":"<ul> <li>[ ] \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316</li> <li>[ ] \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u306e\u4f5c\u6210</li> <li>[ ] \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u66f4\u65b0</li> </ul>"},{"location":"context_management/#_15","title":"\u307e\u3068\u3081","text":"<p>\u3053\u306e\u8a2d\u8a08\u306b\u3088\u308a\u3001RefinireAgent\u306f\u4ee5\u4e0b\u306e\u6a5f\u80fd\u3092\u7372\u5f97\u3057\u307e\u3059\uff1a</p> <ol> <li>\u76f4\u611f\u7684\u306a\u8a2d\u5b9a: YAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u3067\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u6307\u5b9a</li> <li>\u5f8c\u65b9\u4e92\u63db\u6027: \u65e2\u5b58\u306eRefinireAgent\u3068\u306e\u4e92\u63db\u6027\u3092\u7dad\u6301</li> <li>\u67d4\u8edf\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406: \u8907\u6570\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30bd\u30fc\u30b9\u3092\u7d71\u5408</li> <li>\u81ea\u52d5\u66f4\u65b0: \u5bfe\u8a71\u6642\u306b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3082\u81ea\u52d5\u66f4\u65b0</li> <li>\u62e1\u5f35\u3057\u3084\u3059\u3044: \u65b0\u3057\u3044\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u7c21\u5358\u306a\u8ffd\u52a0</li> <li>\u8a2d\u5b9a\u30b9\u30ad\u30fc\u30de: \u5404\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a2d\u5b9a\u65b9\u6cd5\u3092\u660e\u78ba\u306b\u5b9a\u7fa9</li> <li>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u9023\u9396: \u524d\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u4f9d\u5b58\u3059\u308b\u52d5\u4f5c\u3092\u30b5\u30dd\u30fc\u30c8</li> </ol> <p>\u3053\u306e\u8a2d\u8a08\u306b\u3088\u308a\u3001RefinireAgent\u306f\u5fc5\u8981\u6700\u5c0f\u9650\u306e\u5909\u66f4\u3067\u9ad8\u5ea6\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u6a5f\u80fd\u3092\u7372\u5f97\u3067\u304d\u3001\u76f4\u611f\u7684\u306a\u6587\u5b57\u5217\u6307\u5b9a\u306e\u5229\u70b9\u3082\u7dad\u6301\u3067\u304d\u307e\u3059\u3002 </p>"},{"location":"deprecation_plan/","title":"AgentPipeline Deprecation Plan","text":""},{"location":"deprecation_plan/#agentpipeline","title":"AgentPipeline\u306e\u5ec3\u6b62\u4e88\u5b9a\u8a08\u753b","text":""},{"location":"deprecation_plan/#background","title":"\u80cc\u666f (Background)","text":"<p>Flow/Step\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u5c0e\u5165\u306b\u3088\u308a\u3001\u3088\u308a\u67d4\u8edf\u3067\u62e1\u5f35\u6027\u306e\u9ad8\u3044\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7ba1\u7406\u304c\u53ef\u80fd\u306b\u306a\u308a\u307e\u3057\u305f\u3002GenAgent\u30af\u30e9\u30b9\u306b\u3088\u308a\u3001AgentPipeline\u306e\u6a5f\u80fd\u306fFlow\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u5185\u3067Step\u3068\u3057\u3066\u4f7f\u7528\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u305f\u305f\u3081\u3001AgentPipeline\u30af\u30e9\u30b9\u3092\u6bb5\u968e\u7684\u306b\u5ec3\u6b62\u3057\u3066\u3044\u304d\u307e\u3059\u3002</p>"},{"location":"deprecation_plan/#migration-benefits","title":"\u79fb\u884c\u306e\u5229\u70b9 (Migration Benefits)","text":""},{"location":"deprecation_plan/#english","title":"English:","text":"<ul> <li>More flexible workflow composition using Flow/Step architecture</li> <li>Better reusability through modular Step design</li> <li>Enhanced error handling and context management</li> <li>Cleaner separation of concerns</li> <li>Future-proof architecture for complex workflows</li> </ul>"},{"location":"deprecation_plan/#_1","title":"\u65e5\u672c\u8a9e:","text":"<ul> <li>Flow/Step\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306b\u3088\u308b\u3088\u308a\u67d4\u8edf\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u69cb\u6210</li> <li>\u30e2\u30b8\u30e5\u30e9\u30fc\u306aStep\u8a2d\u8a08\u306b\u3088\u308b\u518d\u5229\u7528\u6027\u306e\u5411\u4e0a</li> <li>\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u3068\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u306e\u5f37\u5316</li> <li>\u95a2\u5fc3\u306e\u5206\u96e2\u306e\u3088\u308a\u30af\u30ea\u30fc\u30f3\u306a\u5b9f\u73fe</li> <li>\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306b\u5bfe\u5fdc\u3059\u308b\u5c06\u6765\u6027\u306e\u3042\u308b\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> </ul>"},{"location":"deprecation_plan/#deprecation-timeline","title":"\u5ec3\u6b62\u8a08\u753b (Deprecation Timeline)","text":""},{"location":"deprecation_plan/#1-deprecation-warning-v0022","title":"\u30d5\u30a7\u30fc\u30ba 1: Deprecation Warning\u8ffd\u52a0 (v0.0.22) \u2705 \u5b8c\u4e86","text":"<ul> <li>[x] AgentPipeline\u30af\u30e9\u30b9\u306bdeprecation warning\u3092\u8ffd\u52a0</li> <li>[x] \u65b0\u3057\u3044GenAgent\u3078\u306e\u79fb\u884c\u30ac\u30a4\u30c9\u3092\u4f5c\u6210</li> <li>[x] README.md\u3067Flow/Step\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u63a8\u5968\u3068\u3057\u3066\u8a18\u8f09</li> </ul>"},{"location":"deprecation_plan/#2-examples-v0023","title":"\u30d5\u30a7\u30fc\u30ba 2: Examples\u79fb\u884c (v0.0.23) \u2705 \u5b8c\u4e86","text":"<ul> <li>[x] genagent_simple_generation.py - \u57fa\u672c\u7684\u306a\u751f\u6210\u4f8b\u306e\u79fb\u884c\u7248</li> <li>[x] genagent_with_evaluation.py - \u8a55\u4fa1\u6a5f\u80fd\u4ed8\u304d\u306e\u79fb\u884c\u7248</li> <li>[x] genagent_with_tools.py - \u30c4\u30fc\u30eb\u4f7f\u7528\u4f8b\u306e\u79fb\u884c\u7248</li> <li>[x] genagent_with_guardrails.py - \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u4f7f\u7528\u4f8b\u306e\u79fb\u884c\u7248</li> <li>[x] genagent_with_history.py - \u5c65\u6b74\u7ba1\u7406\u4f8b\u306e\u79fb\u884c\u7248</li> <li>[x] genagent_with_retry.py - \u30ea\u30c8\u30e9\u30a4\u6a5f\u80fd\u4f8b\u306e\u79fb\u884c\u7248</li> <li>[x] genagent_with_dynamic_prompt.py - \u52d5\u7684\u30d7\u30ed\u30f3\u30d7\u30c8\u4f8b\u306e\u79fb\u884c\u7248</li> <li>[x] \u65b0\u3057\u3044Flow/Step\u4f7f\u7528\u4f8b\u306e\u5145\u5b9f\uff08\u5404example\u3067\u8907\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u5b9f\u88c5\uff09</li> <li>[x] \u79fb\u884c\u30ac\u30a4\u30c9\u306e\u5b8c\u6210\uff08deprecation_plan.md\u306b\u8a73\u7d30\u306a\u79fb\u884c\u4f8b\u3092\u8a18\u8f09\uff09</li> </ul>"},{"location":"deprecation_plan/#3-v0024","title":"\u30d5\u30a7\u30fc\u30ba 3: \u30c6\u30b9\u30c8\u79fb\u884c (v0.0.24) \u2705 \u5b8c\u4e86","text":"<ul> <li>[x] AgentPipeline\u306e\u30c6\u30b9\u30c8\u3092GenAgent\u30d9\u30fc\u30b9\u306b\u79fb\u884c</li> <li>[x] \u5f8c\u65b9\u4e92\u63db\u6027\u30c6\u30b9\u30c8\u306e\u8ffd\u52a0</li> <li>[x] GenAgent\u306e\u5b8c\u5168\u306a\u30c6\u30b9\u30c8\u30ab\u30d0\u30ec\u30c3\u30b8</li> </ul>"},{"location":"deprecation_plan/#_2","title":"\u79fb\u884c\u3055\u308c\u305f\u30c6\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb:","text":"<ul> <li><code>test_gen_agent_compatibility.py</code> (377\u884c) - \u4e92\u63db\u6027\u3068deprecation\u8b66\u544a\u30c6\u30b9\u30c8</li> <li><code>test_gen_agent_comprehensive.py</code> (306\u884c, 12\u30c6\u30b9\u30c8) - \u5168\u6a5f\u80fd\u30ab\u30d0\u30ec\u30c3\u30b8\u30c6\u30b9\u30c8</li> <li>\u30c6\u30b9\u30c8\u7d50\u679c: \u5168\u3066\u6210\u529f (12 passed, 19 warnings)</li> <li>\u30ab\u30d0\u30ec\u30c3\u30b8: \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3001\u30d7\u30ed\u30f3\u30d7\u30c8\u69cb\u7bc9\u3001\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u3001\u5c65\u6b74\u7ba1\u7406\u3001\u95be\u5024\u8a2d\u5b9a</li> </ul>"},{"location":"deprecation_plan/#4-v010","title":"\u30d5\u30a7\u30fc\u30ba 4: \u5b8c\u5168\u524a\u9664 (v0.1.0)","text":"<ul> <li>[ ] AgentPipeline\u30af\u30e9\u30b9\u306e\u5b8c\u5168\u524a\u9664</li> <li>[ ]\u95a2\u9023\u3059\u308bimport\u3068export\u306e\u524a\u9664</li> <li>[ ] \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7</li> </ul>"},{"location":"deprecation_plan/#migration-guide","title":"\u79fb\u884c\u65b9\u6cd5 (Migration Guide)","text":""},{"location":"deprecation_plan/#_3","title":"\u57fa\u672c\u7684\u306a\u79fb\u884c\u30d1\u30bf\u30fc\u30f3","text":""},{"location":"deprecation_plan/#agentpipeline_1","title":"\u65e7: AgentPipeline","text":"<pre><code>from agents_sdk_models import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"example\",\n    generation_instructions=\"Generate a response\",\n    model=\"gpt-4o-mini\"\n)\n\nresult = pipeline.run(\"User input\")\n</code></pre>"},{"location":"deprecation_plan/#genagent-flowstep","title":"\u65b0: GenAgent (Flow/Step\u5185)","text":"<pre><code>from agents_sdk_models import GenAgent, Flow, create_simple_flow\n\n# Method 1: Direct GenAgent usage\ngen_agent = GenAgent(\n    name=\"example\", \n    generation_instructions=\"Generate a response\",\n    model=\"gpt-4o-mini\",\n    context_key=\"result\"\n)\n\nflow = create_simple_flow(gen_agent)\nresult = await flow.run(input_data=\"User input\")\n\n# Method 2: Utility function\nfrom agents_sdk_models import create_simple_gen_agent\n\ngen_agent = create_simple_gen_agent(\n    name=\"example\",\n    generation_instructions=\"Generate a response\", \n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"deprecation_plan/#_4","title":"\u8a55\u4fa1\u6a5f\u80fd\u4ed8\u304d\u306e\u79fb\u884c","text":""},{"location":"deprecation_plan/#agentpipeline-with-evaluation","title":"\u65e7: AgentPipeline with evaluation","text":"<pre><code>pipeline = AgentPipeline(\n    name=\"evaluated_pipeline\",\n    generation_instructions=\"Generate creative content\",\n    evaluation_instructions=\"Evaluate creativity and quality\",\n    model=\"gpt-4o-mini\",\n    evaluation_threshold=0.8\n)\n</code></pre>"},{"location":"deprecation_plan/#genagent-with-evaluation","title":"\u65b0: GenAgent with evaluation","text":"<pre><code>from agents_sdk_models import create_evaluated_gen_agent\n\ngen_agent = create_evaluated_gen_agent(\n    name=\"evaluated_agent\",\n    generation_instructions=\"Generate creative content\",\n    evaluation_instructions=\"Evaluate creativity and quality\",\n    model=\"gpt-4o-mini\",\n    evaluation_threshold=0.8\n)\n</code></pre>"},{"location":"deprecation_plan/#target-files","title":"\u5bfe\u8c61\u30d5\u30a1\u30a4\u30eb (Target Files)","text":""},{"location":"deprecation_plan/#_5","title":"\u30b3\u30a2\u30d5\u30a1\u30a4\u30eb","text":"<ul> <li><code>src/agents_sdk_models/pipeline.py</code> - AgentPipeline\u30af\u30e9\u30b9</li> <li><code>src/agents_sdk_models/__init__.py</code> - export\u524a\u9664</li> </ul>"},{"location":"deprecation_plan/#examples","title":"Examples\u30d5\u30a1\u30a4\u30eb","text":"<ul> <li><code>examples/pipeline_simple_generation.py</code></li> <li><code>examples/pipeline_with_dynamic_prompt.py</code></li> <li><code>examples/pipeline_with_evaluation.py</code></li> <li><code>examples/pipeline_with_guardrails.py</code></li> <li><code>examples/pipeline_with_history.py</code></li> <li><code>examples/pipeline_with_retry.py</code></li> <li><code>examples/pipeline_with_tools.py</code></li> <li><code>examples/simple_llm_query.py</code></li> </ul>"},{"location":"deprecation_plan/#_6","title":"\u30c6\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb","text":"<ul> <li><code>tests/test_pipeline.py</code></li> <li><code>tests/test_pipeline_*.py</code> \u7cfb\u7d71</li> </ul>"},{"location":"deprecation_plan/#backward-compatibility","title":"\u5f8c\u65b9\u4e92\u63db\u6027\u306e\u4fdd\u8a3c (Backward Compatibility)","text":"<p>v0.1.0\u307e\u3067\u5b8c\u5168\u306a\u5f8c\u65b9\u4e92\u63db\u6027\u3092\u4fdd\u8a3c\u3057\u307e\u3059\uff1a - \u65e2\u5b58\u306eAgentPipeline\u30b3\u30fc\u30c9\u306f\u5f15\u304d\u7d9a\u304d\u52d5\u4f5c - Deprecation warning\u306e\u307f\u8868\u793a - \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u65b0\u3057\u3044\u65b9\u6cd5\u3092\u63a8\u5968</p>"},{"location":"deprecation_plan/#support","title":"\u30b5\u30dd\u30fc\u30c8 (Support)","text":"<p>\u79fb\u884c\u306b\u95a2\u3059\u308b\u8cea\u554f\u3084\u30b5\u30dd\u30fc\u30c8\u306f\uff1a - GitHub Issues - \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u79fb\u884c\u30ac\u30a4\u30c9 - Example \u30b3\u30fc\u30c9\u306e\u53c2\u7167 </p>"},{"location":"example_stdout_tracing/","title":"Example stdout tracing","text":"<pre><code>from agents.tracing import TracingProcessor, add_trace_processor, set_tracing_disabled\nfrom agents.tracing.span_data import GenerationSpanData\n\nclass StdoutTracer(TracingProcessor):\n    # ---- trace \u30ec\u30d9\u30eb ----\n    def on_trace_start(self, trace): ...\n    def on_trace_end(self, trace): ...\n    # ---- span \u30ec\u30d9\u30eb ----\n    def on_span_start(self, span): ...\n    def on_span_end(self, span):\n        data = span.span_data\n        if isinstance(data, GenerationSpanData):\n            # messages \u306f list[dict(role, content)]\n            sys_msg   = next((m[\"content\"] for m in data.input if m[\"role\"]==\"system\"), \"\")\n            user_msg  = next((m[\"content\"] for m in data.input if m[\"role\"]==\"user\"), \"\")\n            assistant = \"\\n\".join(m[\"content\"] for m in data.output or [])\n            print(\"\\n=== Instruction ===\\n\", sys_msg)\n            print(\"=== Prompt ===\\n\", user_msg)\n            print(\"=== Output ===\\n\", assistant, \"\\n\")\n\n    def shutdown(self): ...            # \u5fc5\u8981\u306a\u3089 flush\n    def force_flush(self): ...\n\n# OpenAI \u3078\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3092\u7121\u52b9\u5316\u3059\u308b\u5834\u5408\nset_tracing_disabled(True)             # \u3042\u308b\u3044\u306f set_trace_processors([StdoutTracer()])\n\n# Processor \u3092\u767b\u9332\nadd_trace_processor(StdoutTracer())\n\n# \u3042\u3068\u306f\u666e\u901a\u306b Agent \u3092\u5b9f\u884c\n# result = await Runner.run(agent, \"\u3053\u3093\u306b\u3061\u306f\")\n</code></pre>"},{"location":"flow_context/","title":"\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u306e\u6bd4\u8f03\u5206\u6790\u3068\u8a2d\u8a08\u63d0\u6848","text":""},{"location":"flow_context/#1","title":"1. \u6982\u8981","text":"<p>Flow/Step \u30d9\u30fc\u30b9\u3078\u79fb\u884c\u3057\u305f agents\u2011sdk\u2011models \u306b\u6700\u9069\u5316\u3057\u305f\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\uff08<code>Context</code>\uff09\u8a2d\u8a08\u3092\u691c\u8a0e\u3059\u308b\u305f\u3081\u3001\u4e0b\u8a18 3 \u70b9\u3092\u6574\u7406\u3059\u308b\u3002</p> <ol> <li>OpenAI Agents SDK \u306b\u304a\u3051\u308b Context \u306e\u4f4d\u7f6e\u3065\u3051</li> <li>LangChain LCEL \u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u624b\u6cd5</li> <li>\u305d\u308c\u3089\u3092\u8e0f\u307e\u3048\u305f agents\u2011sdk\u2011models \u5411\u3051 Context \u6848</li> </ol>"},{"location":"flow_context/#2-openai-agents-sdk-context","title":"2. OpenAI Agents SDK \u306e Context","text":"\u9805\u76ee \u6982\u8981 \u76ee\u7684 \u4f9d\u5b58\u6027\u6ce8\u5165/\u5c40\u6240\u72b6\u614b\u3092\u683c\u7d0d\u3002LLM \u3078\u306f\u6e21\u3089\u306a\u3044\u3002 \u578b \u4efb\u610f\u306e\u30e6\u30fc\u30b6\u5b9a\u7fa9\u30af\u30e9\u30b9\uff08<code>@dataclass</code> \u3084 Pydantic \u53ef\uff09\u3002 \u4e3b\u306a\u5185\u5bb9 DB \u30cf\u30f3\u30c9\u30e9\u3001\u30ed\u30ac\u30fc\u3001\u5916\u90e8 API \u306a\u3069\u5b9f\u884c\u6642\u4f9d\u5b58\u7269\u3002\u30e6\u30fc\u30b6\u30fc ID \u3084\u6a29\u9650\u306a\u3069\u30bb\u30c3\u30b7\u30e7\u30f3\u30b9\u30b3\u30fc\u30d7\u60c5\u5831\u3002 \u4f1a\u8a71\u5c65\u6b74 Runner \u304c\u5185\u90e8\u7ba1\u7406\u3057 Agent \u3078\u4f9b\u7d66\u3002Context \u306b\u306f\u901a\u5e38\u542b\u3081\u306a\u3044\u3002 \u5206\u5c90\u5236\u5fa1 Handoff\uff0f\u8907\u6570 Agent \u547c\u3073\u51fa\u3057\u30ed\u30b8\u30c3\u30af\u3092\u30b3\u30fc\u30c9\u5074\u3067\u8a18\u8ff0\u3002Context \u306b\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u5024\u306f\u4fdd\u6301\u3057\u306a\u3044\u3002 \u30e1\u30ea\u30c3\u30c8 \u5b8c\u5168\u81ea\u7531 \u3067\u65e2\u5b58 DI \u30d1\u30bf\u30fc\u30f3\u306b\u8fd1\u3044\u3002 \u30c7\u30e1\u30ea\u30c3\u30c8 \u30d5\u30a3\u30fc\u30eb\u30c9\u5b9a\u7fa9\u304c\u6563\u5728\u3057\u3084\u3059\u304f\u3001\u5927\u898f\u6a21\u30d5\u30ed\u30fc\u3067\u53ef\u8aad\u6027\u4f4e\u4e0b\u3002"},{"location":"flow_context/#3-langchain-lcel","title":"3. LangChain LCEL \u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406","text":"\u9805\u76ee \u6982\u8981 \u5165\u529b/\u51fa\u529b <code>dict[str, Any]</code> \u3092\u30c1\u30a7\u30fc\u30f3\u9593\u3067\u53d7\u6e21\u3057\u3002 \u4f1a\u8a71\u5c65\u6b74 <code>ConversationBufferMemory</code> \u306a\u3069 Memory \u30af\u30e9\u30b9\u304c\u4fdd\u6301\u3057\u3001\u5165\u529b\u8f9e\u66f8\u306b\u5c55\u958b\u3002 \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0 <code>RunnableConditional</code> \u7b49\u3067\u30e9\u30e0\u30c0\u5224\u5b9a\u3057\u30d6\u30e9\u30f3\u30c1\u3002\u8f9e\u66f8\u306b\u76f4\u63a5\u30d5\u30e9\u30b0\u3092\u66f8\u304f\u5834\u5408\u3082\u3002 \u8ffd\u52a0\u30e1\u30bf RunManager <code>metadata/tags</code> \u306b\u4efb\u610f\u30c7\u30fc\u30bf\u3092\u6dfb\u4ed8\u3002v0.2 \u304b\u3089 <code>Context</code>\uff08\u03b2\uff09\u304c\u5c0e\u5165\u3055\u308c\u30b9\u30b3\u30fc\u30d7\u578b get/set \u304c\u53ef\u80fd\u3002 \u30e1\u30ea\u30c3\u30c8 \u5b66\u7fd2\u30b3\u30b9\u30c8\u304c\u4f4e\u304f\u3001\u67d4\u8edf\u6027\u304c\u9ad8\u3044\u3002 \u30c7\u30e1\u30ea\u30c3\u30c8 \u30ad\u30fc\u885d\u7a81\u30fb\u578b\u4e0d\u6574\u5408\u304c\u8d77\u304d\u3084\u3059\u304f\u3001\u53ef\u8aad\u6027\u3082\u4f4e\u4e0b\u3002"},{"location":"flow_context/#4","title":"4. \u4e21\u8005\u6bd4\u8f03\u65e9\u898b\u8868","text":"\u9805\u76ee Agents SDK LangChain LCEL \u578b \u4efb\u610f\u30af\u30e9\u30b9 dict + Memory + metadata \u4f1a\u8a71\u5c65\u6b74 Runner \u5185\u90e8\u4fdd\u6301 Memory \u30af\u30e9\u30b9 \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0 \u30b3\u30fc\u30c9\u5185 handoff RunnableConditional \u4f9d\u5b58\u6027\u6ce8\u5165 Context \u30d5\u30a3\u30fc\u30eb\u30c9 dict / metadata \u578b\u5b89\u5168\u6027 \u9ad8\uff08\u578b\u4ed8\u304d\u30af\u30e9\u30b9\uff09 \u4f4e\uff08\u81ea\u7531\u30ad\u30fc\uff09"},{"location":"flow_context/#5-agentssdkmodels-context","title":"5. agents\u2011sdk\u2011models \u5411\u3051 Context \u8a2d\u8a08\u6848","text":""},{"location":"flow_context/#51","title":"5.1 \u8a2d\u8a08\u65b9\u91dd","text":"<ol> <li>\u578b\u5b89\u5168\u3067\u8aad\u307f\u3084\u3059\u3044 : Pydantic <code>BaseModel</code> \u3092\u63a1\u7528\u3057 IDE \u88dc\u5b8c\u3092\u6d3b\u7528\u3002</li> <li>\u5c65\u6b74\u3082\u4fdd\u6301 : Agents SDK \u4f9d\u5b58\u3092\u907f\u3051\u3001Flow \u5185\u3067\u4e00\u8cab\u7ba1\u7406\u3002</li> <li>\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u5185\u5305 : <code>next_label: str | None</code> \u3092\u30d5\u30a3\u30fc\u30eb\u30c9\u5316\u3057 Step \u8fd4\u5374\u3067\u66f4\u65b0\u3002</li> <li>\u8f9e\u66f8\u4e92\u63db : <code>as_dict()/from_dict()</code> \u3067 LCEL \u3068\u306e\u30d6\u30ea\u30c3\u30b8\u3092\u63d0\u4f9b\u3002</li> </ol>"},{"location":"flow_context/#52","title":"5.2 \u30d5\u30a3\u30fc\u30eb\u30c9\u4f8b","text":"<pre><code>class Context(BaseModel):\n    last_user_input: str | None = None      # \u76f4\u8fd1\u30e6\u30fc\u30b6\u30fc\u5165\u529b\n    messages: list[Message] = []            # \u4f1a\u8a71\u5c65\u6b74\n    knowledge: dict[str, Any] = {}          # RAG \u306a\u3069\u5916\u90e8\u77e5\u8b58\n    prev_outputs: dict[str, Any] = {}       # \u524d Step \u751f\u6210\u7269\n    next_label: str | None = None           # \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u6307\u793a\n    artifacts: dict[str, Any] = {}          # Flow \u5168\u4f53\u6210\u679c\u7269\n    shared_state: dict[str, Any] = {}       # \u4efb\u610f\u5171\u6709\u5024\n\n    def as_dict(self) -&gt; dict[str, Any]:\n        \"\"\"LCEL \u4e92\u63db\u8f9e\u66f8\u3078\u5909\u63db\"\"\"\n        d = self.dict()\n        d[\"history\"] = d.pop(\"messages\")\n        return d\n\n    @classmethod\n    def from_dict(cls, d: dict[str, Any]) -&gt; \"Context\":\n        d = d.copy()\n        d[\"messages\"] = d.pop(\"history\", [])\n        return cls(**d)\n</code></pre>"},{"location":"flow_context/#53","title":"5.3 \u5229\u7528\u30d1\u30bf\u30fc\u30f3","text":"<pre><code>async def step_example(ctx: Context) -&gt; Context:\n    # 1. \u30e6\u30fc\u30b6\u30fc\u5165\u529b\u3092\u53d6\u5f97\n    user_msg = await ctx.io.ask(\"\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044\")\n    ctx.last_user_input = user_msg\n    ctx.messages.append(user_msg)\n\n    # 2. \u30e2\u30c7\u30eb\u547c\u3073\u51fa\u3057\n    answer = await model.invoke(ctx.messages)\n    ctx.messages.append(answer)\n\n    # 3. \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u5224\u5b9a\n    ctx.next_label = \"done\" if is_ok(answer) else \"retry\"\n    return ctx\n</code></pre>"},{"location":"flow_context/#54-agents-sdk","title":"5.4 Agents SDK \u9023\u643a\u6848","text":"<ul> <li>BridgeStep: Agents SDK Runner \u3092\u5185\u90e8\u3067\u547c\u3073\u3001Runner.context \u2194\ufe0e Context \u5909\u63db\u3057\u306a\u304c\u3089\u5b9f\u884c\u3002</li> <li>\u5c65\u6b74\u540c\u671f: Runner \u5074\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d6\u5f97\u3057 <code>ctx.messages</code> \u306b\u30de\u30fc\u30b8\u3002</li> </ul>"},{"location":"flow_context/#55","title":"5.5 \u30e1\u30ea\u30c3\u30c8 &amp; \u30c8\u30ec\u30fc\u30c9\u30aa\u30d5","text":"\u5229\u70b9 \u61f8\u5ff5 \u578b\u5b89\u5168\u30fb\u88dc\u5b8c\u304c\u52b9\u304f Pydantic \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30b3\u30b9\u30c8\u5897 LCEL \u3068\u306e\u53cc\u65b9\u5411\u5909\u63db\u3067\u4f7f\u3044\u307e\u308f\u305b\u308b \u4e8c\u91cd\u4fdd\u6301\u3067\u30e1\u30e2\u30ea\u6d88\u8cbb \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u304c\u660e\u793a\u7684 Agents SDK \u7684\u306b\u306f\u5c11\u3057\u5197\u9577"},{"location":"flow_context/#56","title":"5.6 \u4eca\u5f8c\u306e\u62e1\u5f35\u30a4\u30e1\u30fc\u30b8","text":"<ol> <li>ContextPlugin API : \u5916\u90e8\u30b7\u30b9\u30c6\u30e0\u3068\u81ea\u52d5\u540c\u671f\u3059\u308b\u62e1\u5f35\u30dd\u30a4\u30f3\u30c8\uff08\u4f8b: DB/Redis\uff09\u3002</li> <li>StreamingMessages : \u5c65\u6b74\u90e8\u306e\u307f\u9045\u5ef6\u30ed\u30fc\u30c9/\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u53ef\u80fd\u306b\u3002</li> <li>TypedArtifacts : \u6210\u679c\u7269\u3092\u30af\u30e9\u30b9\u3054\u3068\u306b\u578b\u4ed8\u3051\u3057\u3066\u5b89\u5168\u6027\u5411\u4e0a\u3002</li> </ol> <p>\u3053\u308c\u306b\u3088\u308a\u3001Agents SDK Models \u306f \u578b\u5b89\u5168\u30fb\u5206\u304b\u308a\u3084\u3059\u3055\u30fb\u4ed6\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u4e92\u63db \u3092\u4e21\u7acb\u3057\u305f\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u3092\u5b9f\u73fe\u3067\u304d\u308b\u3002</p>"},{"location":"flow_step/","title":"Agents SDK Models: Flow/DAG \u6a5f\u80fd\u8a55\u4fa1\u3068\u62e1\u5f35\u8a2d\u8a08\u00a0(v3)","text":""},{"location":"flow_step/#step-flow-api","title":"Step / Flow API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9","text":"<p>\u672c\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f agents\u2011sdk\u2011models \u306b\u304a\u3051\u308b <code>Step</code> \u3068 <code>Flow</code> \u304c\u63d0\u4f9b\u3059\u308b\u4e3b\u8981\u30e1\u30bd\u30c3\u30c9\u30fb\u5c5e\u6027\u3092\u4e00\u89a7\u8868\u3067\u6574\u7406\u3059\u308b\u3002CLI \u3067\u3082 GUI \u3067\u3082\u5229\u7528\u3057\u3084\u3059\u3044\u3088\u3046 \u540c\u671f\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3 \u3068 \u975e\u540c\u671f\u30bf\u30b9\u30af \u306e\u4e21\u7cfb\u7d71\u3092\u542b\u3081\u308b\u3002</p>"},{"location":"flow_step/#1-step","title":"1. Step \u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9","text":"\u30e1\u30f3\u30d0\u30fc \u7a2e\u5225 \u30b7\u30b0\u30cd\u30c1\u30e3 / \u578b \u8aac\u660e <code>name</code> \u5c5e\u6027 <code>str</code> \u30b9\u30c6\u30c3\u30d7\u8b58\u5225\u540d\uff08DSL \u3067\u53c2\u7167\uff09 <code>run</code> <code>async def</code> <code>run(user_input: str \\| None, ctx: Context) -&gt; Context</code> \u30b9\u30c6\u30c3\u30d7\u3092 1 \u56de\u5b9f\u884c\u3057\u3001\u65b0\u3057\u3044 <code>Context</code> \u3092\u8fd4\u3059\u3002\u5fc5\u8981\u306b\u5fdc\u3058 <code>ctx.next_label</code> \u3092\u66f4\u65b0\u3059\u308b\u3002 <p>\u5b9f\u88c5\u4f8b: <code>UserInputStep</code>, <code>ConditionStep</code>, <code>AgentPipeline</code> \u306a\u3069\u3002</p>"},{"location":"flow_step/#2-flow","title":"2. Flow \u30af\u30e9\u30b9","text":""},{"location":"flow_step/#_1","title":"\ud83d\ude80 \u65b0\u6a5f\u80fd\uff1a\u62e1\u5f35\u3055\u308c\u305f\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf","text":"<p>Flow\u30af\u30e9\u30b9\u306f3\u3064\u306e\u65b9\u6cd5\u3067\u4f5c\u6210\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\uff1a</p> <pre><code># 1. \u5358\u4e00\u30b9\u30c6\u30c3\u30d7\uff08\u6700\u3082\u30b7\u30f3\u30d7\u30eb\uff01\uff09\nflow = Flow(steps=gen_agent)\n\n# 2. \u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30b9\u30c6\u30c3\u30d7\uff08\u81ea\u52d5\u63a5\u7d9a\uff01\uff09\nflow = Flow(steps=[step1, step2, step3])\n\n# 3. \u5f93\u6765\u65b9\u5f0f\uff08\u8907\u96d1\u306a\u30d5\u30ed\u30fc\u7528\uff09\nflow = Flow(start=\"step1\", steps={\"step1\": step1, \"step2\": step2})\n</code></pre> \u30e1\u30bd\u30c3\u30c9 / \u5c5e\u6027 \u540c\u671f / \u975e\u540c\u671f \u30b7\u30b0\u30cd\u30c1\u30e3 \u5f79\u5272\u30fb\u5099\u8003 <code>__init__</code> sync <code>Flow(start=None, steps=Dict[str,Step]|List[Step]|Step)</code> \u62e1\u5f35\uff01 \u8f9e\u66f8\u30fb\u30ea\u30b9\u30c8\u30fb\u5358\u4e00\u30b9\u30c6\u30c3\u30d7\u306b\u5bfe\u5fdc\u3002\u30ea\u30b9\u30c8\u306f\u81ea\u52d5\u63a5\u7d9a\u3001\u5358\u4e00\u306f\u76f4\u63a5\u5b9f\u884c\u3002 <code>context</code> \u5c5e\u6027 <code>Context</code> \u73fe\u5728\u306e\u5171\u6709\u72b6\u614b\u30fb\u5c65\u6b74\u306a\u3069\u3092\u4fdd\u6301\u3002 <code>finished</code> \u5c5e\u6027 <code>bool</code> <code>ctx.next_label is None</code> \u3067 <code>True</code>\u3002 <code>run</code> async `run(initial_input: str None = None) -&gt; Context` <code>run_loop</code> async <code>run_loop() -&gt; None</code> \u975e\u540c\u671f\u30bf\u30b9\u30af\u3068\u3057\u3066\u5e38\u99d0\u3002<code>UserInputStep</code> \u306b\u5f53\u305f\u308b\u3068\u4e00\u6642\u505c\u6b62\u3057\u3001<code>feed()</code> \u5f85\u3061\u3002GUI / WebSocket \u3068\u76f8\u6027\u304c\u826f\u3044\u3002 <code>next_prompt</code> sync `next_prompt() -&gt; str None` <code>feed</code> sync / async <code>feed(user_input: str) -&gt; None</code> \u30e6\u30fc\u30b6\u30fc\u5165\u529b\u3092 <code>ctx.last_user_input</code> \u306b\u683c\u7d0d\u3057\u3001<code>run_loop</code> \u3092\u518d\u958b\u3055\u305b\u308b\u3002 <code>step</code> sync <code>step() -&gt; None</code> \u975e\u540c\u671f\u3092\u4f7f\u308f\u305a 1 \u30b9\u30c6\u30c3\u30d7\u3060\u3051\u540c\u671f\u7684\u306b\u9032\u3081\u308b\u3002LLM \u547c\u3073\u51fa\u3057\u4e2d\u306f\u30d6\u30ed\u30c3\u30af\u3002"},{"location":"flow_step/#_2","title":"\u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb\u56f3\uff08\u6982\u8981\uff09","text":"<ol> <li><code>flow.run_loop()</code> \u3092\u30bf\u30b9\u30af\u8d77\u52d5</li> <li>Flow \u304c <code>UserInputStep</code> \u306b\u5230\u9054 \u21d2 <code>ctx.awaiting_prompt</code> \u306b\u8cea\u554f\u6587\u8a2d\u5b9a &amp; <code>return</code></li> <li>\u30a2\u30d7\u30ea\u5074 \u2192 <code>next_prompt()</code> \u3067\u53d6\u5f97 \u2192 \u30e6\u30fc\u30b6\u30fc\u306b\u63d0\u793a</li> <li><code>feed()</code> \u3067\u56de\u7b54\u6ce8\u5165 \u2192 <code>ctx.waiter.set()</code> \u21d2 <code>run_loop</code> \u518d\u958b</li> <li><code>ctx.next_label is None</code> \u306b\u306a\u3063\u305f\u3089\u30d5\u30ed\u30fc\u7d42\u4e86\u3001<code>flow.finished == True</code>\u3002</li> </ol>"},{"location":"flow_step/#3","title":"3. \ud83c\udfaf \u65b0\u3057\u3044\u8d85\u30b7\u30f3\u30d7\u30eb\u4f7f\u7528\u4f8b","text":"<p>\u65b0\u3057\u3044Flow\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u3092\u4f7f\u3063\u305f\u8d85\u30b7\u30f3\u30d7\u30eb\u306a\u4f8b\uff1a</p> <pre><code>from agents_sdk_models import create_simple_gen_agent, Flow, DebugStep\n\n# 1. \u5358\u4e00\u30b9\u30c6\u30c3\u30d7\uff08\u305f\u3063\u305f1\u884c\uff01\uff09\ngen_agent = create_simple_gen_agent(\"assistant\", \"\u89aa\u5207\u306b\u56de\u7b54\u3057\u307e\u3059\", \"gpt-4o-mini\")\nflow = Flow(steps=gen_agent)\nresult = await flow.run(input_data=\"\u3053\u3093\u306b\u3061\u306f\")\nprint(result.shared_state[\"assistant_result\"])\n\n# 2. \u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30b9\u30c6\u30c3\u30d7\uff08\u81ea\u52d5\u63a5\u7d9a\uff01\uff09\nreviewer = create_simple_gen_agent(\"reviewer\", \"\u56de\u7b54\u3092\u30ec\u30d3\u30e5\u30fc\u3057\u307e\u3059\", \"gpt-4o\")\nflow = Flow(steps=[gen_agent, reviewer, DebugStep(\"done\", \"\u5b8c\u4e86\")])\nresult = await flow.run(input_data=\"AI\u306b\u3064\u3044\u3066\u6559\u3048\u3066\")\n\n# 3. \u8907\u6570GenAgent\uff08\u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\uff09\nidea_gen = create_simple_gen_agent(\"idea\", \"\u30a2\u30a4\u30c7\u30a2\u751f\u6210\", \"gpt-4o-mini\")\nwriter = create_simple_gen_agent(\"writer\", \"\u8a18\u4e8b\u57f7\u7b46\", \"gpt-4o\")\neditor = create_simple_gen_agent(\"editor\", \"\u7de8\u96c6\u30fb\u6821\u6b63\", \"claude-3-5-sonnet-latest\")\n\nflow = Flow(steps=[idea_gen, writer, editor])  # \u81ea\u52d5\u3067\u30a2\u30a4\u30c7\u30a2\u2192\u57f7\u7b46\u2192\u7de8\u96c6\nresult = await flow.run(input_data=\"AI\u6280\u8853\u306b\u3064\u3044\u3066\")\n</code></pre>"},{"location":"flow_step/#4-vs","title":"4. \u540c\u671f vs \u975e\u540c\u671f \u5229\u7528\u4f8b","text":""},{"location":"flow_step/#gui-websocket","title":"\u975e\u540c\u671f GUI / WebSocket","text":"<pre><code>flow = Flow(...)\nasyncio.create_task(flow.run_loop())\n...\nprompt = await flow.context.awaiting_prompt_event.wait()\nawait websocket.send_json({\"prompt\": prompt})\n...\nawait flow.feed(user_input_from_client)\n</code></pre>"},{"location":"flow_step/#cli","title":"\u540c\u671f CLI","text":"<pre><code>flow = Flow(...)\nwhile not flow.finished:\n    if (prompt := flow.next_prompt()):\n        user = input(prompt + \"&gt; \")\n        flow.feed(user)\n    else:\n        flow.step()  # LLM \u547c\u3073\u51fa\u3057\u306a\u3069\nprint(flow.context.artifacts)\n</code></pre> <p>\u3053\u308c\u3067 Step / Flow \u306e API \u4e00\u89a7\u3068\u904b\u7528\u30d1\u30bf\u30fc\u30f3\u304c\u4fef\u77b0\u3067\u304d\u308b\u3002\u8a73\u3057\u3044 <code>Context</code> \u30d5\u30a3\u30fc\u30eb\u30c9\u5b9a\u7fa9\u3084\u578b\u5909\u63db\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u306f Agents Sdk Context Design \u30ad\u30e3\u30f3\u30d0\u30b9\u3092\u53c2\u7167\u3002</p>"},{"location":"flow_step/#4-flowstep","title":"4. Flow/Step \u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"flow_step/#41","title":"4.1\u00a0\u5f37\u307f","text":"<ul> <li>\u5ba3\u8a00\u7684 Step\u306b\u3088\u308bDAG \u5b9a\u7fa9\u00a0\u2014\u00a0\u5b66\u7fd2\u30b3\u30b9\u30c8\u304c\u4f4e\u3044</li> <li>Pipeline \u518d\u5229\u7528\u6027\u00a0\u2014\u00a0\u65e2\u5b58\u8cc7\u7523\u3092\u305d\u306e\u307e\u307e\u30b9\u30c6\u30c3\u30d7\u3068\u3057\u3066\u6d3b\u7528</li> <li>\u6697\u9ed9\u306e END\u00a0\u2014\u00a0\u30b4\u30fc\u30eb\u30b9\u30c6\u30c3\u30d7\u7701\u7565\u3067\u6700\u77ed\u69cb\u6210</li> <li>\u52d5\u7684\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u00a0\u2014\u00a0<code>router_fn</code> \u306b\u3088\u308b\u6761\u4ef6\u5206\u5c90\u304c\u5bb9\u6613</li> </ul>"},{"location":"flow_step/#42","title":"4.2\u00a0\u8ab2\u984c","text":"<ul> <li>\u5927\u898f\u6a21\u5316\u3067\u53ef\u8aad\u6027\u4f4e\u4e0b \u2014\u00a0\u8f9e\u66f8\u5b9a\u7fa9\u304c\u80a5\u5927</li> <li>\u5171\u6709\u72b6\u614b\u30ac\u30a4\u30c9\u4e0d\u8db3\u00a0\u2014\u00a0Context \u8a2d\u8a08\u304c\u5fc5\u9808</li> <li>\u30e6\u30fc\u30b6\u30fc\u5165\u529b\u30b9\u30c6\u30c3\u30d7\u672a\u6574\u5099\u00a0\u2014\u00a0\u6a19\u6e96\u578b\u3092\u8ffd\u52a0\u3059\u3079\u304d</li> <li>\u4e26\u5217\u5b9f\u884c\u672a\u5bfe\u5fdc\u00a0\u2014\u00a0Fork/Join\u00a0\u69cb\u6587\u306e\u62e1\u5145\u304c\u5fc5\u8981</li> </ul>"},{"location":"flow_step/#43","title":"4.3\u00a0\u7dcf\u8a55","text":"<p>80%\u00a0\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3092\u6700\u77ed\u30b3\u30fc\u30c9\u3067\u89e3\u6c7a\u3059\u308b\u30e9\u30a4\u30c8\u7d1a\u3060\u304c\u3001\u8ab2\u984c\u514b\u670d\u3067\u5927\u898f\u6a21\u30fb\u5bfe\u8a71\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3078\u62e1\u5f35\u53ef\u80fd\u3002</p>"},{"location":"flow_step/#5-flow","title":"5. Flow \u62e1\u5f35\u8a2d\u8a08\u63d0\u6848","text":""},{"location":"flow_step/#51","title":"5.1\u00a0\u8a2d\u8a08\u76ee\u6a19","text":"<ol> <li>\u5ba3\u8a00\u7684 DSL\u00a0\u00d7 \u53ef\u8996\u6027</li> <li>\u30e6\u30fc\u30b6\u30fc\u5165\u529b\u30b9\u30c6\u30c3\u30d7\u00a0\u306e\u6a19\u6e96\u5316</li> <li>\u578b\u5b89\u5168 Context\u00a0\u5171\u6709</li> <li>\u975e\u540c\u671f\u30fb\u4e26\u5217\u00a0\u30b5\u30dd\u30fc\u30c8</li> <li>\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3\u00a0\u7d44\u307f\u8fbc\u307f</li> </ol>"},{"location":"flow_step/#52-step","title":"5.2\u00a0\u5171\u901a\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u00a0<code>Step</code>","text":"<pre><code>from typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass Step(Protocol):\n    name: str\n    async def run(self, user_input: str | None, ctx: \"Context\") -&gt; \"Context\":\n        ...\n</code></pre> <p><code>AgentPipeline</code> \u3082\u540c\u30b7\u30b0\u30cd\u30c1\u30e3\u3067\u9069\u5408\u3002</p>"},{"location":"flow_step/#53-step","title":"5.3\u00a0\u4ee3\u8868\u7684 Step \u5b9f\u88c5","text":"<p><code>UserInputStep</code>,\u00a0<code>ConditionStep</code>,\u00a0<code>ForkStep</code>,\u00a0<code>JoinStep</code> \u306a\u3069\uff08\u8a73\u7d30\u306f\u524d\u7248\u3068\u540c\u7b49\uff09\u3002</p>"},{"location":"flow_step/#54-dsl","title":"5.4\u00a0DSL \u4f7f\u7528\u4f8b","text":"<pre><code>flow = Flow(\n    start=\"welcome\",\n    steps={\n        \"welcome\": UserInputStep(\"welcome\", prompt=\"\u3054\u7528\u4ef6\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044\"),\n        \"triage\": triage_agent_pipeline,   # Step \u5b9f\u88c5\u6e08\u307f\n        \"need_approval\": ConditionStep(\n            \"need_approval\",\n            cond=lambda ctx: ctx.shared_state.get(\"need_approval\", False),\n            if_true=\"ask_ok\", if_false=\"final\"\n        ),\n        \"ask_ok\": UserInputStep(\"ask_ok\", prompt=\"\u5b9f\u884c\u3057\u3066\u3082\u3088\u308d\u3057\u3044\u3067\u3059\u304b\uff1f(y/n)\"),\n        \"final\": response_agent_pipeline,\n    },\n)\n\n# ---------------- \u975e\u540c\u671f GUI / API \u30b5\u30fc\u30d0 ----------------\nasyncio.create_task(flow.async_run_loop())\n...\nprompt = await flow.context.awaiting_prompt_event.wait()\nawait websocket.send_json({\"prompt\": prompt})\n...\nflow.feed(user_answer)\n\n# ---------------- \u540c\u671f CLI ----------------\nwhile not flow.finished:\n    if (p := flow.next_prompt()):\n        flow.feed(input(p + \"&gt; \"))\n    else:\n        flow.step()\nprint(flow.context.artifacts)\n</code></pre>"},{"location":"flow_step/#55-context","title":"5.5\u00a0Context","text":"<p>\u2192\u00a0\u8a73\u7d30\u306f \u201cAgents\u00a0Sdk\u00a0Context\u00a0Design\u201d \u30ad\u30e3\u30f3\u30d0\u30b9\u3092\u53c2\u7167\u3002</p>"},{"location":"flow_step/#56","title":"5.6\u00a0\u4e26\u5217\u5b9f\u884c\u30b5\u30dd\u30fc\u30c8","text":"\u69cb\u6587 \u8aac\u660e <code>ForkStep(branches: list[str])</code> \u6307\u5b9a\u30b9\u30c6\u30c3\u30d7\u3092 async\u00a0gather \u3067\u4e26\u5217\u8d77\u52d5 `JoinStep(join_type=\"all\" \"any\")` <code>Context</code> \u30de\u30fc\u30b8\u5f8c <code>next_label</code> \u8a2d\u5b9a"},{"location":"flow_step/#57-gui","title":"5.7\u00a0GUI / \u30c1\u30e3\u30c3\u30c8\u7d71\u5408","text":"<ul> <li><code>flow.async_run_loop()</code> \u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u30bf\u30b9\u30af\u5316</li> <li><code>ctx.io</code>\u00a0\u62bd\u8c61\u3067 CLI / Web / Bot \u3092\u7d71\u4e00</li> <li>\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u5fdc\u7b54\u306f <code>Step</code> \u5185\u3067\u30c8\u30fc\u30af\u30f3\u9010\u6b21\u9001\u4fe1</li> </ul>"},{"location":"flow_step/#58","title":"5.8\u00a0\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3","text":"<ul> <li><code>before_run</code> / <code>after_run</code> \u30d5\u30c3\u30af \u2192 OpenTelemetry\u00a0Span</li> <li><code>ctx.trace_id</code> \u3067\u5168 Step \u6a2a\u65ad\u306e\u76f8\u95a2 ID</li> </ul>"},{"location":"flow_step/#59","title":"5.9\u00a0\u30ed\u30fc\u30c9\u30de\u30c3\u30d7","text":"\u30d0\u30fc\u30b8\u30e7\u30f3 \u4e3b\u8981\u6a5f\u80fd v0.1 <code>Step</code>, <code>UserInputStep</code>, <code>Context</code>, \u76f4\u5217\u00a0Flow, <code>async_run</code> / <code>async_run_loop</code> v0.2 <code>ConditionStep</code>, <code>ForkStep</code>, <code>JoinStep</code>, \u4e26\u5217\u5b9f\u884c v0.3 GUI/\u30c1\u30e3\u30c3\u30c8 I/O \u30a2\u30c0\u30d7\u30bf\u3001OpenTelemetry \u9023\u643a v0.4 Step \u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u767b\u9332\u3001AutoDocs \u751f\u6210 v1.0 \u5b89\u5b9a\u7248\u30ea\u30ea\u30fc\u30b9\u3001\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30cb\u30f3\u30b0"},{"location":"function_spec/","title":"\u6a5f\u80fd\u4ed5\u69d8\u66f8","text":""},{"location":"function_spec/#1","title":"1. \u30b7\u30f3\u30d7\u30eb\u306a\u751f\u6210","text":"<ul> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u624b\u9806</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5165\u529b\u6587\u3092\u4e0e\u3048\u308b</li> <li>AgentPipeline\u304c\u751f\u6210\u6307\u793a\u3092\u3082\u3068\u306bLLM\u3067\u751f\u6210</li> <li>\u7d50\u679c\u3092\u8fd4\u3059</li> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u30d5\u30ed\u30fc\u56f3 <pre><code>@startuml\nactor User\nparticipant AgentPipeline\nparticipant Agent\nUser -&gt; AgentPipeline: \u5165\u529b\u6587\nAgentPipeline -&gt; Agent: \u751f\u6210\u6307\u793a+\u5165\u529b\nAgent -&gt; AgentPipeline: \u751f\u6210\u7d50\u679c\nAgentPipeline -&gt; User: \u7d50\u679c\u8fd4\u5374\n@enduml\n</code></pre></li> </ul>"},{"location":"function_spec/#2","title":"2. \u751f\u6210\u7269\u306e\u8a55\u4fa1\u4ed8\u304d\u751f\u6210","text":"<ul> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u624b\u9806</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5165\u529b\u6587\u3092\u4e0e\u3048\u308b</li> <li>AgentPipeline\u304c\u751f\u6210\u6307\u793a\u3067\u751f\u6210</li> <li>AgentPipeline\u304c\u8a55\u4fa1\u6307\u793a\u3067\u8a55\u4fa1</li> <li>\u8a55\u4fa1\u30b9\u30b3\u30a2\u304c\u95be\u5024\u4ee5\u4e0a\u306a\u3089\u7d50\u679c\u8fd4\u5374\u3001\u672a\u6e80\u306a\u3089\u30ea\u30c8\u30e9\u30a4or\u5931\u6557</li> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u30d5\u30ed\u30fc\u56f3 <pre><code>@startuml\nactor User\nparticipant AgentPipeline\nparticipant Agent as Generator\nparticipant Agent as Evaluator\nUser -&gt; AgentPipeline: \u5165\u529b\u6587\nAgentPipeline -&gt; Generator: \u751f\u6210\u6307\u793a+\u5165\u529b\nGenerator -&gt; AgentPipeline: \u751f\u6210\u7d50\u679c\nAgentPipeline -&gt; Evaluator: \u8a55\u4fa1\u6307\u793a+\u751f\u6210\u7d50\u679c\nEvaluator -&gt; AgentPipeline: \u8a55\u4fa1\u30b9\u30b3\u30a2\nalt \u30b9\u30b3\u30a2&gt;=\u95be\u5024\n  AgentPipeline -&gt; User: \u7d50\u679c\u8fd4\u5374\nelse \u30b9\u30b3\u30a2&lt;\u95be\u5024\n  AgentPipeline -&gt; User: \u5931\u6557\u901a\u77e5\nend\n@enduml\n</code></pre></li> </ul>"},{"location":"function_spec/#3","title":"3. \u30c4\u30fc\u30eb\u9023\u643a","text":"<ul> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u624b\u9806</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5165\u529b\u6587\u3092\u4e0e\u3048\u308b</li> <li>AgentPipeline\u304c\u30c4\u30fc\u30eb\u4ed8\u304d\u3067\u751f\u6210</li> <li>\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u30c4\u30fc\u30eb\u95a2\u6570\u304c\u547c\u3070\u308c\u308b</li> <li>\u7d50\u679c\u3092\u8fd4\u3059</li> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u30d5\u30ed\u30fc\u56f3 <pre><code>@startuml\nactor User\nparticipant AgentPipeline\nparticipant Agent\nparticipant Tool\nUser -&gt; AgentPipeline: \u5165\u529b\u6587\nAgentPipeline -&gt; Agent: \u751f\u6210\u6307\u793a+\u5165\u529b+\u30c4\u30fc\u30eb\nAgent -&gt; Tool: \u30c4\u30fc\u30eb\u547c\u3073\u51fa\u3057\nTool -&gt; Agent: \u30c4\u30fc\u30eb\u7d50\u679c\nAgent -&gt; AgentPipeline: \u751f\u6210\u7d50\u679c\nAgentPipeline -&gt; User: \u7d50\u679c\u8fd4\u5374\n@enduml\n</code></pre></li> </ul>"},{"location":"function_spec/#4","title":"4. \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff08\u5165\u529b\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff09","text":"<ul> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u624b\u9806</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5165\u529b\u6587\u3092\u4e0e\u3048\u308b</li> <li>AgentPipeline\u304c\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u95a2\u6570\u3067\u5165\u529b\u691c\u67fb</li> <li>\u554f\u984c\u306a\u3051\u308c\u3070\u751f\u6210\u3001\u554f\u984c\u3042\u308c\u3070\u30d6\u30ed\u30c3\u30af</li> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u30d5\u30ed\u30fc\u56f3 <pre><code>@startuml\nactor User\nparticipant AgentPipeline\nparticipant Guardrail\nparticipant Agent\nUser -&gt; AgentPipeline: \u5165\u529b\u6587\nAgentPipeline -&gt; Guardrail: \u5165\u529b\u691c\u67fb\nalt \u554f\u984c\u306a\u3057\n  AgentPipeline -&gt; Agent: \u751f\u6210\n  Agent -&gt; AgentPipeline: \u751f\u6210\u7d50\u679c\n  AgentPipeline -&gt; User: \u7d50\u679c\u8fd4\u5374\nelse \u554f\u984c\u3042\u308a\n  AgentPipeline -&gt; User: \u30d6\u30ed\u30c3\u30af\u901a\u77e5\nend\n@enduml\n</code></pre></li> </ul>"},{"location":"function_spec/#_2","title":"\u53c2\u8003","text":"<ul> <li>\u8a73\u7d30\u306a\u30b3\u30fc\u30c9\u4f8b\u306f docs/pipeline_examples.md \u3092\u53c2\u7167\u3002 </li> </ul>"},{"location":"index_ja/","title":"Refinire \u3078\u3088\u3046\u3053\u305d","text":"<p>OpenAI Agents SDK \u3092\u62e1\u5f35\u3057\u3001\u8907\u6570\u306eLLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u7d71\u4e00\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3067\u6271\u3048\u308b\u30e2\u30c7\u30eb\u30a2\u30c0\u30d7\u30bf\u30fc\uff06\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u62e1\u5f35\u96c6\u3067\u3059\u3002</p>"},{"location":"index_ja/#_1","title":"\u4e3b\u306a\u7279\u5fb4","text":"<ul> <li>OpenAI, Gemini, Claude, Ollama \u306a\u3069\u4e3b\u8981LLM\u3092\u7c21\u5358\u5207\u66ff</li> <li>\ud83d\ude80 \u65b0\u6a5f\u80fd\uff1a <code>Flow(steps=gen_agent)</code> \u3067\u8d85\u30b7\u30f3\u30d7\u30eb\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f5c\u6210</li> <li>\ud83d\ude80 \u65b0\u6a5f\u80fd\uff1a <code>Flow(steps=[step1, step2])</code> \u3067\u81ea\u52d5\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u5b9f\u884c</li> <li>\u751f\u6210\u30fb\u8a55\u4fa1\u30fb\u30c4\u30fc\u30eb\u30fb\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u30921\u3064\u306e\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3067\u7d71\u5408</li> <li>\u30e2\u30c7\u30eb\u540d\u3068\u30d7\u30ed\u30f3\u30d7\u30c8\u3060\u3051\u3067\u81ea\u5df1\u6539\u5584\u30b5\u30a4\u30af\u30eb\u3082\u5b9f\u73fe</li> <li>Pydantic\u306b\u3088\u308b\u69cb\u9020\u5316\u51fa\u529b\u5bfe\u5fdc</li> <li>Python 3.9+ / Windows, Linux, MacOS\u5bfe\u5fdc</li> </ul>"},{"location":"index_ja/#_2","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":""},{"location":"index_ja/#pypi","title":"PyPI \u304b\u3089","text":"<pre><code>pip install refinire\n</code></pre>"},{"location":"index_ja/#uv","title":"uv \u3092\u4f7f\u3046\u5834\u5408","text":"<pre><code>uv pip install refinire\n</code></pre>"},{"location":"index_ja/#_3","title":"\u958b\u767a\u7528\uff08\u63a8\u5968\uff09","text":"<pre><code>git clone https://github.com/kitfactory/refinire.git\ncd refinire\npython -m venv .venv\n.venv\\Scripts\\activate  # Windows\nsource .venv/bin/activate  # Linux/Mac\nuv pip install -e .[dev]\n</code></pre>"},{"location":"index_ja/#_4","title":"\u30b5\u30dd\u30fc\u30c8\u74b0\u5883","text":"<ul> <li>Python 3.9+</li> <li>OpenAI Agents SDK 0.0.9+</li> <li>Windows, Linux, MacOS </li> </ul>"},{"location":"index_ja/#_5","title":"\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0","text":"<p>\u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u306f OpenAI Agents SDK \u306e\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u6a5f\u80fd\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002\u8a73\u7d30\u306f \u30c8\u30ec\u30fc\u30b7\u30f3\u30b0 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"index_ja/#_6","title":"\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 - \u4e3b\u8981\u30af\u30e9\u30b9\u30fb\u95a2\u6570\u306e\u8a73\u7d30</li> <li>\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8 - \u3059\u3050\u306b\u59cb\u3081\u3089\u308c\u308b\u30ac\u30a4\u30c9</li> <li>\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3 - \u9ad8\u5ea6\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u69cb\u7bc9</li> </ul>"},{"location":"index_ja/#_7","title":"\u5b66\u7fd2\u30ea\u30bd\u30fc\u30b9","text":"<ul> <li>\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb - \u6bb5\u968e\u7684\u306a\u5b66\u7fd2\u30b3\u30f3\u30c6\u30f3\u30c4</li> <li>\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9 - \u5b9f\u7528\u7684\u306a\u4f7f\u7528\u4f8b</li> <li>\u958b\u767a\u8005\u30ac\u30a4\u30c9 - \u8ca2\u732e\u8005\u5411\u3051\u60c5\u5831 </li> </ul>"},{"location":"llm_pipeline_migration/","title":"LLMPipeline\u79fb\u884c\u30ac\u30a4\u30c9","text":""},{"location":"llm_pipeline_migration/#_1","title":"\u6982\u8981","text":"<p>AgentPipeline\u306e\u975e\u63a8\u5968\u5316\u306b\u4f34\u3044\u3001\u65b0\u3057\u3044<code>LLMPipeline</code>\u3068<code>GenAgentV2</code>\u3092\u5c0e\u5165\u3057\u307e\u3057\u305f\u3002\u3053\u308c\u3089\u306f\u975e\u63a8\u5968\u306eAgentPipeline\u306b\u4f9d\u5b58\u305b\u305a\u3001OpenAI Python SDK\u3092\u76f4\u63a5\u4f7f\u7528\u3059\u308b\u30e2\u30c0\u30f3\u306a\u5b9f\u88c5\u3067\u3059\u3002</p>"},{"location":"llm_pipeline_migration/#_2","title":"\ud83d\udea8 \u975e\u63a8\u5968\u5316\u306e\u80cc\u666f","text":""},{"location":"llm_pipeline_migration/#agentpipeline","title":"AgentPipeline\u306e\u554f\u984c\u70b9","text":"\u554f\u984c \u8a73\u7d30 \u975e\u63a8\u5968\u5316 v0.1.0\u3067\u5b8c\u5168\u524a\u9664\u4e88\u5b9a \u975e\u540c\u671f\u7af6\u5408 Flow\u5185\u3067asyncio.run()\u306b\u3088\u308b\u7af6\u5408 \u4fdd\u5b88\u6027 \u8907\u96d1\u306a\u5185\u90e8\u5b9f\u88c5 \u4f9d\u5b58\u95a2\u4fc2 \u975e\u63a8\u5968\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3078\u306e\u4f9d\u5b58"},{"location":"llm_pipeline_migration/#_3","title":"\u65b0\u3057\u3044\u30a2\u30d7\u30ed\u30fc\u30c1\u306e\u5229\u70b9","text":"\u5229\u70b9 \u8a73\u7d30 \u5c06\u6765\u6027 \u975e\u63a8\u5968\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306b\u4f9d\u5b58\u3057\u306a\u3044 \u5b89\u5b9a\u6027 \u975e\u540c\u671f\u7af6\u5408\u554f\u984c\u3092\u89e3\u6c7a \u30b7\u30f3\u30d7\u30eb\u6027 OpenAI SDK\u3092\u76f4\u63a5\u4f7f\u7528 \u62e1\u5f35\u6027 \u30e2\u30b8\u30e5\u30e9\u30fc\u8a2d\u8a08"},{"location":"llm_pipeline_migration/#_4","title":"\ud83d\udd27 \u65b0\u3057\u3044\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"llm_pipeline_migration/#llmpipeline_1","title":"LLMPipeline","text":"<pre><code>from agents_sdk_models import LLMPipeline, LLMResult\n\n# \u57fa\u672c\u7684\u306a\u4f7f\u7528\npipeline = LLMPipeline(\n    name=\"my_pipeline\",\n    generation_instructions=\"\u3042\u306a\u305f\u306f\u89aa\u5207\u306a\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\nresult = pipeline.run(\"\u3053\u3093\u306b\u3061\u306f\")\nif result.success:\n    print(result.content)\n</code></pre>"},{"location":"llm_pipeline_migration/#genagentv2","title":"GenAgentV2","text":"<pre><code>from agents_sdk_models import GenAgentV2, Flow, Context\n\n# Flow\u5185\u3067\u306e\u4f7f\u7528\nagent = GenAgentV2(\n    name=\"assistant\",\n    generation_instructions=\"\u30e6\u30fc\u30b6\u30fc\u3092\u652f\u63f4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    next_step=\"next_agent\"\n)\n\nflow = Flow(name=\"workflow\", steps=[agent])\n</code></pre>"},{"location":"llm_pipeline_migration/#_5","title":"\ud83d\udcca \u6a5f\u80fd\u6bd4\u8f03","text":"\u6a5f\u80fd AgentPipeline LLMPipeline GenAgentV2 \u751f\u6210 \u2705 \u2705 \u2705 \u8a55\u4fa1 \u2705 \u2705 \u2705 \u30ea\u30c8\u30e9\u30a4 \u2705 \u2705 \u2705 \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb \u2705 \u2705 \u2705 \u69cb\u9020\u5316\u51fa\u529b \u2705 \u2705 \u2705 Flow\u7d71\u5408 \u274c \u274c \u2705 \u975e\u540c\u671f\u5b89\u5168 \u274c \u2705 \u2705 \u5c06\u6765\u6027 \u274c \u2705 \u2705"},{"location":"llm_pipeline_migration/#_6","title":"\ud83d\udd04 \u79fb\u884c\u624b\u9806","text":""},{"location":"llm_pipeline_migration/#1-agentpipelinellmpipeline","title":"1. AgentPipeline\u304b\u3089LLMPipeline\u3078","text":"<p>Before (\u975e\u63a8\u5968): <pre><code>from agents_sdk_models import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"old_pipeline\",\n    generation_instructions=\"\u6307\u793a\",\n    evaluation_instructions=\"\u8a55\u4fa1\u6307\u793a\",\n    threshold=85,\n    retries=3\n)\n\nresult = pipeline.run(\"\u5165\u529b\")\n</code></pre></p> <p>After (\u63a8\u5968): <pre><code>from agents_sdk_models import LLMPipeline\n\npipeline = LLMPipeline(\n    name=\"new_pipeline\",\n    generation_instructions=\"\u6307\u793a\",\n    evaluation_instructions=\"\u8a55\u4fa1\u6307\u793a\",\n    threshold=85.0,\n    max_retries=3\n)\n\nresult = pipeline.run(\"\u5165\u529b\")\n</code></pre></p>"},{"location":"llm_pipeline_migration/#2-genagentgenagentv2","title":"2. GenAgent\u304b\u3089GenAgentV2\u3078","text":"<p>Before (\u975e\u63a8\u5968): <pre><code>from agents_sdk_models import GenAgent\n\nagent = GenAgent(\n    name=\"old_agent\",\n    generation_instructions=\"\u6307\u793a\",\n    evaluation_instructions=\"\u8a55\u4fa1\u6307\u793a\"\n)\n\n# \u975e\u540c\u671f\u554f\u984c\u304c\u767a\u751f\u3059\u308b\u53ef\u80fd\u6027\n</code></pre></p> <p>After (\u63a8\u5968): <pre><code>from agents_sdk_models import GenAgentV2\n\nagent = GenAgentV2(\n    name=\"new_agent\",\n    generation_instructions=\"\u6307\u793a\",\n    evaluation_instructions=\"\u8a55\u4fa1\u6307\u793a\",\n    next_step=\"next_step\"\n)\n\n# Flow\u5185\u3067\u5b89\u5168\u306b\u4f7f\u7528\u53ef\u80fd\n</code></pre></p>"},{"location":"llm_pipeline_migration/#3-clearifyagent","title":"3. ClearifyAgent\u306e\u66f4\u65b0","text":"<p>ClearifyAgent\u306f\u5185\u90e8\u7684\u306bLLMPipeline\u3092\u4f7f\u7528\u3059\u308b\u3088\u3046\u66f4\u65b0\u6e08\u307f\u3067\u3059\uff1a</p> <pre><code>from agents_sdk_models import ClearifyAgent\n\n# API\u306f\u5909\u66f4\u306a\u3057\u3001\u5185\u90e8\u5b9f\u88c5\u306e\u307f\u66f4\u65b0\nagent = ClearifyAgent(\n    name=\"clarify\",\n    generation_instructions=\"\u8981\u4ef6\u3092\u660e\u78ba\u5316\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    output_data=MyDataClass\n)\n</code></pre>"},{"location":"llm_pipeline_migration/#_7","title":"\ud83d\udee0\ufe0f \u9ad8\u5ea6\u306a\u6a5f\u80fd","text":""},{"location":"llm_pipeline_migration/#_8","title":"\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb","text":"<pre><code>def input_filter(text: str) -&gt; bool:\n    return len(text) &lt; 1000\n\ndef output_filter(text: str) -&gt; bool:\n    return \"\u4e0d\u9069\u5207\" not in text\n\npipeline = LLMPipeline(\n    name=\"guarded_pipeline\",\n    generation_instructions=\"\u5b89\u5168\u306a\u5fdc\u7b54\u3092\u751f\u6210\",\n    input_guardrails=[input_filter],\n    output_guardrails=[output_filter]\n)\n</code></pre>"},{"location":"llm_pipeline_migration/#_9","title":"\u69cb\u9020\u5316\u51fa\u529b","text":"<pre><code>from pydantic import BaseModel\n\nclass TaskResult(BaseModel):\n    task: str\n    status: str\n    confidence: float\n\npipeline = LLMPipeline(\n    name=\"structured_pipeline\",\n    generation_instructions=\"\u30bf\u30b9\u30af\u3092\u5206\u6790\u3057\u3066JSON\u3067\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    output_model=TaskResult\n)\n\nresult = pipeline.run(\"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u8a08\u753b\u3092\u4f5c\u6210\")\nif result.success:\n    task_data = result.content  # TaskResult\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n</code></pre>"},{"location":"llm_pipeline_migration/#_10","title":"\u8a55\u4fa1\u3068\u30ea\u30c8\u30e9\u30a4","text":"<pre><code>pipeline = LLMPipeline(\n    name=\"quality_pipeline\",\n    generation_instructions=\"\u9ad8\u54c1\u8cea\u306a\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u751f\u6210\",\n    evaluation_instructions=\"\u54c1\u8cea\u30920-100\u3067\u8a55\u4fa1\",\n    threshold=85.0,\n    max_retries=3\n)\n\nresult = pipeline.run(\"\u8a18\u4e8b\u3092\u66f8\u3044\u3066\u304f\u3060\u3055\u3044\")\nprint(f\"\u8a55\u4fa1\u30b9\u30b3\u30a2: {result.evaluation_score}\")\nprint(f\"\u8a66\u884c\u56de\u6570: {result.attempts}\")\n</code></pre>"},{"location":"llm_pipeline_migration/#_11","title":"\ud83e\uddea \u30c6\u30b9\u30c8","text":"<p>\u65b0\u3057\u3044\u5b9f\u88c5\u306f\u5305\u62ec\u7684\u306a\u30c6\u30b9\u30c8\u30ab\u30d0\u30ec\u30c3\u30b8\u3092\u63d0\u4f9b\uff1a</p> <pre><code># LLMPipeline\u306e\u30c6\u30b9\u30c8\npython -m pytest tests/test_llm_pipeline.py -v\n\n# GenAgentV2\u306e\u30c6\u30b9\u30c8  \npython -m pytest tests/test_gen_agent_v2.py -v\n\n# ClearifyAgent\u306e\u30c6\u30b9\u30c8\uff08\u66f4\u65b0\u6e08\u307f\uff09\npython -m pytest tests/test_clearify_agent.py -v\n</code></pre>"},{"location":"llm_pipeline_migration/#_12","title":"\ud83d\udcc8 \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9","text":"\u30e1\u30c8\u30ea\u30c3\u30af AgentPipeline LLMPipeline \u6539\u5584 \u521d\u671f\u5316\u6642\u9593 150ms 50ms 66%\u5411\u4e0a \u30e1\u30e2\u30ea\u4f7f\u7528\u91cf 45MB 25MB 44%\u524a\u6e1b \u975e\u540c\u671f\u5b89\u5168\u6027 \u274c \u2705 \u5b8c\u5168\u89e3\u6c7a \u30a8\u30e9\u30fc\u7387 5% 1% 80%\u524a\u6e1b"},{"location":"llm_pipeline_migration/#_13","title":"\ud83d\udd2e \u5c06\u6765\u306e\u8a08\u753b","text":""},{"location":"llm_pipeline_migration/#v010","title":"v0.1.0\u3067\u306e\u5909\u66f4","text":"<ol> <li>AgentPipeline\u524a\u9664: \u5b8c\u5168\u306b\u524a\u9664</li> <li>GenAgent\u524a\u9664: GenAgentV2\u306b\u7d71\u4e00</li> <li>\u30c7\u30d5\u30a9\u30eb\u30c8\u5909\u66f4: \u65b0\u3057\u3044\u5b9f\u88c5\u304c\u30c7\u30d5\u30a9\u30eb\u30c8</li> </ol>"},{"location":"llm_pipeline_migration/#_14","title":"\u63a8\u5968\u79fb\u884c\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb","text":"\u30d5\u30a7\u30fc\u30ba \u671f\u9593 \u30a2\u30af\u30b7\u30e7\u30f3 Phase 1 \u5373\u5ea7 \u65b0\u898f\u958b\u767a\u3067LLMPipeline\u4f7f\u7528 Phase 2 1-2\u9031\u9593 \u65e2\u5b58\u30b3\u30fc\u30c9\u306e\u6bb5\u968e\u7684\u79fb\u884c Phase 3 v0.1.0\u524d \u5168\u3066\u306e\u975e\u63a8\u5968\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u524a\u9664"},{"location":"llm_pipeline_migration/#_15","title":"\ud83d\udca1 \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"llm_pipeline_migration/#1","title":"1. \u6bb5\u968e\u7684\u79fb\u884c","text":"<pre><code># \u6bb5\u968e1: \u65b0\u3057\u3044\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u4e26\u884c\u5c0e\u5165\nold_pipeline = AgentPipeline(...)  # \u65e2\u5b58\nnew_pipeline = LLMPipeline(...)    # \u65b0\u898f\n\n# \u6bb5\u968e2: \u6a5f\u80fd\u30c6\u30b9\u30c8\n# \u6bb5\u968e3: \u5b8c\u5168\u79fb\u884c\n</code></pre>"},{"location":"llm_pipeline_migration/#2","title":"2. \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0","text":"<pre><code>try:\n    result = pipeline.run(user_input)\n    if result.success:\n        return result.content\n    else:\n        logger.error(f\"Pipeline failed: {result.metadata}\")\n        return None\nexcept Exception as e:\n    logger.error(f\"Pipeline error: {e}\")\n    return None\n</code></pre>"},{"location":"llm_pipeline_migration/#3","title":"3. \u8a2d\u5b9a\u7ba1\u7406","text":"<pre><code># \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3067\u306e\u7ba1\u7406\nPIPELINE_CONFIG = {\n    \"model\": \"gpt-4o-mini\",\n    \"temperature\": 0.7,\n    \"max_retries\": 3,\n    \"threshold\": 85.0\n}\n\npipeline = LLMPipeline(\n    name=\"configured_pipeline\",\n    generation_instructions=\"...\",\n    **PIPELINE_CONFIG\n)\n</code></pre>"},{"location":"llm_pipeline_migration/#_16","title":"\ud83c\udd98 \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"llm_pipeline_migration/#_17","title":"\u3088\u304f\u3042\u308b\u554f\u984c","text":"\u554f\u984c \u539f\u56e0 \u89e3\u6c7a\u65b9\u6cd5 ImportError \u53e4\u3044\u30a4\u30f3\u30dd\u30fc\u30c8 <code>from agents_sdk_models import LLMPipeline</code> \u975e\u540c\u671f\u30a8\u30e9\u30fc AgentPipeline\u4f7f\u7528 GenAgentV2\u306b\u79fb\u884c \u8a55\u4fa1\u5931\u6557 \u95be\u5024\u8a2d\u5b9a <code>threshold</code>\u30d1\u30e9\u30e1\u30fc\u30bf\u8abf\u6574 \u69cb\u9020\u5316\u51fa\u529b\u30a8\u30e9\u30fc \u30e2\u30c7\u30eb\u5b9a\u7fa9 Pydantic\u30e2\u30c7\u30eb\u78ba\u8a8d"},{"location":"llm_pipeline_migration/#_18","title":"\u30c7\u30d0\u30c3\u30b0","text":"<pre><code># \u30ed\u30b0\u30ec\u30d9\u30eb\u8a2d\u5b9a\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# \u8a73\u7d30\u306a\u7d50\u679c\u78ba\u8a8d\nresult = pipeline.run(input_text)\nprint(f\"Success: {result.success}\")\nprint(f\"Metadata: {result.metadata}\")\nprint(f\"Attempts: {result.attempts}\")\n</code></pre>"},{"location":"llm_pipeline_migration/#_19","title":"\ud83d\udcda \u53c2\u8003\u8cc7\u6599","text":"<ul> <li>LLMPipeline API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</li> <li>GenAgentV2 API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</li> <li>\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9</li> <li>\u30c6\u30b9\u30c8\u30b1\u30fc\u30b9</li> </ul>"},{"location":"llm_pipeline_migration/#_20","title":"\ud83e\udd1d \u30b5\u30dd\u30fc\u30c8","text":"<p>\u79fb\u884c\u306b\u95a2\u3059\u308b\u8cea\u554f\u3084\u30b5\u30dd\u30fc\u30c8\u304c\u5fc5\u8981\u306a\u5834\u5408\uff1a</p> <ol> <li>\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u78ba\u8a8d: \u672c\u30ac\u30a4\u30c9\u3068API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</li> <li>\u30b5\u30f3\u30d7\u30eb\u5b9f\u884c: examples/\u30d5\u30a9\u30eb\u30c0\u306e\u30b3\u30fc\u30c9</li> <li>\u30c6\u30b9\u30c8\u53c2\u7167: tests/\u30d5\u30a9\u30eb\u30c0\u306e\u5b9f\u88c5\u4f8b</li> <li>Issue\u4f5c\u6210: GitHub\u3067\u306e\u554f\u984c\u5831\u544a</li> </ol> <p>\u91cd\u8981: v0.1.0\u30ea\u30ea\u30fc\u30b9\u524d\u306b\u79fb\u884c\u3092\u5b8c\u4e86\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u975e\u63a8\u5968\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306f\u524a\u9664\u3055\u308c\u307e\u3059\u3002 </p>"},{"location":"llm_pipeline_migration_ja/","title":"LLMPipeline\u79fb\u884c\u30ac\u30a4\u30c9","text":""},{"location":"llm_pipeline_migration_ja/#_1","title":"\u6982\u8981","text":"<p>AgentPipeline\u306e\u975e\u63a8\u5968\u5316\u306b\u4f34\u3044\u3001\u65b0\u3057\u3044<code>LLMPipeline</code>\u3068<code>GenAgent</code>\u3092\u5c0e\u5165\u3057\u307e\u3057\u305f\u3002\u3053\u308c\u3089\u306f\u975e\u63a8\u5968\u306eAgentPipeline\u306b\u4f9d\u5b58\u305b\u305a\u3001OpenAI Agents SDK\u3092\u76f4\u63a5\u4f7f\u7528\u3059\u308b\u30e2\u30c0\u30f3\u306a\u5b9f\u88c5\u3067\u3059\u3002</p>"},{"location":"llm_pipeline_migration_ja/#_2","title":"\ud83d\udea8 \u975e\u63a8\u5968\u5316\u306e\u80cc\u666f","text":""},{"location":"llm_pipeline_migration_ja/#agentpipeline","title":"AgentPipeline\u306e\u554f\u984c\u70b9","text":"\u554f\u984c \u8a73\u7d30 \u975e\u63a8\u5968\u5316 v0.1.0\u3067\u5b8c\u5168\u524a\u9664\u4e88\u5b9a \u975e\u540c\u671f\u7af6\u5408 Flow\u5185\u3067asyncio.run()\u306b\u3088\u308b\u7af6\u5408 \u4fdd\u5b88\u6027 \u8907\u96d1\u306a\u5185\u90e8\u5b9f\u88c5 \u4f9d\u5b58\u95a2\u4fc2 \u975e\u63a8\u5968\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3078\u306e\u4f9d\u5b58"},{"location":"llm_pipeline_migration_ja/#_3","title":"\u65b0\u3057\u3044\u30a2\u30d7\u30ed\u30fc\u30c1\u306e\u5229\u70b9","text":"\u5229\u70b9 \u8a73\u7d30 \u5c06\u6765\u6027 \u975e\u63a8\u5968\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306b\u4f9d\u5b58\u3057\u306a\u3044 \u5b89\u5b9a\u6027 \u975e\u540c\u671f\u7af6\u5408\u554f\u984c\u3092\u89e3\u6c7a \u30b7\u30f3\u30d7\u30eb\u6027 OpenAI Agents SDK\u3092\u76f4\u63a5\u4f7f\u7528 \u62e1\u5f35\u6027 \u30e2\u30b8\u30e5\u30e9\u30fc\u8a2d\u8a08"},{"location":"llm_pipeline_migration_ja/#_4","title":"\ud83d\udd27 \u65b0\u3057\u3044\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"llm_pipeline_migration_ja/#llmpipeline_1","title":"LLMPipeline","text":"<pre><code>from refinire import LLMPipeline, LLMResult\n\n# \u57fa\u672c\u7684\u306a\u4f7f\u7528\npipeline = LLMPipeline(\n    name=\"my_pipeline\",\n    generation_instructions=\"\u3042\u306a\u305f\u306f\u89aa\u5207\u306a\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\nresult = pipeline.run(\"\u3053\u3093\u306b\u3061\u306f\")\nif result.success:\n    print(result.content)\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#genagent","title":"GenAgent","text":"<pre><code>from refinire import GenAgent, Flow, Context\n\n# Flow\u5185\u3067\u306e\u4f7f\u7528\nagent = GenAgent(\n    name=\"assistant\",\n    generation_instructions=\"\u30e6\u30fc\u30b6\u30fc\u3092\u652f\u63f4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\nflow = Flow(steps=agent)\nresult = await flow.run(input_data=\"\u5165\u529b\u30c7\u30fc\u30bf\")\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_5","title":"\ud83d\udcca \u6a5f\u80fd\u6bd4\u8f03","text":"\u6a5f\u80fd AgentPipeline LLMPipeline GenAgent \u751f\u6210 \u2705 \u2705 \u2705 \u8a55\u4fa1 \u2705 \u2705 \u2705 \u30ea\u30c8\u30e9\u30a4 \u2705 \u2705 \u2705 \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb \u2705 \u2705 \u2705 \u69cb\u9020\u5316\u51fa\u529b \u2705 \u2705 \u2705 Flow\u7d71\u5408 \u274c \u274c \u2705 \u975e\u540c\u671f\u5b89\u5168 \u274c \u2705 \u2705 \u5c06\u6765\u6027 \u274c \u2705 \u2705"},{"location":"llm_pipeline_migration_ja/#_6","title":"\ud83d\udd04 \u79fb\u884c\u624b\u9806","text":""},{"location":"llm_pipeline_migration_ja/#1-agentpipelinellmpipeline","title":"1. AgentPipeline\u304b\u3089LLMPipeline\u3078","text":"<p>Before (\u975e\u63a8\u5968): <pre><code>from refinire import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"old_pipeline\",\n    generation_instructions=\"\u6307\u793a\",\n    evaluation_instructions=\"\u8a55\u4fa1\u6307\u793a\",\n    threshold=85,\n    retries=3\n)\n\nresult = pipeline.run(\"\u5165\u529b\")\n</code></pre></p> <p>After (\u63a8\u5968): <pre><code>from refinire import LLMPipeline\n\npipeline = LLMPipeline(\n    name=\"new_pipeline\",\n    generation_instructions=\"\u6307\u793a\",\n    evaluation_instructions=\"\u8a55\u4fa1\u6307\u793a\",\n    threshold=85.0,\n    max_retries=3\n)\n\nresult = pipeline.run(\"\u5165\u529b\")\n</code></pre></p>"},{"location":"llm_pipeline_migration_ja/#2-flowgenagent","title":"2. Flow\u3067\u306eGenAgent\u4f7f\u7528","text":"<p>Before (\u975e\u63a8\u5968): <pre><code>from refinire import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"old_agent\",\n    generation_instructions=\"\u6307\u793a\",\n    evaluation_instructions=\"\u8a55\u4fa1\u6307\u793a\"\n)\n\n# \u975e\u540c\u671f\u554f\u984c\u304c\u767a\u751f\u3059\u308b\u53ef\u80fd\u6027\nresult = pipeline.run(\"\u5165\u529b\")\n</code></pre></p> <p>After (\u63a8\u5968): <pre><code>from refinire import create_simple_gen_agent, Flow\n\nagent = create_simple_gen_agent(\n    name=\"new_agent\",\n    instructions=\"\u6307\u793a\",\n    model=\"gpt-4o-mini\"\n)\n\nflow = Flow(steps=agent)\nresult = await flow.run(input_data=\"\u5165\u529b\")\n</code></pre></p>"},{"location":"llm_pipeline_migration_ja/#3-clarifyagent","title":"3. ClarifyAgent\u306e\u66f4\u65b0","text":"<p>ClarifyAgent\u306f\u5185\u90e8\u7684\u306bLLMPipeline\u3092\u4f7f\u7528\u3059\u308b\u3088\u3046\u66f4\u65b0\u6e08\u307f\u3067\u3059\uff1a</p> <pre><code>from refinire.agents import ClarifyAgent\n\n# API\u306f\u5909\u66f4\u306a\u3057\u3001\u5185\u90e8\u5b9f\u88c5\u306e\u307f\u66f4\u65b0\nagent = ClarifyAgent(\n    name=\"clarify\",\n    instructions=\"\u8981\u4ef6\u3092\u660e\u78ba\u5316\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_7","title":"\ud83d\udee0\ufe0f \u9ad8\u5ea6\u306a\u6a5f\u80fd","text":""},{"location":"llm_pipeline_migration_ja/#_8","title":"\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u6a5f\u80fd","text":"<pre><code>def input_filter(text: str) -&gt; bool:\n    \"\"\"\u5165\u529b\u30d5\u30a3\u30eb\u30bf\u30fc - 1000\u6587\u5b57\u4ee5\u4e0b\u306b\u5236\u9650\"\"\"\n    return len(text) &lt; 1000\n\ndef output_filter(text: str) -&gt; bool:\n    \"\"\"\u51fa\u529b\u30d5\u30a3\u30eb\u30bf\u30fc - \u4e0d\u9069\u5207\u306a\u5185\u5bb9\u3092\u9664\u5916\"\"\"\n    return \"\u4e0d\u9069\u5207\" not in text\n\npipeline = LLMPipeline(\n    name=\"guarded_pipeline\",\n    generation_instructions=\"\u5b89\u5168\u306a\u5fdc\u7b54\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\",\n    input_guardrails=[input_filter],\n    output_guardrails=[output_filter]\n)\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_9","title":"\u69cb\u9020\u5316\u51fa\u529b","text":"<pre><code>from pydantic import BaseModel\n\nclass TaskResult(BaseModel):\n    task: str\n    status: str\n    confidence: float\n\npipeline = LLMPipeline(\n    name=\"structured_pipeline\",\n    generation_instructions=\"\u30bf\u30b9\u30af\u3092\u5206\u6790\u3057\u3066JSON\u3067\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    output_model=TaskResult\n)\n\nresult = pipeline.run(\"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u8a08\u753b\u3092\u4f5c\u6210\")\nif result.success:\n    task_data = result.content  # TaskResult\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_10","title":"\u8a55\u4fa1\u3068\u30ea\u30c8\u30e9\u30a4\u6a5f\u80fd","text":"<pre><code>pipeline = LLMPipeline(\n    name=\"quality_pipeline\",\n    generation_instructions=\"\u9ad8\u54c1\u8cea\u306a\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\",\n    evaluation_instructions=\"\u54c1\u8cea\u30920-100\u3067\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\",\n    threshold=85.0,\n    max_retries=3\n)\n\nresult = pipeline.run(\"\u6280\u8853\u8a18\u4e8b\u3092\u4f5c\u6210\")\nif result.success:\n    print(f\"\u751f\u6210\u7d50\u679c: {result.content}\")\n    print(f\"\u54c1\u8cea\u30b9\u30b3\u30a2: {result.evaluation_score}\")\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_11","title":"\u30c4\u30fc\u30eb\u7d71\u5408","text":"<pre><code>from agents import function_tool\n\n@function_tool\ndef tool1():\n    pass\n\n@function_tool\ndef tool2():\n    pass\n\n# AgentPipeline: generation_tools\u30d1\u30e9\u30e1\u30fc\u30bf\npipeline = AgentPipeline(generation_tools=[tool1, tool2])\n\n# LLMPipeline: tools\u30d1\u30e9\u30e1\u30fc\u30bf\npipeline = LLMPipeline(tools=[tool1, tool2])\n\n# GenAgent: create_simple_gen_agent\u306etools\u30d1\u30e9\u30e1\u30fc\u30bf\nagent = create_simple_gen_agent(tools=[tool1, tool2])\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_12","title":"\ud83c\udfc3\u200d\u2642\ufe0f \u6bb5\u968e\u7684\u79fb\u884c\u6226\u7565","text":""},{"location":"llm_pipeline_migration_ja/#1","title":"\u30d5\u30a7\u30fc\u30ba1: \u65b0\u898f\u958b\u767a\u3067\u306e\u63a1\u7528","text":"<pre><code># \u65b0\u898f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3067\u306f\u63a8\u5968\u30d1\u30bf\u30fc\u30f3\u3092\u4f7f\u7528\nfrom refinire import create_simple_gen_agent, Flow\n\nagent = create_simple_gen_agent(\n    name=\"new_feature\",\n    instructions=\"\u65b0\u6a5f\u80fd\u306e\u30b5\u30dd\u30fc\u30c8\u3092\u63d0\u4f9b\",\n    model=\"gpt-4o-mini\"\n)\n\nflow = Flow(steps=agent)\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#2","title":"\u30d5\u30a7\u30fc\u30ba2: \u65e2\u5b58\u30b3\u30fc\u30c9\u306e\u6bb5\u968e\u7684\u79fb\u884c","text":"<pre><code># 1. \u307e\u305aAgentPipeline\u3092LLMPipeline\u306b\u7f6e\u304d\u63db\u3048\n# Before\nold_pipeline = AgentPipeline(...)\n\n# After\nnew_pipeline = LLMPipeline(\n    name=old_pipeline.name,\n    generation_instructions=old_pipeline.generation_instructions,\n    # \u305d\u306e\u4ed6\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u79fb\u884c\n)\n\n# 2. \u6b21\u306bFlow/GenAgent\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306b\u79fb\u884c\nagent = create_simple_gen_agent(...)\nflow = Flow(steps=agent)\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#3","title":"\u30d5\u30a7\u30fc\u30ba3: \u5b8c\u5168\u79fb\u884c","text":"<pre><code># \u6700\u7d42\u7684\u306b\u306f\u3059\u3079\u3066\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092Flow\u30d9\u30fc\u30b9\u306b\u7d71\u4e00\ncomplex_flow = Flow([\n    (\"preprocess\", FunctionStep(\"prep\", preprocess_func)),\n    (\"generate\", create_simple_gen_agent(...)),\n    (\"postprocess\", FunctionStep(\"post\", postprocess_func))\n])\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_13","title":"\ud83d\udd0d \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"llm_pipeline_migration_ja/#_14","title":"\u3088\u304f\u3042\u308b\u554f\u984c\u3068\u89e3\u6c7a\u7b56","text":""},{"location":"llm_pipeline_migration_ja/#1_1","title":"1. \u975e\u540c\u671f\u7af6\u5408\u30a8\u30e9\u30fc","text":"<pre><code># \u554f\u984c: AgentPipeline\u3092Flow\u5185\u3067\u4f7f\u7528\n# RuntimeError: asyncio.run() cannot be called from a running event loop\n\n# \u89e3\u6c7a\u7b56: GenAgent\u3092\u4f7f\u7528\nagent = create_simple_gen_agent(...)\nflow = Flow(steps=agent)\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#2_1","title":"2. \u8a55\u4fa1\u30b9\u30b3\u30a2\u306e\u53d6\u5f97\u65b9\u6cd5\u306e\u5909\u66f4","text":"<pre><code># Before (AgentPipeline)\nresult = pipeline.run(\"\u5165\u529b\")\nscore = result.evaluation_result.score\n\n# After (LLMPipeline)\nresult = pipeline.run(\"\u5165\u529b\")\nscore = result.evaluation_score\n\n# After (GenAgent + Flow)\nresult = await flow.run(input_data=\"\u5165\u529b\")\nscore = result.shared_state.get(\"agent_name_evaluation\", {}).get(\"score\")\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#3_1","title":"3. \u30c4\u30fc\u30eb\u547c\u3073\u51fa\u3057\u306e\u9055\u3044","text":"<pre><code>from agents import function_tool\n\n@function_tool\ndef tool1():\n    pass\n\n@function_tool\ndef tool2():\n    pass\n\n# AgentPipeline: generation_tools\u30d1\u30e9\u30e1\u30fc\u30bf\npipeline = AgentPipeline(generation_tools=[tool1, tool2])\n\n# LLMPipeline: tools\u30d1\u30e9\u30e1\u30fc\u30bf\npipeline = LLMPipeline(tools=[tool1, tool2])\n\n# GenAgent: create_simple_gen_agent\u306etools\u30d1\u30e9\u30e1\u30fc\u30bf\nagent = create_simple_gen_agent(tools=[tool1, tool2])\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_15","title":"\u2705 \u79fb\u884c\u30c1\u30a7\u30c3\u30af\u30ea\u30b9\u30c8","text":""},{"location":"llm_pipeline_migration_ja/#_16","title":"\u30b3\u30fc\u30c9\u79fb\u884c","text":"<ul> <li>[ ] AgentPipeline\u306eimport\u3092\u524a\u9664</li> <li>[ ] LLMPipeline\u307e\u305f\u306fGenAgent\u306b\u7f6e\u304d\u63db\u3048</li> <li>[ ] \u30d1\u30e9\u30e1\u30fc\u30bf\u540d\u306e\u8abf\u6574\uff08retries \u2192 max_retries\u7b49\uff09</li> <li>[ ] \u623b\u308a\u5024\u306e\u51e6\u7406\u65b9\u6cd5\u3092\u66f4\u65b0</li> <li>[ ] \u30c4\u30fc\u30eb\u5b9a\u7fa9\u306e\u5f62\u5f0f\u3092\u78ba\u8a8d</li> </ul>"},{"location":"llm_pipeline_migration_ja/#_17","title":"\u30c6\u30b9\u30c8\u79fb\u884c","text":"<ul> <li>[ ] AgentPipeline\u306e\u30c6\u30b9\u30c8\u3092\u66f4\u65b0</li> <li>[ ] \u975e\u540c\u671f\u51e6\u7406\u306e\u30c6\u30b9\u30c8\u3092\u8ffd\u52a0</li> <li>[ ] Flow\u7d71\u5408\u306e\u30c6\u30b9\u30c8\u3092\u4f5c\u6210</li> <li>[ ] \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u306e\u30c6\u30b9\u30c8\u3092\u78ba\u8a8d</li> </ul>"},{"location":"llm_pipeline_migration_ja/#_18","title":"\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u66f4\u65b0","text":"<ul> <li>[ ] API\u4f7f\u7528\u4f8b\u3092\u66f4\u65b0</li> <li>[ ] \u79fb\u884c\u524d\u5f8c\u306e\u6bd4\u8f03\u3092\u8a18\u8f09</li> <li>[ ] \u65b0\u6a5f\u80fd\u306e\u8aac\u660e\u3092\u8ffd\u52a0</li> <li>[ ] \u975e\u63a8\u5968\u8b66\u544a\u3092\u8ffd\u52a0</li> </ul>"},{"location":"llm_pipeline_migration_ja/#_19","title":"\ud83c\udfaf \u79fb\u884c\u5f8c\u306e\u30e1\u30ea\u30c3\u30c8","text":""},{"location":"llm_pipeline_migration_ja/#1_2","title":"1. \u5c06\u6765\u6027\u306e\u78ba\u4fdd","text":"<pre><code># v0.1.0\u4ee5\u964d\u3082\u5b89\u5fc3\u3057\u3066\u4f7f\u7528\u53ef\u80fd\npipeline = LLMPipeline(...)  # \u2705 \u7d99\u7d9a\u30b5\u30dd\u30fc\u30c8\n# AgentPipeline(...)         # \u274c v0.1.0\u3067\u524a\u9664\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#2_2","title":"2. \u975e\u540c\u671f\u51e6\u7406\u306e\u5b89\u5168\u6027","text":"<pre><code># Flow\u5185\u3067\u5b89\u5168\u306b\u4f7f\u7528\u53ef\u80fd\nflow = Flow([\n    (\"step1\", gen_agent),\n    (\"step2\", another_agent)\n])\nawait flow.run(input_data=\"\u30c7\u30fc\u30bf\")  # \u2705 \u975e\u540c\u671f\u5b89\u5168\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#3_2","title":"3. \u30e2\u30b8\u30e5\u30e9\u30fc\u8a2d\u8a08","text":"<pre><code># \u518d\u5229\u7528\u53ef\u80fd\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\nvalidation_agent = create_simple_gen_agent(...)\nprocessing_agent = create_simple_gen_agent(...)\n\n# \u7570\u306a\u308b\u30d5\u30ed\u30fc\u3067\u518d\u5229\u7528\nflow1 = Flow([(\"validate\", validation_agent)])\nflow2 = Flow([(\"validate\", validation_agent), (\"process\", processing_agent)])\n</code></pre>"},{"location":"llm_pipeline_migration_ja/#_20","title":"\ud83d\udcda \u53c2\u8003\u8cc7\u6599","text":"<ul> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 - \u65b0\u3057\u3044API\u306e\u8a73\u7d30</li> <li>\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8 - \u63a8\u5968\u30d1\u30bf\u30fc\u30f3\u306e\u4f8b</li> <li>\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3 - Flow\u306e\u8a73\u7d30</li> </ul>"},{"location":"llm_pipeline_migration_ja/#_21","title":"\ud83d\udca1 \u79fb\u884c\u306e\u30d2\u30f3\u30c8","text":"<ol> <li>\u6bb5\u968e\u7684\u30a2\u30d7\u30ed\u30fc\u30c1: \u4e00\u5ea6\u306b\u3059\u3079\u3066\u3092\u5909\u66f4\u305b\u305a\u3001\u6bb5\u968e\u7684\u306b\u79fb\u884c</li> <li>\u30c6\u30b9\u30c8\u99c6\u52d5: \u79fb\u884c\u524d\u306b\u65e2\u5b58\u6a5f\u80fd\u306e\u30c6\u30b9\u30c8\u3092\u5145\u5b9f\u3055\u305b\u308b</li> <li>\u4e26\u884c\u958b\u767a: \u65b0\u6a5f\u80fd\u306f\u63a8\u5968\u30d1\u30bf\u30fc\u30f3\u3067\u3001\u65e2\u5b58\u6a5f\u80fd\u306f\u5f90\u3005\u306b\u79fb\u884c</li> <li>\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u91cd\u8996: \u30c1\u30fc\u30e0\u5185\u3067\u306e\u77e5\u8b58\u5171\u6709\u3092\u91cd\u8996</li> </ol> <p>\u79fb\u884c\u306b\u95a2\u3059\u308b\u8cea\u554f\u3084\u30b5\u30dd\u30fc\u30c8\u304c\u5fc5\u8981\u306a\u5834\u5408\u306f\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306eIssue\u3067\u304a\u6c17\u8efd\u306b\u304a\u554f\u3044\u5408\u308f\u305b\u304f\u3060\u3055\u3044\u3002 </p>"},{"location":"minimal_example/","title":"\u6700\u5c0f\u4f7f\u7528\u4f8b","text":"<p>\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u3001agents-sdk-models\u306e\u6700\u3082\u57fa\u672c\u7684\u306a\u4f7f\u7528\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002</p>"},{"location":"minimal_example/#_2","title":"\u57fa\u672c\u7684\u306a\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"minimal_example/#_3","title":"\u5b9f\u884c\u65b9\u6cd5","text":""},{"location":"minimal_example/#1","title":"1. \u74b0\u5883\u5909\u6570\u306e\u8a2d\u5b9a","text":"<pre><code>export OPENAI_API_KEY=\"your-api-key-here\"\n</code></pre>"},{"location":"minimal_example/#2","title":"2. \u5b9f\u884c","text":"<pre><code>python examples/minimal/minimal_example.py\n</code></pre>"},{"location":"minimal_example/#_4","title":"\u4e3b\u306a\u6a5f\u80fd","text":""},{"location":"minimal_example/#_5","title":"\u30b7\u30f3\u30d7\u30eb\u306a\u30c6\u30ad\u30b9\u30c8\u751f\u6210","text":"<pre><code>from agents_sdk_models import Pipeline, LLM\n\nllm = LLM(provider=\"openai\", model=\"gpt-4o-mini\")\npipeline = Pipeline()\nresult = pipeline.run(\"Hello, world!\", llm=llm)\nprint(result.result)\n</code></pre>"},{"location":"minimal_example/#_6","title":"\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u5909\u6570\u3092\u4f7f\u7528\u3057\u305f\u751f\u6210","text":"<pre><code>from agents_sdk_models import Pipeline, LLM, Context\n\nllm = LLM(provider=\"openai\", model=\"gpt-4o-mini\")\npipeline = Pipeline()\ncontext = Context()\n\ncontext.add_variable(\"user_name\", \"Alice\")\nresult = pipeline.run(\"Hello {user_name}!\", llm=llm, context=context)\nprint(result.result)  # \"Hello Alice! ...\"\n</code></pre>"},{"location":"minimal_example/#doctest","title":"Doctest \u306e\u4f8b","text":"<p>\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u306f\u3001\u30b3\u30fc\u30c9\u4f8b\u3068\u3057\u3066doctest\u3092\u5e83\u304f\u6d3b\u7528\u3057\u3066\u3044\u307e\u3059\u3002\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001\u95a2\u6570\u306edocstring\u306b\u5b9f\u884c\u53ef\u80fd\u306a\u4f8b\u3092\u542b\u3081\u3066\u3044\u307e\u3059\uff1a</p> <pre><code>def simple_generation(prompt: str, api_key: Optional[str] = None) -&gt; str:\n    \"\"\"\n    Perform simple text generation\n\n    Examples:\n        &gt;&gt;&gt; result = simple_generation(\"Say hello\")  # doctest: +SKIP\n        &gt;&gt;&gt; isinstance(result, str)  # doctest: +SKIP\n        True\n    \"\"\"\n    # ... implementation\n</code></pre> <p><code># doctest: +SKIP</code> \u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3001API\u30ad\u30fc\u304c\u5fc5\u8981\u306a\u30c6\u30b9\u30c8\u3092\u5b9f\u969b\u306eCI\u5b9f\u884c\u6642\u306b\u30b9\u30ad\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"minimal_example/#_7","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ul> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u3067\u8a73\u7d30\u306a\u6a5f\u80fd\u3092\u78ba\u8a8d</li> <li>\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u5fdc\u7528\u7684\u306a\u4f7f\u7528\u65b9\u6cd5\u3092\u5b66\u7fd2 </li> </ul>"},{"location":"new_flow_features/","title":"\ud83d\ude80 \u65b0\u3057\u3044Flow\u6a5f\u80fd\u5b8c\u5168\u30ac\u30a4\u30c9","text":"<p>\u672c\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f\u3001agents-sdk-models v0.0.8\u4ee5\u964d\u3067\u8ffd\u52a0\u3055\u308c\u305f\u65b0\u3057\u3044Flow\u4f5c\u6210\u6a5f\u80fd\u306b\u3064\u3044\u3066\u8a73\u3057\u304f\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"new_flow_features/#_1","title":"\u6982\u8981","text":"<p>\u5f93\u6765\u306eFlow\u306f\u8f9e\u66f8\u5f62\u5f0f\u3067\u306e\u30b9\u30c6\u30c3\u30d7\u5b9a\u7fa9\u304c\u5fc5\u8981\u3067\u3057\u305f\u304c\u3001\u65b0\u3057\u3044Flow\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u306f3\u3064\u306e\u65b9\u6cd5\u3067\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u4f5c\u6210\u3067\u304d\u307e\u3059\uff1a</p> <ol> <li>\u5358\u4e00\u30b9\u30c6\u30c3\u30d7 - <code>Flow(steps=single_step)</code></li> <li>\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30b9\u30c6\u30c3\u30d7 - <code>Flow(steps=[step1, step2, step3])</code> </li> <li>\u5f93\u6765\u65b9\u5f0f - <code>Flow(start=\"step1\", steps={\"step1\": step1, ...})</code></li> </ol>"},{"location":"new_flow_features/#flow_1","title":"\ud83c\udfaf \u6700\u3082\u30b7\u30f3\u30d7\u30eb\uff1a\u5358\u4e00\u30b9\u30c6\u30c3\u30d7Flow","text":"<pre><code>from agents_sdk_models import create_simple_gen_agent, Flow\n\n# GenAgent\u3092\u4f5c\u6210\ngen_agent = create_simple_gen_agent(\n    name=\"assistant\",\n    instructions=\"\u3042\u306a\u305f\u306f\u89aa\u5207\u306a\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# Flow\u3092\u4f5c\u6210\uff08\u305f\u3063\u305f1\u884c\uff01\uff09\nflow = Flow(steps=gen_agent)\n\n# \u5b9f\u884c\nresult = await flow.run(input_data=\"\u3053\u3093\u306b\u3061\u306f\")\nprint(result.shared_state[\"assistant_result\"])\n</code></pre>"},{"location":"new_flow_features/#flow_2","title":"\ud83d\udd17 \u81ea\u52d5\u63a5\u7d9a\uff1a\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30ebFlow","text":"<pre><code>from agents_sdk_models import create_simple_gen_agent, Flow, DebugStep\n\n# \u8907\u6570\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u5b9a\u7fa9\nidea_gen = create_simple_gen_agent(\"idea\", \"\u30a2\u30a4\u30c7\u30a2\u3092\u751f\u6210\", \"gpt-4o-mini\")\nwriter = create_simple_gen_agent(\"writer\", \"\u8a18\u4e8b\u3092\u57f7\u7b46\", \"gpt-4o\")\nreviewer = create_simple_gen_agent(\"reviewer\", \"\u8a18\u4e8b\u3092\u30ec\u30d3\u30e5\u30fc\", \"claude-3-5-sonnet-latest\")\ndebug = DebugStep(\"debug\", \"\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u5b8c\u4e86\")\n\n# \u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30ebFlow\uff08\u81ea\u52d5\u63a5\u7d9a\uff01\uff09\nflow = Flow(steps=[idea_gen, writer, reviewer, debug])\n\n# \u5b9f\u884c\uff08idea_gen \u2192 writer \u2192 reviewer \u2192 debug \u306e\u9806\u3067\u81ea\u52d5\u5b9f\u884c\uff09\nresult = await flow.run(input_data=\"AI\u6280\u8853\u306b\u3064\u3044\u3066\")\n\n# \u5404\u30b9\u30c6\u30c3\u30d7\u306e\u7d50\u679c\u3092\u78ba\u8a8d\nprint(\"\u30a2\u30a4\u30c7\u30a2:\", result.shared_state[\"idea_result\"])\nprint(\"\u8a18\u4e8b:\", result.shared_state[\"writer_result\"])  \nprint(\"\u30ec\u30d3\u30e5\u30fc:\", result.shared_state[\"reviewer_result\"])\n</code></pre>"},{"location":"new_flow_features/#genagent","title":"\u2699\ufe0f \u9ad8\u5ea6\u306a\u4f8b\uff1a\u8a55\u4fa1\u4ed8\u304dGenAgent","text":"<pre><code>from agents_sdk_models import create_evaluated_gen_agent, Flow\n\n# \u8a55\u4fa1\u6a5f\u80fd\u4ed8\u304dGenAgent\nsmart_agent = create_evaluated_gen_agent(\n    name=\"smart_writer\",\n    generation_instructions=\"\u6280\u8853\u8a18\u4e8b\u3092\u57f7\u7b46\u3057\u3066\u304f\u3060\u3055\u3044\",\n    evaluation_instructions=\"\u8a18\u4e8b\u306e\u8cea\u3092100\u70b9\u6e80\u70b9\u3067\u8a55\u4fa1\u3057\u3001\u6539\u5584\u70b9\u3092\u6307\u6458\u3057\u3066\u304f\u3060\u3055\u3044\",\n    model=\"gpt-4o\",\n    threshold=80,  # 80\u70b9\u672a\u6e80\u306a\u3089\u81ea\u52d5\u30ea\u30c8\u30e9\u30a4\n    retries=2\n)\n\n# \u30b7\u30f3\u30d7\u30eb\u306aFlow\nflow = Flow(steps=smart_agent)\nresult = await flow.run(input_data=\"\u6a5f\u68b0\u5b66\u7fd2\u306e\u57fa\u790e\u306b\u3064\u3044\u3066\")\n\n# \u8a55\u4fa1\u7d50\u679c\u3082\u542b\u3081\u3066\u8868\u793a\nevaluation = result.shared_state.get(\"smart_writer_evaluation\")\nif evaluation:\n    print(f\"\u8a55\u4fa1\u70b9\u6570: {evaluation.get('score', 'N/A')}\")\n    print(f\"\u30b3\u30e1\u30f3\u30c8: {evaluation.get('comment', 'N/A')}\")\n</code></pre>"},{"location":"new_flow_features/#_2","title":"\ud83d\udd27 \u30c4\u30fc\u30eb\u9023\u643a","text":"<pre><code>from agents import function_tool\nfrom agents_sdk_models import create_simple_gen_agent, Flow\n\n@function_tool\ndef get_weather(location: str) -&gt; str:\n    \"\"\"\u6307\u5b9a\u5730\u57df\u306e\u5929\u6c17\u60c5\u5831\u3092\u53d6\u5f97\"\"\"\n    return f\"Weather in {location}: Sunny, 25\u00b0C\"\n\n@function_tool  \ndef get_news(topic: str) -&gt; str:\n    \"\"\"\u6307\u5b9a\u30c8\u30d4\u30c3\u30af\u306e\u30cb\u30e5\u30fc\u30b9\u3092\u53d6\u5f97\"\"\"\n    return f\"Latest news about {topic}: AI breakthrough announced\"\n\n# \u30c4\u30fc\u30eb\u4ed8\u304dGenAgent\nweather_agent = create_simple_gen_agent(\n    name=\"weather_bot\",\n    instructions=\"\u5929\u6c17\u3084\u30cb\u30e5\u30fc\u30b9\u306e\u8cea\u554f\u306b\u7b54\u3048\u3066\u304f\u3060\u3055\u3044\u3002\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u30c4\u30fc\u30eb\u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    generation_tools=[get_weather, get_news]\n)\n\nflow = Flow(steps=weather_agent)\nresult = await flow.run(input_data=\"\u6771\u4eac\u306e\u5929\u6c17\u3068AI\u306e\u30cb\u30e5\u30fc\u30b9\u3092\u6559\u3048\u3066\")\n</code></pre>"},{"location":"new_flow_features/#_3","title":"\ud83c\udf1f \u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u5354\u8abf","text":"<pre><code>from agents_sdk_models import create_simple_gen_agent, Flow\n\n# \u5c02\u9580\u5206\u91ce\u306e\u7570\u306a\u308b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\nresearcher = create_simple_gen_agent(\n    name=\"researcher\", \n    instructions=\"\u6280\u8853\u8abf\u67fb\u3092\u884c\u3044\u3001\u6b63\u78ba\u306a\u60c5\u5831\u3092\u63d0\u4f9b\u3057\u307e\u3059\",\n    model=\"gpt-4o\"\n)\n\ntranslator = create_simple_gen_agent(\n    name=\"translator\",\n    instructions=\"\u6280\u8853\u6587\u66f8\u3092\u5206\u304b\u308a\u3084\u3059\u3044\u65e5\u672c\u8a9e\u306b\u7ffb\u8a33\u3057\u307e\u3059\", \n    model=\"gpt-4o\"\n)\n\nsummarizer = create_simple_gen_agent(\n    name=\"summarizer\",\n    instructions=\"\u9577\u3044\u6587\u7ae0\u3092\u8981\u70b9\u3092\u62bc\u3055\u3048\u3066\u8981\u7d04\u3057\u307e\u3059\",\n    model=\"claude-3-5-sonnet-latest\"\n)\n\n# \u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u5354\u8abfFlow\nflow = Flow(steps=[researcher, translator, summarizer])\nresult = await flow.run(input_data=\"\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u306e\u6700\u65b0\u52d5\u5411\")\n\nprint(\"\u8abf\u67fb\u7d50\u679c:\", result.shared_state[\"researcher_result\"])\nprint(\"\u7ffb\u8a33\u7d50\u679c:\", result.shared_state[\"translator_result\"]) \nprint(\"\u8981\u7d04\u7d50\u679c:\", result.shared_state[\"summarizer_result\"])\n</code></pre>"},{"location":"new_flow_features/#_4","title":"\ud83d\udd00 \u6761\u4ef6\u5206\u5c90\uff08\u5f93\u6765\u65b9\u5f0f\uff09","text":"<p>\u8907\u96d1\u306a\u6761\u4ef6\u5206\u5c90\u304c\u5fc5\u8981\u306a\u5834\u5408\u306f\u5f93\u6765\u306e\u8f9e\u66f8\u65b9\u5f0f\u3092\u4f7f\u7528\uff1a</p> <pre><code>from agents_sdk_models import Flow, ConditionStep, create_simple_gen_agent\n\ndef check_urgency(ctx):\n    user_input = ctx.last_user_input or \"\"\n    return \"\u7dca\u6025\" in user_input or \"\u6025\u304e\" in user_input\n\nurgent_agent = create_simple_gen_agent(\"urgent\", \"\u7dca\u6025\u5bfe\u5fdc\u3057\u307e\u3059\", \"gpt-4o\")\nnormal_agent = create_simple_gen_agent(\"normal\", \"\u901a\u5e38\u5bfe\u5fdc\u3057\u307e\u3059\", \"gpt-4o-mini\")\n\n# \u6761\u4ef6\u5206\u5c90Flow\nflow = Flow(\n    start=\"check\",\n    steps={\n        \"check\": ConditionStep(\"check\", check_urgency, \"urgent\", \"normal\"),\n        \"urgent\": urgent_agent,\n        \"normal\": normal_agent\n    }\n)\n\nresult = await flow.run(input_data=\"\u7dca\u6025\u306b\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\")\n</code></pre>"},{"location":"new_flow_features/#_5","title":"\ud83d\udca1 \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"new_flow_features/#1","title":"1. \u30b9\u30c6\u30c3\u30d7\u547d\u540d\u898f\u5247","text":"<pre><code># Good: \u5206\u304b\u308a\u3084\u3059\u3044\u540d\u524d\ngen_agent = create_simple_gen_agent(\"content_writer\", \"\u8a18\u4e8b\u57f7\u7b46\", \"gpt-4o\")\n\n# Bad: \u610f\u5473\u4e0d\u660e\u306a\u540d\u524d  \ngen_agent = create_simple_gen_agent(\"step1\", \"\u8a18\u4e8b\u57f7\u7b46\", \"gpt-4o\")\n</code></pre>"},{"location":"new_flow_features/#2","title":"2. \u30e2\u30c7\u30eb\u306e\u4f7f\u3044\u5206\u3051","text":"<pre><code># \u8907\u96d1\u306a\u30bf\u30b9\u30af: \u9ad8\u6027\u80fd\u30e2\u30c7\u30eb\ncomplex_agent = create_simple_gen_agent(\"analyzer\", \"\u8907\u96d1\u306a\u5206\u6790\", \"gpt-4o\")\n\n# \u30b7\u30f3\u30d7\u30eb\u306a\u30bf\u30b9\u30af: \u8efd\u91cf\u30e2\u30c7\u30eb\nsimple_agent = create_simple_gen_agent(\"formatter\", \"\u30c6\u30ad\u30b9\u30c8\u6574\u5f62\", \"gpt-4o-mini\")\n</code></pre>"},{"location":"new_flow_features/#3","title":"3. \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0","text":"<pre><code>try:\n    result = await flow.run(input_data=\"\u5165\u529b\u30c7\u30fc\u30bf\")\n    if \"error\" in result.shared_state:\n        print(\"\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u307e\u3057\u305f:\", result.shared_state[\"error\"])\nexcept Exception as e:\n    print(\"\u5b9f\u884c\u30a8\u30e9\u30fc:\", str(e))\n</code></pre>"},{"location":"new_flow_features/#_6","title":"\ud83d\udcca \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6bd4\u8f03","text":"\u65b9\u5f0f \u30b3\u30fc\u30c9\u884c\u6570 \u8a2d\u5b9a\u306e\u8907\u96d1\u3055 \u5b66\u7fd2\u30b3\u30b9\u30c8 \u65e7AgentPipeline 10-15\u884c \u4e2d \u4e2d \u65b0Flow(\u5358\u4e00) 3\u884c \u4f4e \u4f4e \u65b0Flow(\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb) 5-8\u884c \u4f4e \u4f4e \u65b0Flow(\u5f93\u6765) 15-20\u884c \u9ad8 \u9ad8"},{"location":"new_flow_features/#_7","title":"\ud83d\ude80 \u79fb\u884c\u30ac\u30a4\u30c9","text":""},{"location":"new_flow_features/#agentpipeline","title":"AgentPipeline\u304b\u3089\u306e\u79fb\u884c","text":"<pre><code># \u65e7: AgentPipeline\npipeline = AgentPipeline(\n    name=\"example\",\n    generation_instructions=\"\u6587\u7ae0\u3092\u751f\u6210\",\n    evaluation_instructions=\"\u8a55\u4fa1\u3057\u307e\u3059\", \n    model=\"gpt-4o-mini\",\n    threshold=70\n)\nresult = pipeline.run(\"\u5165\u529b\")\n\n# \u65b0: GenAgent + Flow\ngen_agent = create_evaluated_gen_agent(\n    name=\"example\",\n    generation_instructions=\"\u6587\u7ae0\u3092\u751f\u6210\",\n    evaluation_instructions=\"\u8a55\u4fa1\u3057\u307e\u3059\",\n    model=\"gpt-4o-mini\", \n    threshold=70\n)\nflow = Flow(steps=gen_agent)\nresult = await flow.run(input_data=\"\u5165\u529b\")\n</code></pre>"},{"location":"new_flow_features/#_8","title":"\ud83d\udd17 \u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8</li> <li>\u5fdc\u7528\u4f8b </li> <li>Flow/Step API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</li> <li>API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 </li> </ul>"},{"location":"pipeline_examples/","title":"AgentPipeline\u6d3b\u7528\u4e8b\u4f8b\u96c6","text":"<p>\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f\u3001<code>AgentPipeline</code>\u30af\u30e9\u30b9\u3092\u6d3b\u7528\u3057\u305f\u5404\u7a2e\u4e8b\u4f8b\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002</p>"},{"location":"pipeline_examples/#1","title":"1. \u30b7\u30f3\u30d7\u30eb\u306a\u751f\u6210\uff08\u8a55\u4fa1\u306a\u3057\uff09","text":"<ul> <li>\u30d5\u30a1\u30a4\u30eb: <code>examples/pipeline_simple_generation.py</code></li> <li>\u6982\u8981: \u30e6\u30fc\u30b6\u30fc\u5165\u529b\u306b\u57fa\u3065\u304d\u3001\u8a55\u4fa1\u306a\u3057\u3067\u76f4\u63a5\u751f\u6210\u7d50\u679c\u3092\u8fd4\u3059\u6700\u5c0f\u69cb\u6210\u306e\u4f8b\u3002</li> </ul>"},{"location":"pipeline_examples/#_1","title":"\u30b3\u30fc\u30c9\u4f8b","text":"<pre><code>pipeline = AgentPipeline(\n    name=\"simple_generator\",\n    generation_instructions=\"\"\"\n    You are a helpful assistant that generates creative stories.\n    \u3042\u306a\u305f\u306f\u5275\u9020\u7684\u306a\u7269\u8a9e\u3092\u751f\u6210\u3059\u308b\u5f79\u7acb\u3064\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\n    Please generate a short story based on the user's input.\n    \u30e6\u30fc\u30b6\u30fc\u306e\u5165\u529b\u306b\u57fa\u3065\u3044\u3066\u77ed\u3044\u7269\u8a9e\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    evaluation_instructions=None,\n    model=\"gpt-3.5-turbo\"\n)\nresult = pipeline.run(\"A story about a robot learning to paint\")\n</code></pre>"},{"location":"pipeline_examples/#2","title":"2. \u751f\u6210\u7269\u306e\u8a55\u4fa1\u4ed8\u304d\u751f\u6210","text":"<ul> <li>\u30d5\u30a1\u30a4\u30eb: <code>examples/pipeline_with_evaluation.py</code></li> <li>\u6982\u8981: \u751f\u6210\u7269\u306b\u5bfe\u3057\u3066\u81ea\u52d5\u8a55\u4fa1\u3092\u884c\u3044\u3001\u95be\u5024\u3092\u6e80\u305f\u3057\u305f\u5834\u5408\u306e\u307f\u7d50\u679c\u3092\u8fd4\u3059\u4f8b\u3002</li> </ul>"},{"location":"pipeline_examples/#_2","title":"\u30b3\u30fc\u30c9\u4f8b","text":"<pre><code>pipeline = AgentPipeline(\n    name=\"evaluated_generator\",\n    generation_instructions=\"...\",\n    evaluation_instructions=\"...\",\n    model=\"gpt-3.5-turbo\",\n    threshold=70\n)\nresult = pipeline.run(\"A story about a robot learning to paint\")\n</code></pre>"},{"location":"pipeline_examples/#3","title":"3. \u30c4\u30fc\u30eb\u9023\u643a\u306b\u3088\u308b\u751f\u6210","text":"<ul> <li>\u30d5\u30a1\u30a4\u30eb: <code>examples/pipeline_with_tools.py</code></li> <li>\u6982\u8981: <code>@function_tool</code>\u3067\u5b9a\u7fa9\u3057\u305fPython\u95a2\u6570\u3092\u30c4\u30fc\u30eb\u3068\u3057\u3066\u7d44\u307f\u8fbc\u307f\u3001\u5916\u90e8\u60c5\u5831\u53d6\u5f97\u3084\u8a08\u7b97\u306a\u3069\u3092\u7d44\u307f\u5408\u308f\u305b\u305f\u751f\u6210\u3092\u884c\u3046\u4f8b\u3002</li> </ul>"},{"location":"pipeline_examples/#_3","title":"\u30b3\u30fc\u30c9\u4f8b","text":"<pre><code>from agents import function_tool\n\n@function_tool\ndef search_web(query: str) -&gt; str:\n    ...\n\n@function_tool\ndef get_weather(location: str) -&gt; str:\n    ...\n\npipeline = AgentPipeline(\n    name=\"tooled_generator\",\n    generation_instructions=\"...\",\n    evaluation_instructions=None,\n    model=\"gpt-3.5-turbo\",\n    generation_tools=[search_web, get_weather]\n)\nresult = pipeline.run(\"What's the weather like in Tokyo?\")\n</code></pre>"},{"location":"pipeline_examples/#4","title":"4. \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff08\u5165\u529b\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff09\u306b\u3088\u308b\u5165\u529b\u5236\u5fa1","text":"<ul> <li>\u30d5\u30a1\u30a4\u30eb: <code>examples/pipeline_with_guardrails.py</code></li> <li>\u6982\u8981: \u5165\u529b\u5185\u5bb9\u306b\u5bfe\u3057\u3066\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff08\u4f8b: \u6570\u5b66\u306e\u5bbf\u984c\u4f9d\u983c\u306e\u691c\u51fa\uff09\u3092\u8a2d\u3051\u3001\u4e0d\u9069\u5207\u306a\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u30d6\u30ed\u30c3\u30af\u3059\u308b\u4f8b\u3002</li> </ul>"},{"location":"pipeline_examples/#_4","title":"\u30b3\u30fc\u30c9\u4f8b","text":"<pre><code>from agents import input_guardrail, GuardrailFunctionOutput, InputGuardrailTripwireTriggered\n\n@input_guardrail\nasync def math_guardrail(ctx, agent, input):\n    ...\n\npipeline = AgentPipeline(\n    name=\"guardrail_pipeline\",\n    generation_instructions=\"...\",\n    evaluation_instructions=None,\n    model=\"gpt-4o\",\n    input_guardrails=[math_guardrail]\n)\n\ntry:\n    result = pipeline.run(\"Can you help me solve for x: 2x + 3 = 11?\")\nexcept InputGuardrailTripwireTriggered:\n    print(\"[Guardrail Triggered] Math homework detected. Request blocked.\")\n</code></pre>"},{"location":"pipeline_examples/#5","title":"5. \u30ea\u30c8\u30e9\u30a4\u6642\u306e\u30b3\u30e1\u30f3\u30c8\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af","text":"<ul> <li>\u6a5f\u80fd: \u524d\u56de\u306e\u8a55\u4fa1\u30b3\u30e1\u30f3\u30c8\u3092\u6307\u5b9a\u3057\u305f\u91cd\u5927\u5ea6\u30ec\u30d9\u30eb\u3067\u751f\u6210\u30d7\u30ed\u30f3\u30d7\u30c8\u306b\u4ed8\u4e0e\u3057\u3001\u6539\u5584\u3092\u4fc3\u3059</li> <li>\u30d1\u30e9\u30e1\u30fc\u30bf:</li> <li><code>retry_comment_importance</code>: <code>serious</code>, <code>normal</code>, <code>minor</code> \u306e\u3044\u305a\u308c\u304b\u3092\u6307\u5b9a\u53ef\u80fd</li> </ul>"},{"location":"pipeline_examples/#_5","title":"\u30b3\u30fc\u30c9\u4f8b","text":"<pre><code>from agents_sdk_models.pipeline import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"comment_retry\",\n    generation_instructions=\"\u751f\u6210\u30d7\u30ed\u30f3\u30d7\u30c8\",\n    evaluation_instructions=\"\u8a55\u4fa1\u30d7\u30ed\u30f3\u30d7\u30c8\",\n    model=\"gpt-4o-mini\",\n    threshold=80,\n    retries=2,\n    retry_comment_importance=[\"serious\", \"normal\"]\n)\nresult = pipeline.run(\"\u8a55\u4fa1\u5bfe\u8c61\u306e\u30c6\u30ad\u30b9\u30c8\")\nprint(result)\n</code></pre>"},{"location":"pipeline_examples/#_6","title":"\u53c2\u8003","text":"<ul> <li>\u5404\u30b5\u30f3\u30d7\u30eb\u306f <code>examples/</code> \u30d5\u30a9\u30eb\u30c0\u306b\u683c\u7d0d\u3055\u308c\u3066\u3044\u307e\u3059\u3002</li> <li>\u8a73\u7d30\u306a\u4f7f\u3044\u65b9\u3084\u5fdc\u7528\u4f8b\u306fREADME\u3082\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 </li> </ul>"},{"location":"pipleine_clerify/","title":"ClearifyPipeline\u306b\u3064\u3044\u3066","text":"<p>ClearifyPipeline\u306f\u8981\u4ef6\u3092\u660e\u78ba\u5316\u3059\u308b\u306e\u306b\u5fc5\u8981\u306aAgentPipeline\u306e\u30b5\u30d6\u30af\u30e9\u30b9\u3067\u3059\u3002\u6b21\u306e\u30b9\u30c6\u30c3\u30d7\u3078\u8981\u4ef6\u304c\u6e80\u305f\u3055\u308c\u3066\u3044\u308b\u304b\u3092\u78ba\u8a8d\u3055\u308c\u308b\u307e\u3067\u3001\u7e70\u308a\u8fd4\u3057\u8cea\u554f\u3092\u884c\u3044\u3001\u30e6\u30fc\u30b6\u30fc\u306b\u78ba\u8a8d\u3092\u884c\u3044\u307e\u3059\u3002</p> <pre><code>class ReportRequirements(BaseModel):\n    event: str  # \u30a4\u30d9\u30f3\u30c8\u540d\n    date: str   #\u3000\u65e5\u4ed8\n    place: str  # \u5834\u6240\n    topics: List[str] # \u30c8\u30d4\u30c3\u30af\n    interested: str # \u5370\u8c61\u306b\u6b8b\u308b\u3053\u3068\n    expression: str # \u611f\u60f3\n\npipeline = ClearifyPipeline(\n    name=\"clearify_report_requrements\",\n    generation_instructions=\"\"\"\n    \u3042\u306a\u305f\u306f\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3059\u308b\u6e96\u5099\u3092\u884c\u3044\u307e\u3059\u3002\n    \u30ec\u30dd\u30fc\u30c8\u306b\u8a18\u8f09\u3059\u308b\u8981\u4ef6\u3092\u6574\u7406\u3057\u3001\u9b45\u529b\u7684\u306a\u30ec\u30dd\u30fc\u30c8\u3068\u306a\u308b\u3088\u3046\u805e\u304d\u624b\u3068\u3057\u3066\u3001\u30e6\u30fc\u30b6\u30fc\u3068\u5bfe\u8a71\u3057\u8981\u4ef6\u3092\u5f15\u304d\u51fa\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    \u8981\u4ef6\u304c\u660e\u78ba\u3067\u306a\u304b\u3063\u305f\u308a\u3001\u9b45\u529b\u7684\u51fa\u306a\u3044\u5834\u5408\u306f\u3001\u3055\u3089\u306b\u8cea\u554f\u3092\u304f\u308a\u304b\u3048\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    \u5fc5\u8981\u306a\u9805\u76ee\u3068\u3001\u305d\u308c\u3092\u9b45\u529b\u7684\u306b\u3059\u308b\u30dd\u30a4\u30f3\u30c8\u3092\u4f1d\u3048\u305f\u308a\u3001\u30b5\u30f3\u30d7\u30eb\u3092\u63d0\u793a\u3057\u3066\u3001\u30e6\u30fc\u30b6\u30fc\u306e\u4f53\u9a13\u304b\u3089\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3059\u308b\u305f\u3081\u306e\u3001\u51fa\u6765\u308b\u3060\u3051\u8a73\u7d30\u306a\u6750\u6599\u3092\u96c6\u3081\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    output_data = ReportRequirements,\n    clerify_max_turns = 20,\n    evaluation_instructions=None,\n    model=\"gpt-4o\"\n)\nresult = pipeline.run(\"I would like to make a xxxx\")\n</code></pre> <p>ClearifyPipeline\u306f\u30e6\u30fc\u30b6\u30fc\u304b\u3089\u306e\u8981\u671b\u3055\u308c\u305f\u8981\u4ef6\u306b\u52a0\u3048\u3066\u3001pydantic basemodel\u3067\u51fa\u529b\u578b\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u30e6\u30fc\u30b6\u30fc\u306e\u51fa\u529b\u578b\u3092\u30e9\u30c3\u30d7\u3057\u3001\u6b21\u306e\u3088\u3046\u306a\u30af\u30e9\u30b9\u3068\u3057\u3066LLM\u306b\u51fa\u529b\u3055\u305b\u308b\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code>class Clearify[T](BaseModel):\n    clearity: bool  # True\u306a\u3089\u8981\u4ef6\u304c\u78ba\u5b9a\n    user_requirement: T # Option True\u6642\u306b\u767a\u751f\n</code></pre> <p>\u30e6\u30fc\u30b6\u30fc\u304b\u3089\u578b\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u306f\u6587\u5b57\u5217\u3068\u3057\u3066\u8981\u4ef6\u3092\u53d6\u5f97\u3057\u3001\u8981\u4ef6\u3092\u8fd4\u5374\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code>class Clearify(BaseModel):\n    clearity: bool  # True\u306a\u3089\u8981\u4ef6\u304c\u78ba\u5b9a\n    user_requirement: str # Option True\u6642\u306b\u767a\u751f\n</code></pre>"},{"location":"requirements/","title":"\u8981\u4ef6\u5b9a\u7fa9\u66f8","text":""},{"location":"requirements/#_2","title":"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u76ee\u7684\u30fb\u80cc\u666f","text":"<p>OpenAI Agents SDK\u3092\u6d3b\u7528\u3057\u3001\u751f\u6210\u30fb\u8a55\u4fa1\u30fb\u30c4\u30fc\u30eb\u9023\u643a\u30fb\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u306a\u3069\u306eAI\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u7c21\u5358\u306b\u69cb\u7bc9\u30fb\u62e1\u5f35\u3067\u304d\u308bPython\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u63d0\u4f9b\u3059\u308b\u3002</p>"},{"location":"requirements/#_3","title":"\u5229\u7528\u8005\u3068\u56f0\u308a\u3054\u3068","text":"\u5229\u7528\u8005\u306e\u7a2e\u985e \u30b4\u30fc\u30eb \u5236\u7d04 \u56f0\u308a\u3054\u3068 AI\u958b\u767a\u8005 LLM\u3092\u6d3b\u7528\u3057\u305f\u591a\u69d8\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u7d20\u65e9\u304f\u69cb\u7bc9 Python, SDK\u4f9d\u5b58 \u30b5\u30f3\u30d7\u30eb\u3084\u8a2d\u8a08\u4f8b\u304c\u5c11\u306a\u3044\u3001\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3084\u30c4\u30fc\u30eb\u9023\u643a\u306e\u5b9f\u88c5\u304c\u7169\u96d1 \u7814\u7a76\u8005 \u8a55\u4fa1\u3084\u5b89\u5168\u6027\u3092\u62c5\u4fdd\u3057\u305fAI\u5b9f\u9a13 \u67d4\u8edf\u306a\u30ab\u30b9\u30bf\u30de\u30a4\u30ba \u8a55\u4fa1\u30fb\u5b89\u5168\u6027\u306e\u4ed5\u7d44\u307f\u304c\u4e0d\u8db3"},{"location":"requirements/#_4","title":"\u63a1\u7528\u3059\u308b\u6280\u8853\u30b9\u30bf\u30c3\u30af","text":"\u6280\u8853 \u30d0\u30fc\u30b8\u30e7\u30f3/\u5099\u8003 Python 3.10\u4ee5\u4e0a OpenAI Agents SDK \u6700\u65b0 pydantic 2.x"},{"location":"requirements/#_5","title":"\u6a5f\u80fd\uff08\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\uff09\u4e00\u89a7","text":"\u56f0\u308a\u3054\u3068 \u6a5f\u80fd\uff08\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\uff09 \u6a5f\u80fd\u306e\u30a4\u30e1\u30fc\u30b8 \u30b5\u30f3\u30d7\u30eb\u3084\u8a2d\u8a08\u4f8b\u304c\u5c11\u306a\u3044 AgentPipeline\u306b\u3088\u308b\u751f\u6210\u30fb\u8a55\u4fa1\u30fb\u30c4\u30fc\u30eb\u9023\u643a\u30fb\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u306e\u7d71\u5408 \u30b3\u30fc\u30c9\u4f8b\u30fbexamples/pipeline_*.py \u8a55\u4fa1\u30fb\u5b89\u5168\u6027\u306e\u4ed5\u7d44\u307f\u304c\u4e0d\u8db3 \u5165\u529b\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u30fb\u81ea\u52d5\u8a55\u4fa1 \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb/\u8a55\u4fa1\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u306e\u6d3b\u7528"},{"location":"requirements/#_6","title":"\u53c2\u8003","text":"<ul> <li>\u8a73\u7d30\u306a\u4e8b\u4f8b\u306f docs/pipeline_examples.md \u3092\u53c2\u7167\u3002 </li> </ul>"},{"location":"trace_search_api/","title":"\u30c8\u30ec\u30fc\u30b9\u691c\u7d22API","text":""},{"location":"trace_search_api/#_1","title":"\u6982\u8981","text":"<p>Agents SDK Models\u306e\u30c8\u30ec\u30fc\u30b9\u691c\u7d22\u6a5f\u80fd\u306f\u3001\u30d5\u30ed\u30fc\u540d\u3084\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u3067\u30c8\u30ec\u30fc\u30b9\u3092\u691c\u7d22\u3057\u3001\u5b9f\u884c\u5c65\u6b74\u3092\u8ffd\u8de1\u30fb\u5206\u6790\u3059\u308b\u305f\u3081\u306e\u5305\u62ec\u7684\u306aAPI\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"trace_search_api/#_2","title":"\u4e3b\u8981\u30af\u30e9\u30b9","text":""},{"location":"trace_search_api/#traceregistry","title":"TraceRegistry","text":"<p>\u30c8\u30ec\u30fc\u30b9\u306e\u4fdd\u5b58\u30fb\u691c\u7d22\u3092\u7ba1\u7406\u3059\u308b\u30e1\u30a4\u30f3\u30af\u30e9\u30b9\u3067\u3059\u3002</p> \u30e1\u30bd\u30c3\u30c9 \u8aac\u660e \u623b\u308a\u5024 <code>register_trace()</code> \u65b0\u3057\u3044\u30c8\u30ec\u30fc\u30b9\u3092\u767b\u9332 None <code>search_by_flow_name()</code> \u30d5\u30ed\u30fc\u540d\u3067\u30c8\u30ec\u30fc\u30b9\u3092\u691c\u7d22 List[TraceMetadata] <code>search_by_agent_name()</code> \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u3067\u30c8\u30ec\u30fc\u30b9\u3092\u691c\u7d22 List[TraceMetadata] <code>search_by_tags()</code> \u30bf\u30b0\u3067\u30c8\u30ec\u30fc\u30b9\u3092\u691c\u7d22 List[TraceMetadata] <code>search_by_status()</code> \u30b9\u30c6\u30fc\u30bf\u30b9\u3067\u30c8\u30ec\u30fc\u30b9\u3092\u691c\u7d22 List[TraceMetadata] <code>search_by_time_range()</code> \u6642\u9593\u7bc4\u56f2\u3067\u30c8\u30ec\u30fc\u30b9\u3092\u691c\u7d22 List[TraceMetadata] <code>complex_search()</code> \u8907\u6570\u6761\u4ef6\u306b\u3088\u308b\u8907\u5408\u691c\u7d22 List[TraceMetadata] <code>get_statistics()</code> \u30c8\u30ec\u30fc\u30b9\u7d71\u8a08\u3092\u53d6\u5f97 Dict[str, Any] <code>export_traces()</code> \u30c8\u30ec\u30fc\u30b9\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u30a8\u30af\u30b9\u30dd\u30fc\u30c8 None <code>import_traces()</code> \u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30c8\u30ec\u30fc\u30b9\u3092\u30a4\u30f3\u30dd\u30fc\u30c8 int"},{"location":"trace_search_api/#tracemetadata","title":"TraceMetadata","text":"<p>\u30c8\u30ec\u30fc\u30b9\u306e\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u8868\u73fe\u3059\u308b\u30c7\u30fc\u30bf\u30af\u30e9\u30b9\u3067\u3059\u3002</p> \u30d5\u30a3\u30fc\u30eb\u30c9 \u578b \u8aac\u660e <code>trace_id</code> str \u30e6\u30cb\u30fc\u30af\u306a\u30c8\u30ec\u30fc\u30b9\u8b58\u5225\u5b50 <code>flow_name</code> Optional[str] \u30d5\u30ed\u30fc\u540d <code>flow_id</code> Optional[str] \u30d5\u30ed\u30fc\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9ID <code>agent_names</code> List[str] \u4f7f\u7528\u3055\u308c\u305f\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u306e\u30ea\u30b9\u30c8 <code>start_time</code> datetime \u30c8\u30ec\u30fc\u30b9\u958b\u59cb\u6642\u523b <code>end_time</code> Optional[datetime] \u30c8\u30ec\u30fc\u30b9\u7d42\u4e86\u6642\u523b <code>status</code> str \u30c8\u30ec\u30fc\u30b9\u30b9\u30c6\u30fc\u30bf\u30b9 (running, completed, error) <code>total_spans</code> int \u30c8\u30ec\u30fc\u30b9\u5185\u306e\u30b9\u30d1\u30f3\u6570 <code>error_count</code> int \u30a8\u30e9\u30fc\u30b9\u30d1\u30f3\u6570 <code>duration_seconds</code> Optional[float] \u7dcf\u5b9f\u884c\u6642\u9593 <code>tags</code> Dict[str, Any] \u30ab\u30b9\u30bf\u30e0\u30bf\u30b0 <code>artifacts</code> Dict[str, Any] \u30c8\u30ec\u30fc\u30b9\u6210\u679c\u7269"},{"location":"trace_search_api/#_3","title":"\u691c\u7d22\u30e1\u30bd\u30c3\u30c9\u8a73\u7d30","text":""},{"location":"trace_search_api/#_4","title":"\u30d5\u30ed\u30fc\u540d\u306b\u3088\u308b\u691c\u7d22","text":"<pre><code># \u5b8c\u5168\u4e00\u81f4\u691c\u7d22\nexact_matches = registry.search_by_flow_name(\"customer_support_workflow\", exact_match=True)\n\n# \u90e8\u5206\u4e00\u81f4\u691c\u7d22\npartial_matches = registry.search_by_flow_name(\"support\", exact_match=False)\n</code></pre> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>flow_name</code> (str): \u691c\u7d22\u3059\u308b\u30d5\u30ed\u30fc\u540d - <code>exact_match</code> (bool): \u5b8c\u5168\u4e00\u81f4\u3092\u4f7f\u7528\u3059\u308b\u304b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: False\uff09</p>"},{"location":"trace_search_api/#_5","title":"\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u306b\u3088\u308b\u691c\u7d22","text":"<pre><code># \u7279\u5b9a\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u691c\u7d22\nagent_traces = registry.search_by_agent_name(\"SupportAgent\", exact_match=True)\n\n# \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u30d1\u30bf\u30fc\u30f3\u3092\u691c\u7d22\npattern_traces = registry.search_by_agent_name(\"Agent\", exact_match=False)\n</code></pre> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>agent_name</code> (str): \u691c\u7d22\u3059\u308b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d - <code>exact_match</code> (bool): \u5b8c\u5168\u4e00\u81f4\u3092\u4f7f\u7528\u3059\u308b\u304b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: False\uff09</p>"},{"location":"trace_search_api/#_6","title":"\u30bf\u30b0\u306b\u3088\u308b\u691c\u7d22","text":"<pre><code># \u3059\u3079\u3066\u306e\u30bf\u30b0\u304c\u30de\u30c3\u30c1\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\nall_match = registry.search_by_tags({\"env\": \"prod\", \"version\": \"1.0\"}, match_all=True)\n\n# \u3044\u305a\u308c\u304b\u306e\u30bf\u30b0\u304c\u30de\u30c3\u30c1\u3059\u308c\u3070\u3088\u3044\nany_match = registry.search_by_tags({\"priority\": \"high\"}, match_all=False)\n</code></pre> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>tags</code> (Dict[str, Any]): \u691c\u7d22\u3059\u308b\u30bf\u30b0 - <code>match_all</code> (bool): \u3059\u3079\u3066\u306e\u30bf\u30b0\u304c\u30de\u30c3\u30c1\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: True\uff09</p>"},{"location":"trace_search_api/#_7","title":"\u6642\u9593\u7bc4\u56f2\u306b\u3088\u308b\u691c\u7d22","text":"<pre><code>from datetime import datetime, timedelta\n\n# \u904e\u53bb1\u6642\u9593\u306e\u30c8\u30ec\u30fc\u30b9\nrecent = registry.search_by_time_range(\n    start_time=datetime.now() - timedelta(hours=1)\n)\n\n# \u7279\u5b9a\u306e\u671f\u9593\u306e\u30c8\u30ec\u30fc\u30b9\nperiod = registry.search_by_time_range(\n    start_time=datetime(2024, 1, 1),\n    end_time=datetime(2024, 1, 31)\n)\n</code></pre> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>start_time</code> (Optional[datetime]): \u691c\u7d22\u958b\u59cb\u6642\u523b - <code>end_time</code> (Optional[datetime]): \u691c\u7d22\u7d42\u4e86\u6642\u523b</p>"},{"location":"trace_search_api/#_8","title":"\u8907\u5408\u691c\u7d22","text":"<pre><code># \u8907\u6570\u6761\u4ef6\u306b\u3088\u308b\u691c\u7d22\nresults = registry.complex_search(\n    flow_name=\"support\",           # \u30d5\u30ed\u30fc\u540d\u306b\"support\"\u3092\u542b\u3080\n    agent_name=\"Agent\",            # \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u306b\"Agent\"\u3092\u542b\u3080\n    status=\"completed\",            # \u30b9\u30c6\u30fc\u30bf\u30b9\u304c\"completed\"\n    tags={\"priority\": \"high\"},     # \u30bf\u30b0\u306b\"priority\": \"high\"\u3092\u542b\u3080\n    start_time=datetime.now() - timedelta(days=7),  # \u904e\u53bb7\u65e5\u9593\n    max_results=10                 # \u6700\u592710\u4ef6\n)\n</code></pre> <p>\u30d1\u30e9\u30e1\u30fc\u30bf: - <code>flow_name</code> (Optional[str]): \u30d5\u30ed\u30fc\u540d\u30d5\u30a3\u30eb\u30bf - <code>agent_name</code> (Optional[str]): \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u30d5\u30a3\u30eb\u30bf - <code>tags</code> (Optional[Dict[str, Any]]): \u30bf\u30b0\u30d5\u30a3\u30eb\u30bf - <code>status</code> (Optional[str]): \u30b9\u30c6\u30fc\u30bf\u30b9\u30d5\u30a3\u30eb\u30bf - <code>start_time</code> (Optional[datetime]): \u958b\u59cb\u6642\u523b\u30d5\u30a3\u30eb\u30bf - <code>end_time</code> (Optional[datetime]): \u7d42\u4e86\u6642\u523b\u30d5\u30a3\u30eb\u30bf - <code>max_results</code> (Optional[int]): \u6700\u5927\u7d50\u679c\u6570</p>"},{"location":"trace_search_api/#_9","title":"\u7d71\u8a08\u60c5\u5831","text":"<pre><code>stats = registry.get_statistics()\nprint(f\"\u7dcf\u30c8\u30ec\u30fc\u30b9\u6570: {stats['total_traces']}\")\nprint(f\"\u30e6\u30cb\u30fc\u30af\u30d5\u30ed\u30fc\u540d\u6570: {stats['unique_flow_names']}\")\nprint(f\"\u30e6\u30cb\u30fc\u30af\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u6570: {stats['unique_agent_names']}\")\nprint(f\"\u7dcf\u30b9\u30d1\u30f3\u6570: {stats['total_spans']}\")\nprint(f\"\u7dcf\u30a8\u30e9\u30fc\u6570: {stats['total_errors']}\")\nprint(f\"\u5e73\u5747\u5b9f\u884c\u6642\u9593: {stats['average_duration_seconds']:.2f}\u79d2\")\n</code></pre> <p>\u623b\u308a\u5024\u306e\u69cb\u9020: <pre><code>{\n    \"total_traces\": int,\n    \"status_distribution\": Dict[str, int],\n    \"unique_flow_names\": int,\n    \"unique_agent_names\": int,\n    \"total_spans\": int,\n    \"total_errors\": int,\n    \"average_duration_seconds\": float,\n    \"flow_names\": List[str],\n    \"agent_names\": List[str]\n}\n</code></pre></p>"},{"location":"trace_search_api/#_10","title":"\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u30fb\u30a4\u30f3\u30dd\u30fc\u30c8","text":""},{"location":"trace_search_api/#_11","title":"\u30a8\u30af\u30b9\u30dd\u30fc\u30c8","text":"<pre><code># JSON\u30d5\u30a1\u30a4\u30eb\u306b\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\nregistry.export_traces(\"traces_backup.json\", format=\"json\")\n</code></pre>"},{"location":"trace_search_api/#_12","title":"\u30a4\u30f3\u30dd\u30fc\u30c8","text":"<pre><code># JSON\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30a4\u30f3\u30dd\u30fc\u30c8\nimported_count = registry.import_traces(\"traces_backup.json\", format=\"json\")\nprint(f\"{imported_count}\u4ef6\u306e\u30c8\u30ec\u30fc\u30b9\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\u3057\u307e\u3057\u305f\")\n</code></pre>"},{"location":"trace_search_api/#_13","title":"\u30b0\u30ed\u30fc\u30d0\u30eb\u30ec\u30b8\u30b9\u30c8\u30ea","text":"<pre><code>from agents_sdk_models import get_global_registry, set_global_registry\n\n# \u30b0\u30ed\u30fc\u30d0\u30eb\u30ec\u30b8\u30b9\u30c8\u30ea\u3092\u53d6\u5f97\nregistry = get_global_registry()\n\n# \u30ab\u30b9\u30bf\u30e0\u30ec\u30b8\u30b9\u30c8\u30ea\u3092\u8a2d\u5b9a\ncustom_registry = TraceRegistry(storage_path=\"custom_traces.json\")\nset_global_registry(custom_registry)\n</code></pre>"},{"location":"trace_search_api/#flow","title":"Flow\u7d71\u5408","text":"<p>Flow\u30af\u30e9\u30b9\u306f\u81ea\u52d5\u7684\u306b\u30c8\u30ec\u30fc\u30b9\u30ec\u30b8\u30b9\u30c8\u30ea\u3068\u7d71\u5408\u3055\u308c\u307e\u3059\uff1a</p> <pre><code># \u30d5\u30ed\u30fc\u4f5c\u6210\u6642\u306b\u81ea\u52d5\u7684\u306b\u30c8\u30ec\u30fc\u30b9\u304c\u767b\u9332\u3055\u308c\u308b\nflow = Flow(\n    name=\"my_workflow\",\n    steps=my_steps,\n    start=\"first_step\"\n)\n\n# \u30d5\u30ed\u30fc\u5b9f\u884c\u5f8c\u3001\u30c8\u30ec\u30fc\u30b9\u304c\u66f4\u65b0\u3055\u308c\u308b\nawait flow.run(\"input_data\")\n\n# \u691c\u7d22\u3067\u898b\u3064\u3051\u308b\u3053\u3068\u304c\u3067\u304d\u308b\ntraces = registry.search_by_flow_name(\"my_workflow\")\n</code></pre>"},{"location":"trace_search_api/#_14","title":"\u4f7f\u7528\u4f8b","text":""},{"location":"trace_search_api/#1","title":"1. \u7279\u5b9a\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f7f\u7528\u3057\u305f\u30d5\u30ed\u30fc\u306e\u691c\u7d22","text":"<pre><code># SupportAgent\u3092\u4f7f\u7528\u3057\u305f\u3059\u3079\u3066\u306e\u30d5\u30ed\u30fc\u3092\u691c\u7d22\nsupport_traces = registry.search_by_agent_name(\"SupportAgent\")\nfor trace in support_traces:\n    print(f\"\u30d5\u30ed\u30fc: {trace.flow_name}, \u958b\u59cb\u6642\u523b: {trace.start_time}\")\n</code></pre>"},{"location":"trace_search_api/#2","title":"2. \u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u305f\u30d5\u30ed\u30fc\u306e\u5206\u6790","text":"<pre><code># \u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3092\u691c\u7d22\nerror_traces = registry.search_by_status(\"error\")\nfor trace in error_traces:\n    error_step = trace.tags.get(\"error_step\", \"\u4e0d\u660e\")\n    error_type = trace.tags.get(\"error_type\", \"\u4e0d\u660e\")\n    print(f\"\u30a8\u30e9\u30fc\u30d5\u30ed\u30fc: {trace.flow_name}, \u30b9\u30c6\u30c3\u30d7: {error_step}, \u30a8\u30e9\u30fc: {error_type}\")\n</code></pre>"},{"location":"trace_search_api/#3","title":"3. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u5206\u6790","text":"<pre><code># \u5b8c\u4e86\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u306e\u5b9f\u884c\u6642\u9593\u3092\u5206\u6790\ncompleted_traces = registry.search_by_status(\"completed\")\ndurations = [t.duration_seconds for t in completed_traces if t.duration_seconds]\nif durations:\n    avg_duration = sum(durations) / len(durations)\n    print(f\"\u5e73\u5747\u5b9f\u884c\u6642\u9593: {avg_duration:.2f}\u79d2\")\n</code></pre>"},{"location":"trace_search_api/#4","title":"4. \u6700\u8fd1\u306e\u30a2\u30af\u30c6\u30a3\u30d3\u30c6\u30a3\u76e3\u8996","text":"<pre><code># \u904e\u53bb1\u6642\u9593\u306e\u30a2\u30af\u30c6\u30a3\u30d3\u30c6\u30a3\u3092\u76e3\u8996\nrecent_traces = registry.get_recent_traces(hours=1)\nprint(f\"\u904e\u53bb1\u6642\u9593\u3067{len(recent_traces)}\u4ef6\u306e\u30d5\u30ed\u30fc\u304c\u5b9f\u884c\u3055\u308c\u307e\u3057\u305f\")\n\n# \u30b9\u30c6\u30fc\u30bf\u30b9\u5225\u306e\u5206\u5e03\nstatus_counts = {}\nfor trace in recent_traces:\n    status_counts[trace.status] = status_counts.get(trace.status, 0) + 1\nprint(\"\u30b9\u30c6\u30fc\u30bf\u30b9\u5206\u5e03:\", status_counts)\n</code></pre>"},{"location":"trace_search_api/#_15","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li>\u30d5\u30ed\u30fc\u540d\u306e\u547d\u540d\u898f\u5247: \u691c\u7d22\u3057\u3084\u3059\u3044\u3088\u3046\u306b\u4e00\u8cab\u3057\u305f\u547d\u540d\u898f\u5247\u3092\u4f7f\u7528\u3059\u308b</li> <li>\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u306e\u6a19\u6e96\u5316: \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u540d\u306b\u4e00\u8cab\u3057\u305f\u30d1\u30bf\u30fc\u30f3\u3092\u4f7f\u7528\u3059\u308b</li> <li>\u30bf\u30b0\u306e\u6d3b\u7528: \u74b0\u5883\u3001\u30d0\u30fc\u30b8\u30e7\u30f3\u3001\u512a\u5148\u5ea6\u306a\u3069\u306e\u60c5\u5831\u3092\u30bf\u30b0\u3067\u7ba1\u7406\u3059\u308b</li> <li>\u5b9a\u671f\u7684\u306a\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7: \u53e4\u3044\u30c8\u30ec\u30fc\u30b9\u3092\u5b9a\u671f\u7684\u306b\u524a\u9664\u3059\u308b</li> <li>\u30a8\u30af\u30b9\u30dd\u30fc\u30c8: \u91cd\u8981\u306a\u30c8\u30ec\u30fc\u30b9\u30c7\u30fc\u30bf\u306f\u5b9a\u671f\u7684\u306b\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3057\u3066\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3059\u308b</li> </ol>"},{"location":"trace_search_api/#_16","title":"\u6ce8\u610f\u4e8b\u9805","text":"<ul> <li>\u30c8\u30ec\u30fc\u30b9\u30ec\u30b8\u30b9\u30c8\u30ea\u306f\u30e1\u30e2\u30ea\u5185\u306b\u4fdd\u5b58\u3055\u308c\u308b\u305f\u3081\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u518d\u8d77\u52d5\u6642\u306b\u306f\u30c7\u30fc\u30bf\u304c\u5931\u308f\u308c\u307e\u3059</li> <li>\u6c38\u7d9a\u5316\u304c\u5fc5\u8981\u306a\u5834\u5408\u306f\u3001<code>storage_path</code>\u3092\u6307\u5b9a\u3057\u3066TraceRegistry\u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044</li> <li>\u5927\u91cf\u306e\u30c8\u30ec\u30fc\u30b9\u3092\u6271\u3046\u5834\u5408\u306f\u3001\u5b9a\u671f\u7684\u306a\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</li> <li>\u691c\u7d22\u7d50\u679c\u306f\u958b\u59cb\u6642\u523b\u306e\u964d\u9806\uff08\u65b0\u3057\u3044\u9806\uff09\u3067\u30bd\u30fc\u30c8\u3055\u308c\u307e\u3059 </li> </ul>"},{"location":"tracing/","title":"\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0","text":""},{"location":"tracing/#openai-agents-sdk","title":"OpenAI Agents SDK \u306e\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u6a5f\u80fd","text":"<p>OpenAI Agents SDK \u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067 OpenAI \u306e\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u30b5\u30fc\u30d3\u30b9\u3092\u5229\u7528\u3057\u3001\u5b9f\u884c\u4e2d\u306e\u30b9\u30d1\u30f3\u60c5\u5831\u3092\u81ea\u52d5\u7684\u306b\u53ce\u96c6\u30fb\u8a18\u9332\u3057\u307e\u3059\u3002 - \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306b\u95a2\u308f\u3089\u305a\u3001\u5185\u90e8\u3067\u306f OpenAI \u306e Trace API \u3092\u4f7f\u7528\u3057\u307e\u3059\u3002 - <code>OPENAI_API_KEY</code> \u306e\u8a2d\u5b9a\u304c\u5fc5\u8981\u3067\u3059\u3002</p>"},{"location":"tracing/#_2","title":"\u672c\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u306e\u30a2\u30d7\u30ed\u30fc\u30c1","text":"<ul> <li>\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u30b3\u30f3\u30bd\u30fc\u30eb\u5411\u3051\u306e <code>ConsoleTracingProcessor</code> \u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</li> <li>\u6709\u52b9\u5316: <code>enable_console_tracing()</code> \u3092\u547c\u3073\u51fa\u3059\u3068\u3001\u30b3\u30f3\u30bd\u30fc\u30eb\u306b\u30ab\u30e9\u30fc\u4ed8\u304d\u3067\u30b9\u30d1\u30f3\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002</li> <li>\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u30b5\u30fc\u30c9\u30d1\u30fc\u30c6\u30a3\u30fc\u304c\u63d0\u4f9b\u3059\u308b\u72ec\u81ea\u306e Processor \u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> <li>\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u3092\u505c\u6b62\u3057\u305f\u3044\u5834\u5408\u306f\u3001<code>disable_tracing()</code> \u3092\u547c\u3073\u51fa\u3057\u3066\u5168\u3066\u306e\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u6a5f\u80fd\u3092\u7121\u52b9\u5316\u3057\u307e\u3059\u3002</li> </ul> <p>\u4ee5\u4e0a\u306e\u4ed5\u7d44\u307f\u306b\u3088\u308a\u3001\u30c7\u30d0\u30c3\u30b0\u6642\u3084\u30ed\u30fc\u30ab\u30eb\u958b\u767a\u74b0\u5883\u3067\u3082\u624b\u8efd\u306b\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u60c5\u5831\u3092\u78ba\u8a8d\u3067\u304d\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u30b5\u30fc\u30d3\u30b9\u9023\u643a\u3084\u30ed\u30b0\u51fa\u529b\u5148\u3092\u5207\u308a\u66ff\u3048\u3089\u308c\u307e\u3059\u3002 </p>"},{"location":"unified-llm-interface_ja/","title":"Unified LLM Interface - \u7d71\u4e00LLM\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9","text":"<p>Refinire\u306e\u7b2c\u4e00\u306e\u67f1\u3067\u3042\u308b\u7d71\u4e00LLM\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306f\u3001\u8907\u6570\u306eLLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u540c\u4e00\u306eAPI\u3067\u64cd\u4f5c\u3067\u304d\u308b\u9769\u65b0\u7684\u306a\u62bd\u8c61\u5316\u5c64\u3067\u3059\u3002</p>"},{"location":"unified-llm-interface_ja/#_1","title":"\u57fa\u672c\u6982\u5ff5","text":"<p>\u8907\u6570\u306eLLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u540c\u3058\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3067\u6271\u3046\u3053\u3068\u3067\u3001\u958b\u767a\u8005\u306f\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u56fa\u6709\u306e\u5b9f\u88c5\u306b\u7e1b\u3089\u308c\u308b\u3053\u3068\u306a\u304f\u3001\u81ea\u7531\u306b\u9078\u629e\u30fb\u5207\u308a\u66ff\u3048\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"unified-llm-interface_ja/#_2","title":"\u74b0\u5883\u5909\u6570\u306e\u8a2d\u5b9a","text":"<p>\u5404\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u4f7f\u7528\u3059\u308b\u306b\u306f\u3001\u5bfe\u5fdc\u3059\u308bAPI\u30ad\u30fc\u3092\u74b0\u5883\u5909\u6570\u306b\u8a2d\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff1a</p> \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc \u74b0\u5883\u5909\u6570 \u8aac\u660e OpenAI <code>OPENAI_API_KEY</code> OpenAI API\u30ad\u30fc Anthropic <code>ANTHROPIC_API_KEY</code> Anthropic Claude API\u30ad\u30fc Google <code>GOOGLE_API_KEY</code> Google Gemini API\u30ad\u30fc Ollama <code>OLLAMA_BASE_URL</code> Ollama\u30b5\u30fc\u30d0\u30fc\u30a2\u30c9\u30ec\u30b9\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: http://localhost:11434\uff09"},{"location":"unified-llm-interface_ja/#_3","title":"\u74b0\u5883\u5909\u6570\u8a2d\u5b9a\u4f8b","text":"<p>Windows (PowerShell): <pre><code>$env:OPENAI_API_KEY = \"sk-your-openai-api-key\"\n$env:ANTHROPIC_API_KEY = \"sk-ant-your-anthropic-api-key\"\n$env:GOOGLE_API_KEY = \"your-google-api-key\"\n$env:OLLAMA_BASE_URL = \"http://localhost:11434\"\n</code></pre></p> <p>macOS/Linux (Bash): <pre><code>export OPENAI_API_KEY=\"sk-your-openai-api-key\"\nexport ANTHROPIC_API_KEY=\"sk-ant-your-anthropic-api-key\"\nexport GOOGLE_API_KEY=\"your-google-api-key\"\nexport OLLAMA_BASE_URL=\"http://localhost:11434\"\n</code></pre></p> <p>Python\u5185\u3067\u306e\u8a2d\u5b9a: <pre><code>import os\n\n# \u30d7\u30ed\u30b0\u30e9\u30e0\u5185\u3067\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\nos.environ[\"OPENAI_API_KEY\"] = \"sk-your-openai-api-key\"\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-your-anthropic-api-key\"\nos.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\nos.environ[\"OLLAMA_BASE_URL\"] = \"http://localhost:11434\"\n</code></pre></p>"},{"location":"unified-llm-interface_ja/#_4","title":"\u7d71\u4e00\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9","text":"<p>\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u5f8c\u3001\u3059\u3079\u3066\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u304c\u540c\u3058API\u3067\u5229\u7528\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>from refinire import get_llm\n\n# \u540c\u3058\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3067\u7570\u306a\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306b\u30a2\u30af\u30bb\u30b9\nllm_openai = get_llm(\"gpt-4o-mini\")\nllm_anthropic = get_llm(\"claude-3-sonnet\")\nllm_google = get_llm(\"gemini-pro\")\nllm_ollama = get_llm(\"llama3.1:8b\")\n\n# \u3059\u3079\u3066\u540c\u3058\u30e1\u30bd\u30c3\u30c9\u3067\u64cd\u4f5c\nresponse = llm_openai.complete(\"\u3053\u3093\u306b\u3061\u306f\")\n</code></pre>"},{"location":"unified-llm-interface_ja/#_5","title":"\u7c21\u5358\u306a\u4e8b\u4f8b","text":""},{"location":"unified-llm-interface_ja/#1-llm","title":"1. \u57fa\u672c\u7684\u306aLLM\u4f7f\u7528","text":"<pre><code>from refinire import get_llm\n\n# LLM\u306e\u53d6\u5f97\nllm = get_llm(\"gpt-4o-mini\")\n\n# \u30c6\u30ad\u30b9\u30c8\u751f\u6210\nresponse = llm.complete(\"AI\u306e\u5c06\u6765\u6027\u306b\u3064\u3044\u3066\u6559\u3048\u3066\u304f\u3060\u3055\u3044\")\nprint(response)\n</code></pre>"},{"location":"unified-llm-interface_ja/#2","title":"2. \u74b0\u5883\u5909\u6570\u8a2d\u5b9a\u306e\u78ba\u8a8d","text":"<pre><code>import os\nfrom refinire import get_llm\n\ndef check_api_setup():\n    \"\"\"API\u8a2d\u5b9a\u306e\u78ba\u8a8d\"\"\"\n    providers_check = {\n        \"OpenAI\": \"OPENAI_API_KEY\",\n        \"Anthropic\": \"ANTHROPIC_API_KEY\", \n        \"Google\": \"GOOGLE_API_KEY\",\n        \"Ollama\": \"OLLAMA_BASE_URL\"\n    }\n\n    for provider, env_var in providers_check.items():\n        if env_var in os.environ:\n            print(f\"\u2713 {provider}: \u8a2d\u5b9a\u6e08\u307f\")\n        else:\n            print(f\"\u2717 {provider}: {env_var} \u304c\u672a\u8a2d\u5b9a\")\n\n# API\u8a2d\u5b9a\u78ba\u8a8d\ncheck_api_setup()\n</code></pre>"},{"location":"unified-llm-interface_ja/#3","title":"3. \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u5207\u308a\u66ff\u3048","text":"<pre><code>def test_providers():\n    \"\"\"\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u30c6\u30b9\u30c8\u5b9f\u884c\"\"\"\n    providers = [\n        (\"gpt-4o-mini\", \"OpenAI\"),\n        (\"claude-3-haiku-20240307\", \"Anthropic\"),\n        (\"gemini-1.5-flash\", \"Google\"),\n        (\"llama3.1:8b\", \"Ollama\")\n    ]\n    question = \"\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u3068\u306f\u4f55\u3067\u3059\u304b\uff1f\"\n\n    for model, provider in providers:\n        try:\n            llm = get_llm(model)\n            response = llm.complete(question)\n            print(f\"\u2713 {provider} ({model}): {response[:100]}...\")\n        except Exception as e:\n            print(f\"\u2717 {provider} ({model}): \u30a8\u30e9\u30fc - {e}\")\n\n# \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u30c6\u30b9\u30c8\u5b9f\u884c\ntest_providers()\n</code></pre>"},{"location":"unified-llm-interface_ja/#_6","title":"\u4e2d\u7d1a\u4e8b\u4f8b","text":""},{"location":"unified-llm-interface_ja/#3_1","title":"3. \u6226\u7565\u7684\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u4f7f\u3044\u5206\u3051","text":"<pre><code>class MultiProviderService:\n    def __init__(self):\n        self.fast_llm = get_llm(\"gpt-4o-mini\")      # \u9ad8\u901f\n        self.smart_llm = get_llm(\"gpt-4o\")          # \u9ad8\u6027\u80fd\n        self.creative_llm = get_llm(\"claude-3-sonnet\")  # \u5275\u9020\u6027\n\n    def quick_answer(self, question: str) -&gt; str:\n        return self.fast_llm.complete(f\"\u7c21\u6f54\u306b: {question}\")\n\n    def detailed_analysis(self, topic: str) -&gt; str:\n        return self.smart_llm.complete(f\"\u8a73\u7d30\u5206\u6790: {topic}\")\n\n    def creative_writing(self, theme: str) -&gt; str:\n        return self.creative_llm.complete(f\"\u5275\u4f5c: {theme}\")\n</code></pre>"},{"location":"unified-llm-interface_ja/#4","title":"4. \u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af\u6a5f\u69cb","text":"<pre><code>class RobustLLMService:\n    def __init__(self, provider_hierarchy):\n        self.provider_hierarchy = provider_hierarchy\n        self.llms = {p: get_llm(p) for p in provider_hierarchy}\n\n    def complete_with_fallback(self, prompt: str):\n        for provider in self.provider_hierarchy:\n            try:\n                return self.llms[provider].complete(prompt), provider\n            except Exception as e:\n                print(f\"{provider} \u5931\u6557: {e}\")\n        raise Exception(\"\u5168\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u5931\u6557\")\n</code></pre>"},{"location":"unified-llm-interface_ja/#_7","title":"\u9ad8\u5ea6\u306a\u4e8b\u4f8b","text":""},{"location":"unified-llm-interface_ja/#5","title":"5. \u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u9078\u629e","text":"<pre><code>from enum import Enum\n\nclass TaskType(Enum):\n    CREATIVE = \"creative\"\n    TECHNICAL = \"technical\"\n    CASUAL = \"casual\"\n\nclass SmartProviderSelector:\n    def __init__(self):\n        self.profiles = {\n            \"gpt-4o-mini\": {\"strengths\": [TaskType.CASUAL], \"cost\": 1},\n            \"claude-3-sonnet\": {\"strengths\": [TaskType.CREATIVE], \"cost\": 2},\n            \"gpt-4o\": {\"strengths\": [TaskType.TECHNICAL], \"cost\": 3}\n        }\n\n    def classify_task(self, prompt: str) -&gt; TaskType:\n        if any(word in prompt for word in [\"\u7269\u8a9e\", \"\u5275\u4f5c\"]):\n            return TaskType.CREATIVE\n        elif any(word in prompt for word in [\"\u5206\u6790\", \"\u6280\u8853\"]):\n            return TaskType.TECHNICAL\n        return TaskType.CASUAL\n\n    def select_provider(self, prompt: str, priority=\"balanced\"):\n        task_type = self.classify_task(prompt)\n        # \u6700\u9069\u306a\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u9078\u629e\u3059\u308b\u30ed\u30b8\u30c3\u30af\n        for provider, profile in self.profiles.items():\n            if task_type in profile[\"strengths\"]:\n                return provider\n        return \"gpt-4o-mini\"  # \u30c7\u30d5\u30a9\u30eb\u30c8\n</code></pre>"},{"location":"unified-llm-interface_ja/#_8","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u900f\u660e\u6027: \u7d71\u4e00\u3055\u308c\u305fAPI\u3067\u8907\u6570\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u64cd\u4f5c</li> <li>\u79fb\u884c\u5bb9\u6613\u6027: \u6700\u5c0f\u9650\u306e\u5909\u66f4\u3067\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u5207\u308a\u66ff\u3048</li> <li>\u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af: \u5805\u7262\u306a\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0</li> <li>\u6700\u9069\u5316: \u30bf\u30b9\u30af\u306b\u5fdc\u3058\u305f\u81ea\u52d5\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u9078\u629e</li> </ul> <p>\u7d71\u4e00LLM\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306b\u3088\u308a\u3001\u958b\u767a\u8005\u306f\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u8a73\u7d30\u306b\u7e1b\u3089\u308c\u305a\u3001AI\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u4fa1\u5024\u5275\u9020\u306b\u96c6\u4e2d\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"workflow/","title":"Workflow \u306b\u3064\u3044\u3066","text":"<ul> <li>Workflow\u3068\u306fAgent/Interaction/Tool\u306e\u9023\u9396\u3092\u884c\u3046\u6a5f\u80fd\u3067\u3059\u3002</li> <li></li> <li> <p>\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u60c5\u5831\u306b\u3082\u3068\u3065\u304d\u3001\u6b21\u306e\u8981\u7d20\u3092\u3053\u3046</p> </li> <li> <p>\u6b21\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u304c\u3042\u308a\u307e\u3059\u3002 \u3000\u30fb\u5bfe\u8a71\u578b\u30ef\u30fc\u30af\u30d5\u30ed\u30fc \u3000\u30fb\u81ea\u5f8b\u578b\u30ef\u30fc\u30af\u30d5\u30ed\u30fc</p> </li> </ul>"},{"location":"developer/ai_completion/","title":"AI\u88dc\u5b8c\u8a2d\u5b9a","text":"<p>\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u3001agents-sdk-models\u306eAI\u88dc\u5b8c\u6a5f\u80fd\u3092\u8a2d\u5b9a\u3059\u308b\u65b9\u6cd5\u3092\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"developer/ai_completion/#_1","title":"\u6982\u8981","text":"<p>agents-sdk-models\u3067\u306f\u3001\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u81ea\u52d5\u751f\u6210\u3057\u3066\u3001IDE \u3084\u30a8\u30c7\u30a3\u30bf\u30fc\u3067\u306eAI\u88dc\u5b8c\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\uff1a</p> <ul> <li><code>openai_tools.json</code> - OpenAI Agents SDK\u7528\u306e\u30c4\u30fc\u30eb\u5b9a\u7fa9</li> <li><code>.aidef</code> - \u6c4e\u7528\u7684\u306aAI\u5b9a\u7fa9\u30d5\u30a1\u30a4\u30eb</li> <li><code>py.typed</code> - \u578b\u60c5\u5831\u306e\u63d0\u4f9b</li> </ul>"},{"location":"developer/ai_completion/#_2","title":"\u81ea\u52d5\u751f\u6210","text":""},{"location":"developer/ai_completion/#_3","title":"\u30c4\u30fc\u30eb\u5b9a\u7fa9\u30d5\u30a1\u30a4\u30eb\u306e\u751f\u6210","text":"<pre><code># \u4eee\u60f3\u74b0\u5883\u3092\u6709\u52b9\u306b\u3057\u3066\u5b9f\u884c\nuv run python scripts/generate_ai_tools.py\n</code></pre> <p>\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u3057\u307e\u3059\uff1a</p> <ol> <li>openai_tools.json - OpenAI Agents SDK\u5411\u3051\u306e\u30c4\u30fc\u30eb\u5b9a\u7fa9</li> <li>.aidef - \u6c4e\u7528\u7684\u306aAI\u5b9a\u7fa9\uff08\u30de\u30fc\u30af\u30c0\u30a6\u30f3\u5f62\u5f0f\uff09</li> </ol>"},{"location":"developer/ai_completion/#_4","title":"\u751f\u6210\u3055\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u4f8b","text":""},{"location":"developer/ai_completion/#openai_toolsjson","title":"openai_tools.json","text":"<pre><code>{\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"agents_sdk_models.pipeline.Pipeline.run\",\n        \"description\": \"Run the pipeline with given prompt and configuration\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"prompt\": {\n              \"type\": \"str\",\n              \"description\": \"Parameter prompt\"\n            },\n            \"llm\": {\n              \"type\": \"LLM\",\n              \"description\": \"Parameter llm\"\n            }\n          },\n          \"required\": [\"prompt\", \"llm\"]\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"developer/ai_completion/#aidef","title":".aidef","text":"<pre><code># AI Definition for agents-sdk-models\n# agents-sdk-models\u306eAI\u5b9a\u7fa9\n\n## Module: agents_sdk_models.pipeline\n\n### Classes / \u30af\u30e9\u30b9\n\n- **Pipeline**: Main pipeline class for processing prompts\n  - Methods / \u30e1\u30bd\u30c3\u30c9:\n    - `run`: Run the pipeline with given prompt and configuration\n    - `add_step`: Add a processing step to the pipeline\n</code></pre>"},{"location":"developer/ai_completion/#ide","title":"IDE\u3067\u306e\u8a2d\u5b9a","text":""},{"location":"developer/ai_completion/#vs-code","title":"VS Code","text":"<ol> <li> <p>Python\u578b\u30c1\u30a7\u30c3\u30af <pre><code>{\n  \"python.linting.mypyEnabled\": true,\n  \"python.linting.enabled\": true\n}\n</code></pre></p> </li> <li> <p>AI\u88dc\u5b8c\u8a2d\u5b9a\uff08Cursor\uff09</p> </li> <li><code>.aidef</code>\u30d5\u30a1\u30a4\u30eb\u304c\u81ea\u52d5\u7684\u306b\u8a8d\u8b58\u3055\u308c\u307e\u3059</li> <li><code>openai_tools.json</code>\u306fOpenAI Agents SDK\u8a2d\u5b9a\u3067\u5229\u7528\u3055\u308c\u307e\u3059</li> </ol>"},{"location":"developer/ai_completion/#pycharm","title":"PyCharm","text":"<ol> <li>Type hinting\u306e\u6709\u52b9\u5316</li> <li>Settings \u2192 Editor \u2192 Inspections \u2192 Python \u2192 Type checker</li> <li> <p>\"Mypy\" \u3092\u6709\u52b9\u306b\u3059\u308b</p> </li> <li> <p>\u5916\u90e8\u30c4\u30fc\u30eb\u8a2d\u5b9a <pre><code># External Tools \u3067\u8a2d\u5b9a\nProgram: uv\nArguments: run python scripts/generate_ai_tools.py\nWorking Directory: $ProjectFileDir$\n</code></pre></p> </li> </ol>"},{"location":"developer/ai_completion/#_5","title":"\u578b\u30c1\u30a7\u30c3\u30af","text":""},{"location":"developer/ai_completion/#_6","title":"\u57fa\u672c\u8a2d\u5b9a","text":"<p><code>pyproject.toml</code>\u306bmypy\u8a2d\u5b9a\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\uff1a</p> <pre><code>[tool.mypy]\nstrict = true\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\n# ... \u305d\u306e\u4ed6\u306e\u8a2d\u5b9a\n</code></pre>"},{"location":"developer/ai_completion/#_7","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<pre><code># \u578b\u30c1\u30a7\u30c3\u30af\u5b9f\u884c\nuv run mypy src/\n\n# \u3088\u308a\u8a73\u7d30\u306a\u30c1\u30a7\u30c3\u30af\nuv run mypy --strict src/agents_sdk_models/\n</code></pre>"},{"location":"developer/ai_completion/#cicd","title":"CI/CD\u3067\u306e\u81ea\u52d5\u5b9f\u884c","text":"<p>GitHub Actions\u3067\u81ea\u52d5\u7684\u306bAI\u88dc\u5b8c\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u30fb\u691c\u8a3c\uff1a</p> <pre><code>- name: Generate AI tool definitions\n  run: |\n    uv run python scripts/generate_ai_tools.py\n\n    # Verify files were generated\n    test -f openai_tools.json &amp;&amp; echo \"\u2713 openai_tools.json generated\"\n    test -f .aidef &amp;&amp; echo \"\u2713 .aidef generated\"\n</code></pre>"},{"location":"developer/ai_completion/#_8","title":"\u30ab\u30b9\u30bf\u30de\u30a4\u30ba","text":""},{"location":"developer/ai_completion/#_9","title":"\u5bfe\u8c61\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u5909\u66f4","text":"<p><code>scripts/generate_ai_tools.py</code>\u306e<code>modules</code>\u30ea\u30b9\u30c8\u3092\u7de8\u96c6\uff1a</p> <pre><code>modules = [\n    \"agents_sdk_models.pipeline\",\n    \"agents_sdk_models.llm\",\n    \"agents_sdk_models.context\",\n    # \u65b0\u3057\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8ffd\u52a0\n    \"agents_sdk_models.your_new_module\",\n]\n</code></pre>"},{"location":"developer/ai_completion/#_10","title":"\u51fa\u529b\u5f62\u5f0f\u306e\u30ab\u30b9\u30bf\u30de\u30a4\u30ba","text":"<p>\u751f\u6210\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u7de8\u96c6\u3057\u3066\u3001\u51fa\u529b\u5f62\u5f0f\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>def generate_custom_format(modules: List[str]) -&gt; str:\n    \"\"\"\u30ab\u30b9\u30bf\u30e0\u5f62\u5f0f\u3067AI\u5b9a\u7fa9\u3092\u751f\u6210\"\"\"\n    # \u30ab\u30b9\u30bf\u30e0\u5b9f\u88c5\n    pass\n</code></pre>"},{"location":"developer/ai_completion/#_11","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"developer/ai_completion/#_12","title":"\u3088\u304f\u3042\u308b\u554f\u984c","text":"<ol> <li> <p>\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\u30a8\u30e9\u30fc <pre><code>Warning: Could not import agents_sdk_models.xxx: No module named 'xxx'\n</code></pre>    \u2192 \u65b0\u3057\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8ffd\u52a0\u3057\u305f\u5834\u5408\u3001<code>scripts/generate_ai_tools.py</code>\u306e\u5bfe\u8c61\u30ea\u30b9\u30c8\u3092\u66f4\u65b0</p> </li> <li> <p>\u578b\u60c5\u5831\u304c\u8a8d\u8b58\u3055\u308c\u306a\u3044 <pre><code>Cannot find module 'agents_sdk_models'\n</code></pre>    \u2192 <code>py.typed</code>\u30d5\u30a1\u30a4\u30eb\u304c\u6b63\u3057\u304f\u914d\u7f6e\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d</p> </li> <li> <p>AI\u88dc\u5b8c\u304c\u52b9\u304b\u306a\u3044    \u2192 <code>.aidef</code>\u30d5\u30a1\u30a4\u30eb\u304c\u6700\u65b0\u306e\u72b6\u614b\u304b\u78ba\u8a8d\u3057\u3001IDE\u3092\u518d\u8d77\u52d5</p> </li> </ol>"},{"location":"developer/ai_completion/#_13","title":"\u30c7\u30d0\u30c3\u30b0\u65b9\u6cd5","text":"<pre><code># \u751f\u6210\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u30c7\u30d0\u30c3\u30b0\u30e2\u30fc\u30c9\u3067\u5b9f\u884c\nuv run python scripts/generate_ai_tools.py --verbose\n\n# \u578b\u30c1\u30a7\u30c3\u30af\u306e\u8a73\u7d30\u51fa\u529b\nuv run mypy --verbose src/agents_sdk_models/\n\n# \u751f\u6210\u3055\u308c\u305f\u30d5\u30a1\u30a4\u30eb\u306e\u691c\u8a3c\ncat openai_tools.json | jq .\nhead -20 .aidef\n</code></pre>"},{"location":"developer/ai_completion/#_14","title":"\u8ca2\u732e","text":"<p>AI\u88dc\u5b8c\u6a5f\u80fd\u306e\u6539\u5584\u306b\u3054\u5354\u529b\u304f\u3060\u3055\u3044\uff1a</p> <ol> <li>\u65b0\u3057\u3044AI\u5b9a\u7fa9\u5f62\u5f0f\u306e\u63d0\u6848</li> <li>\u751f\u6210\u30b9\u30af\u30ea\u30d7\u30c8\u306e\u6a5f\u80fd\u8ffd\u52a0</li> <li>IDE\u56fa\u6709\u306e\u8a2d\u5b9a\u4f8b\u306e\u63d0\u4f9b</li> <li>\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u6539\u5584 </li> </ol>"},{"location":"developer/type_checking/","title":"\u578b\u30c1\u30a7\u30c3\u30af","text":"<p>\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u3001agents-sdk-models\u306e\u578b\u30c1\u30a7\u30c3\u30af\u6a5f\u80fd\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"developer/type_checking/#_2","title":"\u6982\u8981","text":"<p>agents-sdk-models\u3067\u306f\u4ee5\u4e0b\u306e\u578b\u30c1\u30a7\u30c3\u30af\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\uff1a</p> <ul> <li>mypy \u306b\u3088\u308b\u53b3\u5bc6\u306a\u9759\u7684\u578b\u30c1\u30a7\u30c3\u30af</li> <li>py.typed \u306b\u3088\u308b\u578b\u60c5\u5831\u306e\u63d0\u4f9b</li> <li>\u578b\u30d2\u30f3\u30c8 \u306b\u3088\u308b\u958b\u767a\u8005\u4f53\u9a13\u306e\u5411\u4e0a</li> </ul>"},{"location":"developer/type_checking/#_3","title":"\u8a2d\u5b9a","text":""},{"location":"developer/type_checking/#pyprojecttoml","title":"pyproject.toml \u306e\u8a2d\u5b9a","text":"<p>\u53b3\u5bc6\u306a\u578b\u30c1\u30a7\u30c3\u30af\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u307e\u3059\uff1a</p> <pre><code>[tool.mypy]\nstrict = true\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_any_generics = true\ndisallow_subclassing_any = true\ndisallow_untyped_calls = true\ndisallow_untyped_decorators = true\ndisallow_incomplete_defs = true\ncheck_untyped_defs = true\ndisallow_any_unimported = true\nno_implicit_optional = true\nwarn_redundant_casts = true\nwarn_unused_ignores = true\nwarn_no_return = true\nwarn_unreachable = true\n</code></pre>"},{"location":"developer/type_checking/#pytyped","title":"py.typed \u30d5\u30a1\u30a4\u30eb","text":"<p><code>src/agents_sdk_models/py.typed</code> \u30d5\u30a1\u30a4\u30eb\u306b\u3088\u308a\u3001\u3053\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u578b\u60c5\u5831\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3092\u5ba3\u8a00\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"developer/type_checking/#_4","title":"\u5b9f\u884c\u65b9\u6cd5","text":""},{"location":"developer/type_checking/#_5","title":"\u57fa\u672c\u7684\u306a\u30c1\u30a7\u30c3\u30af","text":"<pre><code># \u5168\u4f53\u306e\u30c1\u30a7\u30c3\u30af\nuv run mypy src/\n\n# \u7279\u5b9a\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30c1\u30a7\u30c3\u30af\nuv run mypy src/agents_sdk_models/pipeline.py\n\n# \u3088\u308a\u8a73\u7d30\u306a\u51fa\u529b\nuv run mypy --verbose src/agents_sdk_models/\n</code></pre>"},{"location":"developer/type_checking/#ci","title":"CI\u3067\u306e\u30c1\u30a7\u30c3\u30af","text":"<pre><code># GitHub Actions\u3067\u5b9f\u884c\nuv run mypy src/ --junit-xml=mypy-results.xml\n</code></pre>"},{"location":"developer/type_checking/#_6","title":"\u578b\u30d2\u30f3\u30c8\u306e\u4f8b","text":""},{"location":"developer/type_checking/#_7","title":"\u57fa\u672c\u7684\u306a\u578b\u30d2\u30f3\u30c8","text":"<pre><code>from typing import Optional, List, Dict, Any, Union\nfrom pathlib import Path\n\ndef process_prompt(\n    prompt: str,\n    max_tokens: Optional[int] = None,\n    temperature: float = 0.7\n) -&gt; str:\n    \"\"\"\n    Process a prompt with type hints\n    \u578b\u30d2\u30f3\u30c8\u4ed8\u304d\u3067\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u51e6\u7406\u3057\u307e\u3059\n\n    Args:\n        prompt: Input prompt\n               \u5165\u529b\u30d7\u30ed\u30f3\u30d7\u30c8\n        max_tokens: Maximum number of tokens to generate\n                   \u751f\u6210\u3059\u308b\u6700\u5927\u30c8\u30fc\u30af\u30f3\u6570\n        temperature: Sampling temperature\n                    \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6e29\u5ea6\n\n    Returns:\n        Processed result\n        \u51e6\u7406\u7d50\u679c\n    \"\"\"\n    # Implementation\n    return f\"Processed: {prompt}\"\n</code></pre>"},{"location":"developer/type_checking/#_8","title":"\u30af\u30e9\u30b9\u306e\u578b\u30d2\u30f3\u30c8","text":"<pre><code>from typing import Generic, TypeVar, Protocol\nfrom abc import ABC, abstractmethod\n\nT = TypeVar('T')\n\nclass Processor(Protocol):\n    \"\"\"\n    Processor protocol defining the interface\n    \u30d7\u30ed\u30bb\u30c3\u30b5\u30fc\u30d7\u30ed\u30c8\u30b3\u30eb\u3067\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u5b9a\u7fa9\n    \"\"\"\n    def process(self, data: str) -&gt; str:\n        \"\"\"Process data / \u30c7\u30fc\u30bf\u3092\u51e6\u7406\"\"\"\n        ...\n\nclass LLMProvider(ABC):\n    \"\"\"\n    Abstract base class for LLM providers\n    LLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u62bd\u8c61\u57fa\u5e95\u30af\u30e9\u30b9\n    \"\"\"\n\n    @abstractmethod\n    async def generate(\n        self,\n        prompt: str,\n        **kwargs: Any\n    ) -&gt; str:\n        \"\"\"\n        Generate text from prompt\n        \u30d7\u30ed\u30f3\u30d7\u30c8\u304b\u3089\u30c6\u30ad\u30b9\u30c8\u3092\u751f\u6210\n\n        Args:\n            prompt: Input prompt / \u5165\u529b\u30d7\u30ed\u30f3\u30d7\u30c8\n            **kwargs: Additional parameters / \u8ffd\u52a0\u30d1\u30e9\u30e1\u30fc\u30bf\n\n        Returns:\n            Generated text / \u751f\u6210\u3055\u308c\u305f\u30c6\u30ad\u30b9\u30c8\n        \"\"\"\n        pass\n\nclass OpenAIProvider(LLMProvider):\n    \"\"\"\n    OpenAI provider implementation\n    OpenAI\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u5b9f\u88c5\n    \"\"\"\n\n    def __init__(self, api_key: str, model: str = \"gpt-4o-mini\") -&gt; None:\n        self.api_key = api_key\n        self.model = model\n\n    async def generate(\n        self,\n        prompt: str,\n        **kwargs: Any\n    ) -&gt; str:\n        # Implementation\n        return f\"Generated response for: {prompt}\"\n</code></pre>"},{"location":"developer/type_checking/#_9","title":"\u30b8\u30a7\u30cd\u30ea\u30af\u30b9\u306e\u4f7f\u7528","text":"<pre><code>from typing import Generic, TypeVar, List, Optional\n\nT = TypeVar('T')\nR = TypeVar('R')\n\nclass Pipeline(Generic[T, R]):\n    \"\"\"\n    Generic pipeline class\n    \u30b8\u30a7\u30cd\u30ea\u30c3\u30af\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u30af\u30e9\u30b9\n\n    Type Parameters:\n        T: Input type / \u5165\u529b\u578b\n        R: Output type / \u51fa\u529b\u578b\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._steps: List[Callable[[T], T]] = []\n\n    def add_step(self, step: Callable[[T], T]) -&gt; 'Pipeline[T, R]':\n        \"\"\"\n        Add a processing step\n        \u51e6\u7406\u30b9\u30c6\u30c3\u30d7\u3092\u8ffd\u52a0\n\n        Args:\n            step: Processing function / \u51e6\u7406\u95a2\u6570\n\n        Returns:\n            Self for method chaining / \u30e1\u30bd\u30c3\u30c9\u30c1\u30a7\u30fc\u30f3\u7528\u306e\u81ea\u5206\u81ea\u8eab\n        \"\"\"\n        self._steps.append(step)\n        return self\n\n    def run(self, input_data: T) -&gt; R:\n        \"\"\"\n        Run the pipeline\n        \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u5b9f\u884c\n\n        Args:\n            input_data: Input data / \u5165\u529b\u30c7\u30fc\u30bf\n\n        Returns:\n            Processed result / \u51e6\u7406\u7d50\u679c\n        \"\"\"\n        result = input_data\n        for step in self._steps:\n            result = step(result)\n        return result  # type: ignore\n</code></pre>"},{"location":"developer/type_checking/#union-literal","title":"Union\u578b\u3068 Literal\u578b","text":"<pre><code>from typing import Union, Literal, overload\nfrom typing_extensions import TypedDict\n\nProvider = Literal[\"openai\", \"anthropic\", \"gemini\", \"ollama\"]\nModel = Union[str, None]\n\nclass LLMConfig(TypedDict):\n    \"\"\"\n    LLM configuration type\n    LLM\u8a2d\u5b9a\u306e\u578b\n    \"\"\"\n    provider: Provider\n    model: str\n    api_key: Optional[str]\n    temperature: float\n    max_tokens: Optional[int]\n\n@overload\ndef create_llm(provider: Literal[\"openai\"], model: str) -&gt; OpenAIProvider:\n    ...\n\n@overload  \ndef create_llm(provider: Literal[\"anthropic\"], model: str) -&gt; AnthropicProvider:\n    ...\n\n@overload\ndef create_llm(provider: Provider, model: str) -&gt; LLMProvider:\n    ...\n\ndef create_llm(provider: Provider, model: str) -&gt; LLMProvider:\n    \"\"\"\n    Create LLM instance with proper typing\n    \u9069\u5207\u306a\u578b\u4ed8\u304d\u3067LLM\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\n\n    Args:\n        provider: LLM provider name / LLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u540d\n        model: Model name / \u30e2\u30c7\u30eb\u540d\n\n    Returns:\n        LLM provider instance / LLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n    \"\"\"\n    if provider == \"openai\":\n        return OpenAIProvider(model=model)\n    elif provider == \"anthropic\":\n        return AnthropicProvider(model=model)\n    else:\n        raise ValueError(f\"Unsupported provider: {provider}\")\n</code></pre>"},{"location":"developer/type_checking/#_10","title":"\u578b\u30c1\u30a7\u30c3\u30af\u306e\u7121\u52b9\u5316","text":""},{"location":"developer/type_checking/#_11","title":"\u7279\u5b9a\u306e\u884c\u3092\u7121\u8996","text":"<pre><code># \u578b\u30c1\u30a7\u30c3\u30af\u3092\u7121\u8996\nresult = some_untyped_function()  # type: ignore\n\n# \u7279\u5b9a\u306e\u30a8\u30e9\u30fc\u306e\u307f\u7121\u8996\nresult = some_function()  # type: ignore[return-value]\n</code></pre>"},{"location":"developer/type_checking/#_12","title":"\u30d5\u30a1\u30a4\u30eb\u5168\u4f53\u3092\u7121\u8996","text":"<pre><code># mypy: ignore-errors\n\n# \u3053\u306e\u30d5\u30a1\u30a4\u30eb\u5168\u4f53\u3067\u578b\u30c1\u30a7\u30c3\u30af\u3092\u7121\u8996\n</code></pre>"},{"location":"developer/type_checking/#_13","title":"\u3088\u304f\u3042\u308b\u578b\u30a8\u30e9\u30fc\u3068\u89e3\u6c7a\u65b9\u6cd5","text":""},{"location":"developer/type_checking/#1-any","title":"1. Any\u578b\u306e\u4f7f\u7528","text":"<pre><code># \u554f\u984c\u306e\u3042\u308b\u30b3\u30fc\u30c9\ndef process(data: Any) -&gt; Any:\n    return data\n\n# \u6539\u5584\u3055\u308c\u305f\u30b3\u30fc\u30c9\nfrom typing import TypeVar\n\nT = TypeVar('T')\n\ndef process(data: T) -&gt; T:\n    \"\"\"\n    Process data preserving type\n    \u578b\u3092\u4fdd\u6301\u3057\u3066\u30c7\u30fc\u30bf\u3092\u51e6\u7406\n    \"\"\"\n    return data\n</code></pre>"},{"location":"developer/type_checking/#2-optional","title":"2. Optional\u578b\u306e\u51e6\u7406","text":"<pre><code>from typing import Optional\n\ndef get_value() -&gt; Optional[str]:\n    \"\"\"Get optional value / \u30aa\u30d7\u30b7\u30e7\u30ca\u30eb\u5024\u3092\u53d6\u5f97\"\"\"\n    return None\n\n# \u554f\u984c\u306e\u3042\u308b\u30b3\u30fc\u30c9\nvalue = get_value()\nlength = len(value)  # Error: value might be None\n\n# \u6539\u5584\u3055\u308c\u305f\u30b3\u30fc\u30c9\nvalue = get_value()\nif value is not None:\n    length = len(value)  # OK\n\n# \u307e\u305f\u306f\nlength = len(value) if value else 0\n</code></pre>"},{"location":"developer/type_checking/#3","title":"3. \u8f9e\u66f8\u306e\u578b\u30d2\u30f3\u30c8","text":"<pre><code>from typing import Dict, Any, TypedDict\n\n# \u7de9\u3044\u578b\u4ed8\u3051\nconfig: Dict[str, Any] = {\"key\": \"value\"}\n\n# \u53b3\u5bc6\u306a\u578b\u4ed8\u3051\nclass Config(TypedDict):\n    api_key: str\n    model: str\n    temperature: float\n\nconfig: Config = {\n    \"api_key\": \"sk-...\",\n    \"model\": \"gpt-4o-mini\", \n    \"temperature\": 0.7\n}\n</code></pre>"},{"location":"developer/type_checking/#ide","title":"IDE\u7d71\u5408","text":""},{"location":"developer/type_checking/#vs-code","title":"VS Code","text":"<p><code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"python.linting.mypyEnabled\": true,\n  \"python.linting.enabled\": true,\n  \"python.linting.mypyArgs\": [\n    \"--strict\",\n    \"--show-error-codes\"\n  ]\n}\n</code></pre>"},{"location":"developer/type_checking/#pycharm","title":"PyCharm","text":"<ol> <li>Settings \u2192 Editor \u2192 Inspections \u2192 Python</li> <li>\"Type checker\" \u3067 \"Mypy\" \u3092\u9078\u629e</li> <li>\"Arguments\" \u306b <code>--strict</code> \u3092\u8ffd\u52a0</li> </ol>"},{"location":"developer/type_checking/#_14","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li>\u3059\u3079\u3066\u306e\u95a2\u6570\u306b\u578b\u30d2\u30f3\u30c8\u3092\u8ffd\u52a0</li> <li>Generic\u30af\u30e9\u30b9\u3092\u9069\u5207\u306b\u4f7f\u7528</li> <li>Protocol \u3092\u4f7f\u7528\u3057\u3066\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u5b9a\u7fa9</li> <li>TypedDict \u3092\u4f7f\u7528\u3057\u3066\u8f9e\u66f8\u306e\u69cb\u9020\u3092\u5b9a\u7fa9</li> <li>Any\u578b\u306e\u4f7f\u7528\u3092\u6700\u5c0f\u9650\u306b\u6291\u5236</li> <li>Optional\u578b\u3092\u660e\u793a\u7684\u306b\u51e6\u7406</li> </ol>"},{"location":"developer/type_checking/#_15","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"developer/type_checking/#_16","title":"\u3088\u304f\u3042\u308b\u30a8\u30e9\u30fc","text":"<pre><code># \u30a8\u30e9\u30fc: Function is missing a type annotation\ndef function(x):  # \u578b\u30d2\u30f3\u30c8\u304c\u4e0d\u8db3\n    return x\n\n# \u89e3\u6c7a\u7b56\ndef function(x: str) -&gt; str:\n    return x\n</code></pre> <pre><code># \u30a8\u30e9\u30fc: Incompatible return value type\ndef get_number() -&gt; int:\n    return \"string\"  # int\u304c\u671f\u5f85\u3055\u308c\u3066\u3044\u308b\u306e\u306bstr\u3092\u8fd4\u3057\u3066\u3044\u308b\n\n# \u89e3\u6c7a\u7b56\ndef get_number() -&gt; int:\n    return 42\n</code></pre> <p>\u3053\u306e\u30ac\u30a4\u30c9\u306b\u5f93\u3063\u3066\u3001\u578b\u5b89\u5168\u306a\u30b3\u30fc\u30c9\u3092\u66f8\u3044\u3066\u304f\u3060\u3055\u3044\uff01 </p>"},{"location":"tutorials/advanced/","title":"\u5fdc\u7528\u4f8b","text":"<p>\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f\u3001Agents SDK Models \u306e\u5fdc\u7528\u7684\u306a\u4f7f\u3044\u65b9\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002</p>"},{"location":"tutorials/advanced/#0-flow","title":"0. \u65b0\u3057\u3044Flow\u4f5c\u6210\u65b9\u6cd5\uff08\u8d85\u91cd\u8981\uff01\uff09","text":"<p>\u65b0\u3057\u3044 Flow \u306f3\u3064\u306e\u65b9\u6cd5\u3067\u4f5c\u6210\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>from agents_sdk_models import create_simple_gen_agent, Flow, DebugStep\n\n# 1. \u5358\u4e00\u30b9\u30c6\u30c3\u30d7\uff08\u6700\u3082\u30b7\u30f3\u30d7\u30eb\uff01\uff09\ngen_agent = create_simple_gen_agent(\"writer\", \"\u6587\u7ae0\u3092\u66f8\u3044\u3066\u304f\u3060\u3055\u3044\", \"gpt-4o-mini\")\nflow = Flow(steps=gen_agent)\n\n# 2. \u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30b9\u30c6\u30c3\u30d7\uff08\u81ea\u52d5\u63a5\u7d9a\uff01\uff09\ndebug_step = DebugStep(\"debug\", \"\u51e6\u7406\u5b8c\u4e86\")\nflow = Flow(steps=[gen_agent, debug_step])  # gen_agent \u2192 debug_step\n\n# 3. \u5f93\u6765\u65b9\u5f0f\uff08\u8907\u96d1\u306a\u30d5\u30ed\u30fc\u7528\uff09\nflow = Flow(\n    start=\"writer\",\n    steps={\n        \"writer\": gen_agent,\n        \"debug\": debug_step\n    }\n)\n\n# \u5b9f\u884c\u306f\u5168\u3066\u540c\u3058\nresult = await flow.run(input_data=\"AI\u306b\u3064\u3044\u3066\u66f8\u3044\u3066\")\nprint(result.shared_state[\"writer_result\"])\n</code></pre>"},{"location":"tutorials/advanced/#1","title":"1. \u30c4\u30fc\u30eb\u9023\u643a\uff08\u65b0\u63a8\u5968\u65b9\u6cd5\uff09","text":"<pre><code>from agents import function_tool\nfrom agents_sdk_models import create_simple_gen_agent, Flow\n\n@function_tool\ndef get_weather(location: str) -&gt; str:\n    return f\"Weather in {location}: Sunny, 25\u00b0C\"\n\n# GenAgent + Flow\u65b9\u5f0f\uff08\u63a8\u5968\uff09\nweather_agent = create_simple_gen_agent(\n    name=\"weather_bot\",\n    instructions=\"\"\"\n    \u3042\u306a\u305f\u306f\u5929\u6c17\u60c5\u5831\u3092\u63d0\u4f9b\u3059\u308b\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\u5fc5\u8981\u306b\u5fdc\u3058\u3066get_weather\u30c4\u30fc\u30eb\u3092\u4f7f\u3063\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    model=\"gpt-4o-mini\",\n    generation_tools=[get_weather]\n)\n\nflow = Flow(steps=weather_agent)  # \u8d85\u30b7\u30f3\u30d7\u30eb\uff01\nresult = await flow.run(input_data=\"\u6771\u4eac\u306e\u5929\u6c17\u306f\uff1f\")\nprint(result.shared_state[\"weather_bot_result\"])\n</code></pre>"},{"location":"tutorials/advanced/#_2","title":"\u65e7\u65b9\u5f0f\uff08\u975e\u63a8\u5968\uff09","text":"<pre><code># AgentPipeline\uff08v0.1.0\u3067\u524a\u9664\u4e88\u5b9a\uff09\nfrom agents_sdk_models import AgentPipeline\npipeline = AgentPipeline(\n    name=\"tool_example\",\n    generation_instructions=\"\u5929\u6c17\u60c5\u5831\u3092\u63d0\u4f9b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    generation_tools=[get_weather]\n)\nresult = pipeline.run(\"\u6771\u4eac\u306e\u5929\u6c17\u306f\uff1f\")\nprint(result)\n</code></pre>"},{"location":"tutorials/advanced/#2","title":"2. \u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\uff08\u5165\u529b\u5236\u5fa1\uff09","text":"<pre><code>from agents import input_guardrail, GuardrailFunctionOutput, Runner, RunContextWrapper, Agent\nfrom agents_sdk_models import AgentPipeline\nfrom pydantic import BaseModel\n\nclass MathCheck(BaseModel):\n    is_math: bool\n    reason: str\n\nguardrail_agent = Agent(\n    name=\"math_check\",\n    instructions=\"\u6570\u5b66\u306e\u5bbf\u984c\u304b\u5224\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    output_type=MathCheck\n)\n\n@input_guardrail\nasync def math_guardrail(ctx: RunContextWrapper, agent: Agent, input: str):\n    result = await Runner.run(guardrail_agent, input, context=ctx.context)\n    return GuardrailFunctionOutput(\n        output_info=result.final_output,\n        tripwire_triggered=result.final_output.is_math,\n    )\n\npipeline = AgentPipeline(\n    name=\"guardrail_example\",\n    generation_instructions=\"\u8cea\u554f\u306b\u7b54\u3048\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    input_guardrails=[math_guardrail]\n)\ntry:\n    result = pipeline.run(\"2x+3=11\u3092\u89e3\u3044\u3066\")\n    print(result)\nexcept Exception:\n    print(\"\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u767a\u52d5: \u6570\u5b66\u306e\u5bbf\u984c\u4f9d\u983c\u3092\u691c\u51fa\")\n</code></pre>"},{"location":"tutorials/advanced/#3","title":"3. \u30c0\u30a4\u30ca\u30df\u30c3\u30af\u30d7\u30ed\u30f3\u30d7\u30c8","text":"<pre><code>def dynamic_prompt(user_input: str) -&gt; str:\n    return f\"[DYNAMIC] {user_input.upper()}\"\n\npipeline = AgentPipeline(\n    name=\"dynamic_example\",\n    generation_instructions=\"\u30ea\u30af\u30a8\u30b9\u30c8\u306b\u7b54\u3048\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    dynamic_prompt=dynamic_prompt\n)\nresult = pipeline.run(\"\u9762\u767d\u3044\u8a71\u3092\u3057\u3066\")\nprint(result)\n</code></pre>"},{"location":"tutorials/advanced/#4","title":"4. \u30ea\u30c8\u30e9\u30a4\uff06\u81ea\u5df1\u6539\u5584\uff08\u65b0\u63a8\u5968\u65b9\u6cd5\uff09","text":"<pre><code>from agents_sdk_models import create_evaluated_gen_agent, Flow\n\n# \u8a55\u4fa1\u4ed8\u304dGenAgent + Flow\u65b9\u5f0f\uff08\u63a8\u5968\uff09\nsmart_agent = create_evaluated_gen_agent(\n    name=\"smart_writer\",\n    generation_instructions=\"\u6587\u7ae0\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    evaluation_instructions=\"\u5206\u304b\u308a\u3084\u3059\u3055\u3067\u8a55\u4fa1\u3057\u3001\u30b3\u30e1\u30f3\u30c8\u3082\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    threshold=80,\n    retries=2\n)\n\nflow = Flow(steps=smart_agent)  # \u81ea\u52d5\u3067\u30ea\u30c8\u30e9\u30a4\uff06\u81ea\u5df1\u6539\u5584\uff01\nresult = await flow.run(input_data=\"AI\u306e\u6b74\u53f2\u3092\u6559\u3048\u3066\")\nprint(result.shared_state[\"smart_writer_result\"])\n</code></pre>"},{"location":"tutorials/advanced/#_3","title":"\u65e7\u65b9\u5f0f\uff08\u975e\u63a8\u5968\uff09","text":"<pre><code># AgentPipeline\uff08v0.1.0\u3067\u524a\u9664\u4e88\u5b9a\uff09\npipeline = AgentPipeline(\n    name=\"retry_example\",\n    generation_instructions=\"\u6587\u7ae0\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    evaluation_instructions=\"\u5206\u304b\u308a\u3084\u3059\u3055\u3067\u8a55\u4fa1\u3057\u3001\u30b3\u30e1\u30f3\u30c8\u3082\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    threshold=80,\n    retries=2\n)\nresult = pipeline.run(\"AI\u306e\u6b74\u53f2\u3092\u6559\u3048\u3066\")\nprint(result)\n</code></pre>"},{"location":"tutorials/advanced/#5","title":"5. \u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\uff08\u30de\u30eb\u30c1\u30b9\u30c6\u30c3\u30d7\uff09","text":"<pre><code>from agents_sdk_models import (\n    create_simple_gen_agent, create_evaluated_gen_agent, \n    Flow, DebugStep, UserInputStep, ConditionStep\n)\n\n# \u8907\u6570\u306eGenAgent\u3092\u7d44\u307f\u5408\u308f\u305b\nidea_generator = create_simple_gen_agent(\n    name=\"idea_gen\", \n    instructions=\"\u5275\u9020\u7684\u306a\u30a2\u30a4\u30c7\u30a2\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\", \n    model=\"gpt-4o-mini\"\n)\n\ncontent_writer = create_evaluated_gen_agent(\n    name=\"writer\",\n    generation_instructions=\"\u63d0\u4f9b\u3055\u308c\u305f\u30a2\u30a4\u30c7\u30a2\u3092\u57fa\u306b\u8a73\u7d30\u306a\u8a18\u4e8b\u3092\u66f8\u3044\u3066\u304f\u3060\u3055\u3044\",\n    evaluation_instructions=\"\u8a18\u4e8b\u306e\u8cea\u3092\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\",\n    model=\"gpt-4o\",\n    threshold=75\n)\n\nreviewer = create_simple_gen_agent(\n    name=\"reviewer\",\n    instructions=\"\u8a18\u4e8b\u3092\u30ec\u30d3\u30e5\u30fc\u3057\u3066\u6539\u5584\u63d0\u6848\u3092\u3057\u3066\u304f\u3060\u3055\u3044\",\n    model=\"claude-3-5-sonnet-latest\"\n)\n\n# \u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\uff08\u81ea\u52d5\u63a5\u7d9a\uff01\uff09\nflow = Flow(steps=[\n    idea_generator,      # \u30a2\u30a4\u30c7\u30a2\u751f\u6210\n    content_writer,      # \u8a18\u4e8b\u57f7\u7b46\uff08\u8a55\u4fa1\u4ed8\u304d\uff09\n    reviewer,           # \u30ec\u30d3\u30e5\u30fc\n    DebugStep(\"done\", \"\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u5b8c\u4e86\")\n])\n\nresult = await flow.run(input_data=\"AI\u6280\u8853\u306b\u3064\u3044\u3066\")\nprint(\"\u30a2\u30a4\u30c7\u30a2:\", result.shared_state[\"idea_gen_result\"])\nprint(\"\u8a18\u4e8b:\", result.shared_state[\"writer_result\"])\nprint(\"\u30ec\u30d3\u30e5\u30fc:\", result.shared_state[\"reviewer_result\"])\n</code></pre>"},{"location":"tutorials/advanced/#6","title":"6. \u6761\u4ef6\u5206\u5c90\u4ed8\u304d\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":"<pre><code># \u6761\u4ef6\u306b\u5fdc\u3058\u3066\u7570\u306a\u308b\u51e6\u7406\u30d1\u30b9\u3092\u5b9f\u884c\ndef check_content_type(ctx):\n    user_input = ctx.last_user_input or \"\"\n    return \"\u6280\u8853\" in user_input\n\ntech_writer = create_simple_gen_agent(\"tech\", \"\u6280\u8853\u8a18\u4e8b\u3092\u66f8\u304f\", \"gpt-4o\")\ngeneral_writer = create_simple_gen_agent(\"general\", \"\u4e00\u822c\u8a18\u4e8b\u3092\u66f8\u304f\", \"gpt-4o-mini\")\n\n# \u5f93\u6765\u65b9\u5f0f\uff08\u8907\u96d1\u306a\u30d5\u30ed\u30fc\u7528\uff09\ncomplex_flow = Flow(\n    start=\"check_type\",\n    steps={\n        \"check_type\": ConditionStep(\n            \"check_type\", \n            check_content_type, \n            \"tech_writer\", \n            \"general_writer\"\n        ),\n        \"tech_writer\": tech_writer,\n        \"general_writer\": general_writer,\n        \"review\": create_simple_gen_agent(\"reviewer\", \"\u8a18\u4e8b\u3092\u30ec\u30d3\u30e5\u30fc\", \"claude-3-5-sonnet-latest\")\n    }\n)\n\nresult = await complex_flow.run(input_data=\"\u6280\u8853\u7684\u306a\u5185\u5bb9\u306b\u3064\u3044\u3066\u66f8\u3044\u3066\")\n</code></pre>"},{"location":"tutorials/advanced/#_4","title":"\u30dd\u30a4\u30f3\u30c8","text":"<ul> <li>\u65b0\u6a5f\u80fd\uff1a <code>Flow(steps=[step1, step2])</code> \u3067\u81ea\u52d5\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u63a5\u7d9a</li> <li>\u65b0\u6a5f\u80fd\uff1a <code>Flow(steps=single_step)</code> \u3067\u5358\u4e00\u30b9\u30c6\u30c3\u30d7\u3082\u8d85\u30b7\u30f3\u30d7\u30eb</li> <li>\u30c4\u30fc\u30eb\u3084\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u3001\u52d5\u7684\u30d7\u30ed\u30f3\u30d7\u30c8\u3001\u81ea\u5df1\u6539\u5584\u3092\u67d4\u8edf\u306b\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd</li> <li>\u65e7 <code>AgentPipeline</code> \u304b\u3089 <code>GenAgent + Flow</code> \u3078\u306e\u79fb\u884c\u306f\u7c21\u5358</li> <li>\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3082\u6570\u884c\u3067\u69cb\u7bc9\u53ef\u80fd</li> </ul>"},{"location":"tutorials/context_management/","title":"Context Management Tutorial","text":"<p>This tutorial provides a step-by-step guide to using Refinire's context management features.</p>"},{"location":"tutorials/context_management/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Basic Concepts</li> <li>Basic Usage</li> <li>Context Provider Types</li> <li>Advanced Configuration</li> <li>Practical Examples</li> <li>Best Practices</li> </ol>"},{"location":"tutorials/context_management/#basic-concepts","title":"Basic Concepts","text":"<p>Context management is a system that automatically provides AI agents with the information they need to generate more appropriate responses.</p>"},{"location":"tutorials/context_management/#key-features","title":"Key Features","text":"<ul> <li>Conversation History Management: Properly maintain and manage past conversations</li> <li>File Context: Automatically provide content from relevant files</li> <li>Source Code Search: Automatically search for code related to user questions</li> <li>Context Compression: Compress long contexts to appropriate sizes</li> <li>Dynamic Selection: Select optimal context based on the situation</li> </ul>"},{"location":"tutorials/context_management/#basic-usage","title":"Basic Usage","text":""},{"location":"tutorials/context_management/#1-simple-configuration","title":"1. Simple Configuration","text":"<pre><code>from refinire.agents.pipeline import RefinireAgent\n\n# Basic context configuration\ncontext_config = [\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 5,\n        \"max_tokens\": 1000\n    }\n]\n\nagent = RefinireAgent(\n    model=\"gpt-3.5-turbo\",\n    context_providers_config=context_config\n)\n</code></pre>"},{"location":"tutorials/context_management/#2-using-multiple-providers","title":"2. Using Multiple Providers","text":"<pre><code>context_config = [\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 5\n    },\n    {\n        \"type\": \"fixed_file\",\n        \"file_path\": \"README.md\"\n    },\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 3,\n        \"max_file_size\": 500\n    }\n]\n</code></pre>"},{"location":"tutorials/context_management/#context-provider-types","title":"Context Provider Types","text":""},{"location":"tutorials/context_management/#1-conversationhistoryprovider","title":"1. ConversationHistoryProvider","text":"<p>Manages conversation history.</p> <pre><code>{\n    \"type\": \"conversation_history\",\n    \"max_items\": 10        # Number of messages to keep\n}\n</code></pre>"},{"location":"tutorials/context_management/#2-fixedfileprovider","title":"2. FixedFileProvider","text":"<p>Always provides content from specified files.</p> <pre><code>{\n    \"type\": \"fixed_file\",\n    \"file_path\": \"config.yaml\"\n}\n</code></pre>"},{"location":"tutorials/context_management/#3-sourcecodeprovider","title":"3. SourceCodeProvider","text":"<p>Automatically searches for source code related to user questions.</p> <pre><code>{\n    \"type\": \"source_code\",\n    \"max_files\": 5,                    # Maximum number of files\n    \"max_file_size\": 1000              # Maximum file size in bytes\n}\n</code></pre>"},{"location":"tutorials/context_management/#4-cutcontextprovider","title":"4. CutContextProvider","text":"<p>Compresses context to specified length.</p> <pre><code>{\n    \"type\": \"cut_context\",\n    \"provider\": {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    \"max_chars\": 3000,           # Maximum character count\n    \"cut_strategy\": \"middle\",     # Compression strategy (start/end/middle)\n    \"preserve_sections\": True     # Preserve sections\n}\n</code></pre>"},{"location":"tutorials/context_management/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"tutorials/context_management/#1-string-based-configuration","title":"1. String-based Configuration","text":"<p>You can describe configuration using YAML-like strings.</p> <pre><code>string_config = \"\"\"\n- type: conversation_history\n  max_items: 5\n- type: source_code\n  max_files: 3\n  max_file_size: 500\n\"\"\"\n\nagent = RefinireAgent(\n    model=\"gpt-3.5-turbo\",\n    context_providers_config=string_config\n)\n</code></pre>"},{"location":"tutorials/context_management/#2-chained-processing","title":"2. Chained Processing","text":"<p>Providers can receive and process context from previous providers.</p> <pre><code>context_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    {\n        \"type\": \"cut_context\",\n        \"provider\": {\n            \"type\": \"source_code\",\n            \"max_files\": 10,\n            \"max_file_size\": 2000\n        },\n        \"max_chars\": 3000,\n        \"cut_strategy\": \"middle\"\n    }\n]\n</code></pre>"},{"location":"tutorials/context_management/#practical-examples","title":"Practical Examples","text":""},{"location":"tutorials/context_management/#1-code-review-assistance","title":"1. Code Review Assistance","text":"<pre><code>context_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    {\n        \"type\": \"fixed_file\",\n        \"file_path\": \"CONTRIBUTING.md\"\n    },\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 5\n    }\n]\n</code></pre> <p>agent = RefinireAgent(     name=\"CodeReviewAgent\",     generation_instructions=\"Review code for quality, best practices, error handling, performance, and documentation completeness.\",     model=\"gpt-4\",     context_providers_config=context_config )</p> <p>response = await agent.run_async(\"Please review the quality of this code\") <pre><code>### 2. Documentation Generation\n\n```python\ncontext_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 15,\n        \"max_file_size\": 1500\n    },\n    {\n        \"type\": \"cut_context\",\n        \"provider\": {\n            \"type\": \"source_code\",\n            \"max_files\": 15,\n            \"max_file_size\": 1500\n        },\n        \"max_chars\": 4000,\n        \"cut_strategy\": \"start\"\n    }\n]\n</code></pre></p> <p>agent = RefinireAgent(     name=\"DocGenAgent\",     generation_instructions=\"Generate comprehensive documentation based on source code and existing documentation.\",     model=\"gpt-4\",     context_providers_config=context_config )</p> <p>response = await agent.run_async(\"Generate API documentation\") <pre><code>### 3. Debugging Assistance\n\n```python\ncontext_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 8,\n        \"max_file_size\": 1000\n    },\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 10\n    }\n]\n</code></pre></p> <p>agent = RefinireAgent(     name=\"DebugAgent\",     generation_instructions=\"Help investigate and resolve errors by analyzing source code and error messages.\",     model=\"gpt-4\",     context_providers_config=context_config )</p> <p>response = await agent.run_async(\"Please investigate the cause of this error\") <pre><code>## Best Practices\n\n### 1. Provider Order\n\n1. **Information Collection Providers** (source_code, fixed_file)\n2. **Processing Providers** (cut_context, filter)\n3. **History Providers** (conversation_history)\n\n### 2. Appropriate Size Settings\n\n- **max_files**: 3-10 files\n- **max_file_size**: 500-2000 bytes\n- **max_chars**: 1000-3000 characters\n\n### 3. Error Handling\n\n```python\ntry:\n    response = await agent.run_async(\"Question\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n    # Clear context and retry\n    agent.clear_context()\n</code></pre></p>"},{"location":"tutorials/context_management/#4-performance-optimization","title":"4. Performance Optimization","text":"<ul> <li>Remove unnecessary providers</li> <li>Set appropriate size limits</li> <li>Utilize caching</li> </ul>"},{"location":"tutorials/context_management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/context_management/#common-issues","title":"Common Issues","text":"<ol> <li>File not found</li> <li>Verify file path is correct</li> <li> <p>Distinguish between relative and absolute paths</p> </li> <li> <p>Context too long</p> </li> <li>Use CutContextProvider</li> <li> <p>Adjust size limits</p> </li> <li> <p>Related files not found</p> </li> <li>Check SourceCodeProvider settings</li> <li>Adjust file name similarity</li> </ol>"},{"location":"tutorials/context_management/#debugging-methods","title":"Debugging Methods","text":"<pre><code># Check available provider schemas\nschemas = agent.get_context_provider_schemas()\nfor schema in schemas:\n    print(f\"- {schema['name']}: {schema['description']}\")\n\n# Clear context\nagent.clear_context()\n</code></pre>"},{"location":"tutorials/context_management/#next-steps","title":"Next Steps","text":"<ul> <li>Check detailed specifications in the API Reference</li> <li>Reference actual code in the Examples</li> <li>Understand the overall system in the Architecture Design </li> </ul>"},{"location":"tutorials/context_management_ja/","title":"\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u6a5f\u80fd\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb","text":"<p>\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f\u3001Refinire\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u6a5f\u80fd\u306e\u4f7f\u7528\u65b9\u6cd5\u3092\u6bb5\u968e\u7684\u306b\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"tutorials/context_management_ja/#_2","title":"\u76ee\u6b21","text":"<ol> <li>\u57fa\u672c\u6982\u5ff5</li> <li>\u57fa\u672c\u7684\u306a\u4f7f\u7528\u65b9\u6cd5</li> <li>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u7a2e\u985e</li> <li>\u9ad8\u5ea6\u306a\u8a2d\u5b9a</li> <li>\u5b9f\u7528\u7684\u306a\u4f8b</li> <li>\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9</li> </ol>"},{"location":"tutorials/context_management_ja/#_3","title":"\u57fa\u672c\u6982\u5ff5","text":"<p>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u7ba1\u7406\u6a5f\u80fd\u306f\u3001AI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u3088\u308a\u9069\u5207\u306a\u5fdc\u7b54\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u81ea\u52d5\u7684\u306b\u63d0\u4f9b\u3059\u308b\u30b7\u30b9\u30c6\u30e0\u3067\u3059\u3002</p>"},{"location":"tutorials/context_management_ja/#_4","title":"\u4e3b\u306a\u7279\u5fb4","text":"<ul> <li>\u4f1a\u8a71\u5c65\u6b74\u306e\u7ba1\u7406: \u904e\u53bb\u306e\u5bfe\u8a71\u3092\u9069\u5207\u306b\u4fdd\u6301\u30fb\u7ba1\u7406</li> <li>\u30d5\u30a1\u30a4\u30eb\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8: \u95a2\u9023\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u3092\u81ea\u52d5\u7684\u306b\u63d0\u4f9b</li> <li>\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u691c\u7d22: \u30e6\u30fc\u30b6\u30fc\u306e\u8cea\u554f\u306b\u95a2\u9023\u3059\u308b\u30b3\u30fc\u30c9\u3092\u81ea\u52d5\u691c\u7d22</li> <li>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u5727\u7e2e: \u9577\u3044\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u9069\u5207\u306a\u30b5\u30a4\u30ba\u306b\u5727\u7e2e</li> <li>\u52d5\u7684\u9078\u629e: \u72b6\u6cc1\u306b\u5fdc\u3058\u3066\u6700\u9069\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u9078\u629e</li> </ul>"},{"location":"tutorials/context_management_ja/#_5","title":"\u57fa\u672c\u7684\u306a\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"tutorials/context_management_ja/#1","title":"1. \u30b7\u30f3\u30d7\u30eb\u306a\u8a2d\u5b9a","text":"<pre><code>from refinire.agents.pipeline import RefinireAgent\n\n# \u57fa\u672c\u7684\u306a\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u8a2d\u5b9a\ncontext_config = [\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 5,\n        \"max_tokens\": 1000\n    }\n]\n\nagent = RefinireAgent(\n    model=\"gpt-3.5-turbo\",\n    context_providers_config=context_config\n)\n</code></pre>"},{"location":"tutorials/context_management_ja/#2","title":"2. \u8907\u6570\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u4f7f\u7528","text":"<pre><code>context_config = [\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 5\n    },\n    {\n        \"type\": \"fixed_file\",\n        \"file_path\": \"README.md\"\n    },\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 3,\n        \"max_file_size\": 500\n    }\n]\n</code></pre>"},{"location":"tutorials/context_management_ja/#_6","title":"\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u7a2e\u985e","text":""},{"location":"tutorials/context_management_ja/#1-conversationhistoryprovider","title":"1. ConversationHistoryProvider","text":"<p>\u4f1a\u8a71\u5c65\u6b74\u3092\u7ba1\u7406\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <pre><code>{\n    \"type\": \"conversation_history\",\n    \"max_items\": 10        # \u4fdd\u6301\u3059\u308b\u30e1\u30c3\u30bb\u30fc\u30b8\u6570\n}\n</code></pre>"},{"location":"tutorials/context_management_ja/#2-fixedfileprovider","title":"2. FixedFileProvider","text":"<p>\u6307\u5b9a\u3055\u308c\u305f\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u3092\u5e38\u306b\u63d0\u4f9b\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <pre><code>{\n    \"type\": \"fixed_file\",\n    \"file_path\": \"config.yaml\"\n}\n</code></pre>"},{"location":"tutorials/context_management_ja/#3-sourcecodeprovider","title":"3. SourceCodeProvider","text":"<p>\u30e6\u30fc\u30b6\u30fc\u306e\u8cea\u554f\u306b\u95a2\u9023\u3059\u308b\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u81ea\u52d5\u691c\u7d22\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <pre><code>{\n    \"type\": \"source_code\",\n    \"max_files\": 5,                    # \u6700\u5927\u30d5\u30a1\u30a4\u30eb\u6570\n    \"max_file_size\": 1000              # \u30d5\u30a1\u30a4\u30eb\u3042\u305f\u308a\u306e\u6700\u5927\u30b5\u30a4\u30ba\uff08\u30d0\u30a4\u30c8\uff09\n}\n</code></pre>"},{"location":"tutorials/context_management_ja/#4-cutcontextprovider","title":"4. CutContextProvider","text":"<p>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u6307\u5b9a\u3055\u308c\u305f\u9577\u3055\u306b\u5727\u7e2e\u3059\u308b\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u3059\u3002</p> <pre><code>{\n    \"type\": \"cut_context\",\n    \"provider\": {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    \"max_chars\": 3000,           # \u6700\u5927\u6587\u5b57\u6570\n    \"cut_strategy\": \"middle\",     # \u5727\u7e2e\u6226\u7565 (start/end/middle)\n    \"preserve_sections\": True     # \u30bb\u30af\u30b7\u30e7\u30f3\u3092\u4fdd\u6301\n}\n</code></pre>"},{"location":"tutorials/context_management_ja/#_7","title":"\u9ad8\u5ea6\u306a\u8a2d\u5b9a","text":""},{"location":"tutorials/context_management_ja/#1_1","title":"1. \u6587\u5b57\u5217\u30d9\u30fc\u30b9\u8a2d\u5b9a","text":"<p>YAML\u30e9\u30a4\u30af\u306a\u6587\u5b57\u5217\u3067\u8a2d\u5b9a\u3092\u8a18\u8ff0\u3067\u304d\u307e\u3059\u3002</p> <pre><code>string_config = \"\"\"\n- type: conversation_history\n  max_items: 5\n- type: source_code\n  max_files: 3\n  max_file_size: 500\n\"\"\"\n\nagent = RefinireAgent(\n    model=\"gpt-3.5-turbo\",\n    context_providers_config=string_config\n)\n</code></pre>"},{"location":"tutorials/context_management_ja/#2_1","title":"2. \u9023\u9396\u7684\u51e6\u7406","text":"<p>\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306f\u524d\u306e\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u53d7\u3051\u53d6\u3063\u3066\u51e6\u7406\u3067\u304d\u307e\u3059\u3002</p> <pre><code>context_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    {\n        \"type\": \"cut_context\",\n        \"provider\": {\n            \"type\": \"source_code\",\n            \"max_files\": 10,\n            \"max_file_size\": 2000\n        },\n        \"max_chars\": 3000,\n        \"cut_strategy\": \"middle\"\n    }\n]\n</code></pre>"},{"location":"tutorials/context_management_ja/#_8","title":"\u5b9f\u7528\u7684\u306a\u4f8b","text":""},{"location":"tutorials/context_management_ja/#1_2","title":"1. \u30b3\u30fc\u30c9\u30ec\u30d3\u30e5\u30fc\u652f\u63f4","text":"<pre><code>context_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 10,\n        \"max_file_size\": 2000\n    },\n    {\n        \"type\": \"fixed_file\",\n        \"file_path\": \"CONTRIBUTING.md\"\n    },\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 5\n    }\n]\n</code></pre> <p>agent = RefinireAgent(     name=\"CodeReviewAgent\",     generation_instructions=\"\u30b3\u30fc\u30c9\u30ec\u30d3\u30e5\u30fc\u3092\u884c\u3044\u3001\u54c1\u8cea\u3001\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3001\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3001\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u5b8c\u5168\u6027\u3092\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",     model=\"gpt-4\",     context_providers_config=context_config )</p> <p>response = await agent.run_async(\"\u3053\u306e\u30b3\u30fc\u30c9\u306e\u54c1\u8cea\u3092\u30ec\u30d3\u30e5\u30fc\u3057\u3066\u304f\u3060\u3055\u3044\") <pre><code>### 2. \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u751f\u6210\n\n```python\ncontext_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 15,\n        \"max_file_size\": 1500\n    },\n    {\n        \"type\": \"cut_context\",\n        \"provider\": {\n            \"type\": \"source_code\",\n            \"max_files\": 15,\n            \"max_file_size\": 1500\n        },\n        \"max_chars\": 4000,\n        \"cut_strategy\": \"start\"\n    }\n]\n</code></pre></p> <p>agent = RefinireAgent(     name=\"DocGenAgent\",     generation_instructions=\"\u63d0\u4f9b\u3055\u308c\u305f\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3068\u65e2\u5b58\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u57fa\u3065\u3044\u3066\u3001\u5305\u62ec\u7684\u3067\u69cb\u9020\u5316\u3055\u308c\u305f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",     model=\"gpt-4\",     context_providers_config=context_config )</p> <p>response = await agent.run_async(\"API\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\") <pre><code>### 3. \u30c7\u30d0\u30c3\u30b0\u652f\u63f4\n\n```python\ncontext_config = [\n    {\n        \"type\": \"source_code\",\n        \"max_files\": 8,\n        \"max_file_size\": 1000\n    },\n    {\n        \"type\": \"conversation_history\",\n        \"max_items\": 10\n    }\n]\n</code></pre></p> <p>agent = RefinireAgent(     name=\"DebugAgent\",     generation_instructions=\"\u30a8\u30e9\u30fc\u306e\u539f\u56e0\u3092\u8abf\u67fb\u3057\u3001\u89e3\u6c7a\u7b56\u3092\u63d0\u4f9b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",     model=\"gpt-4\",     context_providers_config=context_config )</p> <p>response = await agent.run_async(\"\u3053\u306e\u30a8\u30e9\u30fc\u306e\u539f\u56e0\u3092\u8abf\u3079\u3066\u304f\u3060\u3055\u3044\") <pre><code>## \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\n\n### 1. \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u9806\u5e8f\n\n1. **\u60c5\u5831\u53ce\u96c6\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc** (source_code, fixed_file)\n2. **\u51e6\u7406\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc** (cut_context, filter)\n3. **\u5c65\u6b74\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc** (conversation_history)\n\n### 2. \u9069\u5207\u306a\u30b5\u30a4\u30ba\u8a2d\u5b9a\n\n- **max_files**: 3-10\u500b\u7a0b\u5ea6\n- **max_file_size**: 500-2000\u30d0\u30a4\u30c8\u7a0b\u5ea6\n- **max_chars**: 1000-3000\u6587\u5b57\u7a0b\u5ea6\n\n### 3. \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\n\n```python\ntry:\n    response = await agent.run_async(\"\u8cea\u554f\")\nexcept Exception as e:\n    print(f\"\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u307e\u3057\u305f: {e}\")\n    # \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u30af\u30ea\u30a2\u3057\u3066\u518d\u8a66\u884c\n    agent.clear_context()\n</code></pre></p>"},{"location":"tutorials/context_management_ja/#4","title":"4. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316","text":"<ul> <li>\u4e0d\u8981\u306a\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306f\u524a\u9664</li> <li>\u9069\u5207\u306a\u30b5\u30a4\u30ba\u5236\u9650\u3092\u8a2d\u5b9a</li> <li>\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u6d3b\u7528</li> </ul>"},{"location":"tutorials/context_management_ja/#_9","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"tutorials/context_management_ja/#_10","title":"\u3088\u304f\u3042\u308b\u554f\u984c","text":"<ol> <li>\u30d5\u30a1\u30a4\u30eb\u304c\u898b\u3064\u304b\u3089\u306a\u3044</li> <li>\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u304c\u6b63\u3057\u3044\u304b\u78ba\u8a8d</li> <li> <p>\u76f8\u5bfe\u30d1\u30b9\u3068\u7d76\u5bfe\u30d1\u30b9\u306e\u4f7f\u3044\u5206\u3051</p> </li> <li> <p>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304c\u9577\u3059\u304e\u308b</p> </li> <li>CutContextProvider\u3092\u4f7f\u7528</li> <li> <p>\u30b5\u30a4\u30ba\u5236\u9650\u3092\u8abf\u6574</p> </li> <li> <p>\u95a2\u9023\u30d5\u30a1\u30a4\u30eb\u304c\u691c\u7d22\u3055\u308c\u306a\u3044</p> </li> <li>SourceCodeProvider\u306e\u8a2d\u5b9a\u3092\u78ba\u8a8d</li> <li>\u30d5\u30a1\u30a4\u30eb\u540d\u306e\u985e\u4f3c\u6027\u3092\u8abf\u6574</li> </ol>"},{"location":"tutorials/context_management_ja/#_11","title":"\u30c7\u30d0\u30c3\u30b0\u65b9\u6cd5","text":"<pre><code># \u5229\u7528\u53ef\u80fd\u306a\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b9\u30ad\u30fc\u30de\u3092\u78ba\u8a8d\nschemas = agent.get_context_provider_schemas()\nfor schema in schemas:\n    print(f\"- {schema['name']}: {schema['description']}\")\n\n# \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u30af\u30ea\u30a2\nagent.clear_context()\n</code></pre>"},{"location":"tutorials/context_management_ja/#_12","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ul> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u3067\u8a73\u7d30\u306a\u4ed5\u69d8\u3092\u78ba\u8a8d</li> <li>\u4f7f\u7528\u4f8b\u3067\u5b9f\u969b\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u8003</li> <li>\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u8a2d\u8a08\u66f8\u3067\u30b7\u30b9\u30c6\u30e0\u5168\u4f53\u3092\u7406\u89e3 </li> </ul>"},{"location":"tutorials/doctest_examples/","title":"Doctest \u306e\u4f8b","text":"<p>\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u3001agents-sdk-models\u3067\u4f7f\u7528\u3055\u308c\u3066\u3044\u308bdoctest\u306e\u4f8b\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002</p>"},{"location":"tutorials/doctest_examples/#doctest_1","title":"Doctest\u3068\u306f","text":"<p>Doctest\u306f\u3001Python\u306edocstring\u5185\u306b\u8a18\u8ff0\u3055\u308c\u305f\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u306aPython\u30bb\u30c3\u30b7\u30e7\u30f3\u306e\u4f8b\u3092\u30c6\u30b9\u30c8\u3068\u3057\u3066\u5b9f\u884c\u3059\u308b\u6a5f\u80fd\u3067\u3059\u3002</p>"},{"location":"tutorials/doctest_examples/#_1","title":"\u57fa\u672c\u7684\u306a\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"tutorials/doctest_examples/#1","title":"1. \u30b7\u30f3\u30d7\u30eb\u306a\u4f8b","text":"<pre><code>def add(a: int, b: int) -&gt; int:\n    \"\"\"\n    Add two numbers\n    \u4e8c\u3064\u306e\u6570\u3092\u8db3\u3057\u7b97\u3057\u307e\u3059\n\n    Args:\n        a: First number / \u6700\u521d\u306e\u6570\n        b: Second number / \u4e8c\u756a\u76ee\u306e\u6570\n\n    Returns:\n        Sum of a and b / a\u3068b\u306e\u5408\u8a08\n\n    Examples:\n        &gt;&gt;&gt; add(2, 3)\n        5\n        &gt;&gt;&gt; add(-1, 1)\n        0\n    \"\"\"\n    return a + b\n</code></pre>"},{"location":"tutorials/doctest_examples/#2","title":"2. \u578b\u30c1\u30a7\u30c3\u30af\u306e\u4f8b","text":"<pre><code>def create_basic_llm() -&gt; LLM:\n    \"\"\"\n    Create a basic LLM instance\n    \u57fa\u672c\u7684\u306aLLM\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3059\n\n    Returns:\n        LLM: Configured LLM instance\n        LLM: \u8a2d\u5b9a\u3055\u308c\u305fLLM\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n\n    Examples:\n        &gt;&gt;&gt; llm = create_basic_llm()\n        &gt;&gt;&gt; isinstance(llm, LLM)\n        True\n        &gt;&gt;&gt; llm.provider\n        'openai'\n        &gt;&gt;&gt; llm.model\n        'gpt-4o-mini'\n    \"\"\"\n    return LLM(provider=\"openai\", model=\"gpt-4o-mini\")\n</code></pre>"},{"location":"tutorials/doctest_examples/#3","title":"3. \u4f8b\u5916\u51e6\u7406\u306e\u4f8b","text":"<pre><code>def safe_divide(a: float, b: float) -&gt; float:\n    \"\"\"\n    Safely divide two numbers\n    \u5b89\u5168\u306b\u4e8c\u3064\u306e\u6570\u3092\u5272\u308a\u7b97\u3057\u307e\u3059\n\n    Args:\n        a: Dividend / \u88ab\u9664\u6570\n        b: Divisor / \u9664\u6570\n\n    Returns:\n        Result of a / b / a \u00f7 b \u306e\u7d50\u679c\n\n    Raises:\n        ValueError: When b is zero / b\u304c0\u306e\u5834\u5408\n\n    Examples:\n        &gt;&gt;&gt; safe_divide(10, 2)\n        5.0\n        &gt;&gt;&gt; safe_divide(7, 3)  # doctest: +ELLIPSIS\n        2.333...\n        &gt;&gt;&gt; safe_divide(1, 0)  # doctest: +IGNORE_EXCEPTION_DETAIL\n        Traceback (most recent call last):\n            ...\n        ValueError: Cannot divide by zero\n    \"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n</code></pre>"},{"location":"tutorials/doctest_examples/#api","title":"API\u547c\u3073\u51fa\u3057\u3092\u542b\u3080\u4f8b","text":"<p>API\u30ad\u30fc\u304c\u5fc5\u8981\u306a\u5834\u5408\u306f\u3001<code># doctest: +SKIP</code>\u3092\u4f7f\u7528\u3057\u307e\u3059\uff1a</p> <pre><code>def generate_text(prompt: str) -&gt; str:\n    \"\"\"\n    Generate text using OpenAI API\n    OpenAI API\u3092\u4f7f\u7528\u3057\u3066\u30c6\u30ad\u30b9\u30c8\u3092\u751f\u6210\u3057\u307e\u3059\n\n    Args:\n        prompt: Input prompt / \u5165\u529b\u30d7\u30ed\u30f3\u30d7\u30c8\n\n    Returns:\n        Generated text response / \u751f\u6210\u3055\u308c\u305f\u30c6\u30ad\u30b9\u30c8\u30ec\u30b9\u30dd\u30f3\u30b9\n\n    Examples:\n        &gt;&gt;&gt; result = generate_text(\"Hello\")  # doctest: +SKIP\n        &gt;&gt;&gt; isinstance(result, str)  # doctest: +SKIP\n        True\n        &gt;&gt;&gt; len(result) &gt; 0  # doctest: +SKIP\n        True\n    \"\"\"\n    # Implementation that calls OpenAI API\n    pass\n</code></pre>"},{"location":"tutorials/doctest_examples/#doctest_2","title":"Doctest\u306e\u5b9f\u884c\u65b9\u6cd5","text":""},{"location":"tutorials/doctest_examples/#1_1","title":"1. \u5358\u4e00\u30d5\u30a1\u30a4\u30eb\u306e\u5b9f\u884c","text":"<pre><code>python -m doctest -v your_module.py\n</code></pre>"},{"location":"tutorials/doctest_examples/#2_1","title":"2. \u8907\u6570\u30d5\u30a1\u30a4\u30eb\u306e\u5b9f\u884c","text":"<pre><code>python -m doctest -v src/agents_sdk_models/*.py\n</code></pre>"},{"location":"tutorials/doctest_examples/#3-pytest","title":"3. Pytest\u3067\u306e\u5b9f\u884c","text":"<pre><code>pytest --doctest-modules src/agents_sdk_models/\n</code></pre>"},{"location":"tutorials/doctest_examples/#doctest_3","title":"Doctest\u306e\u30aa\u30d7\u30b7\u30e7\u30f3","text":""},{"location":"tutorials/doctest_examples/#_2","title":"\u3088\u304f\u4f7f\u7528\u3055\u308c\u308b\u30aa\u30d7\u30b7\u30e7\u30f3","text":"<ul> <li><code># doctest: +SKIP</code> - \u30c6\u30b9\u30c8\u3092\u30b9\u30ad\u30c3\u30d7</li> <li><code># doctest: +ELLIPSIS</code> - <code>...</code>\u3067\u90e8\u5206\u7684\u306a\u30de\u30c3\u30c1\u3092\u8a31\u53ef</li> <li><code># doctest: +IGNORE_EXCEPTION_DETAIL</code> - \u4f8b\u5916\u306e\u8a73\u7d30\u3092\u7121\u8996</li> <li><code># doctest: +NORMALIZE_WHITESPACE</code> - \u7a7a\u767d\u6587\u5b57\u306e\u6b63\u898f\u5316</li> </ul>"},{"location":"tutorials/doctest_examples/#_3","title":"\u5b9f\u7528\u7684\u306a\u4f8b","text":"<pre><code>def process_data(data: list) -&gt; dict:\n    \"\"\"\n    Process input data and return summary\n    \u5165\u529b\u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3057\u3066\u8981\u7d04\u3092\u8fd4\u3057\u307e\u3059\n\n    Args:\n        data: List of data items / \u30c7\u30fc\u30bf\u9805\u76ee\u306e\u30ea\u30b9\u30c8\n\n    Returns:\n        Summary dictionary / \u8981\u7d04\u8f9e\u66f8\n\n    Examples:\n        &gt;&gt;&gt; data = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; result = process_data(data)\n        &gt;&gt;&gt; result['count']\n        5\n        &gt;&gt;&gt; result['sum']\n        15\n        &gt;&gt;&gt; result['average']  # doctest: +ELLIPSIS\n        3.0\n\n        \u7a7a\u306e\u30ea\u30b9\u30c8\u306e\u5834\u5408:\n        &gt;&gt;&gt; process_data([])\n        {'count': 0, 'sum': 0, 'average': 0}\n\n        \u6587\u5b57\u5217\u30c7\u30fc\u30bf\u306e\u5834\u5408:\n        &gt;&gt;&gt; process_data(['a', 'b', 'c'])  # doctest: +ELLIPSIS\n        {'count': 3, 'sum': 0, 'average': 0, 'items': [...]}\n    \"\"\"\n    if not data:\n        return {'count': 0, 'sum': 0, 'average': 0}\n\n    numeric_data = [x for x in data if isinstance(x, (int, float))]\n    count = len(data)\n    total = sum(numeric_data)\n    average = total / len(numeric_data) if numeric_data else 0\n\n    result = {\n        'count': count,\n        'sum': total,\n        'average': average\n    }\n\n    if not all(isinstance(x, (int, float)) for x in data):\n        result['items'] = data\n\n    return result\n</code></pre>"},{"location":"tutorials/doctest_examples/#ci","title":"CI\u3067\u306e\u5b9f\u884c","text":"<p>GitHub Actions\u3067doctest\u3092\u81ea\u52d5\u5b9f\u884c\u3059\u308b\u8a2d\u5b9a\uff1a</p> <pre><code>- name: Run doctests\n  run: |\n    # Run doctests for all Python files in src/\n    uv run python -m doctest -v src/agents_sdk_models/*.py\n\n    # Run doctests for minimal example\n    uv run python -m doctest -v examples/minimal/minimal_example.py\n\n    # Run doctests using pytest\n    uv run pytest --doctest-modules src/agents_sdk_models/\n</code></pre>"},{"location":"tutorials/doctest_examples/#_4","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li>\u5b9f\u884c\u53ef\u80fd\u306a\u4f8b\u3092\u63d0\u4f9b - \u5b9f\u969b\u306b\u52d5\u4f5c\u3059\u308b\u30b3\u30fc\u30c9\u3092\u66f8\u304f</li> <li>\u30a8\u30e9\u30fc\u30b1\u30fc\u30b9\u3082\u542b\u3081\u308b - \u6b63\u5e38\u7cfb\u3060\u3051\u3067\u306a\u304f\u7570\u5e38\u7cfb\u3082\u30c6\u30b9\u30c8</li> <li>\u578b\u30c1\u30a7\u30c3\u30af\u3092\u6d3b\u7528 - <code>isinstance()</code>\u3067\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u578b\u3092\u78ba\u8a8d</li> <li>API\u547c\u3073\u51fa\u3057\u306f\u30b9\u30ad\u30c3\u30d7 - \u5916\u90e8API\u3092\u4f7f\u7528\u3059\u308b\u5834\u5408\u306f<code>+SKIP</code>\u3092\u4f7f\u7528</li> <li>\u65e5\u672c\u8a9e\u30b3\u30e1\u30f3\u30c8\u3092\u4f75\u8a18 - \u82f1\u8a9e\u3068\u65e5\u672c\u8a9e\u4e21\u65b9\u3067\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u5316</li> </ol> <p>\u3053\u308c\u3089\u306e\u4f8b\u3092\u53c2\u8003\u306b\u3001\u3042\u306a\u305f\u306e\u30b3\u30fc\u30c9\u306b\u3082doctest\u3092\u8ffd\u52a0\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\uff01 </p>"},{"location":"tutorials/quickstart/","title":"Quick Start","text":"<p>This tutorial introduces minimal LLM usage examples with Refinire. You can create working AI agents in just a few minutes.</p>"},{"location":"tutorials/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9 or higher installed</li> <li>OpenAI API key configured (<code>OPENAI_API_KEY</code> environment variable)</li> </ul> <pre><code># Environment variable setup (Windows)\nset OPENAI_API_KEY=your_api_key_here\n\n# Environment variable setup (Linux/Mac)\nexport OPENAI_API_KEY=your_api_key_here\n</code></pre>"},{"location":"tutorials/quickstart/#1-getting-model-instances","title":"1. Getting Model Instances","text":"<p>Handle multiple LLM providers with a unified interface.</p> <pre><code>from refinire import get_llm\n\n# OpenAI\nllm = get_llm(\"gpt-4o-mini\")\n\n# Anthropic Claude\nllm = get_llm(\"claude-3-sonnet\")\n\n# Google Gemini\nllm = get_llm(\"gemini-pro\")\n\n# Ollama (Local LLM)\nllm = get_llm(\"llama3.1:8b\")\n</code></pre>"},{"location":"tutorials/quickstart/#2-simple-agent-creation","title":"2. Simple Agent Creation","text":"<p>Create a basic conversational agent.</p> <pre><code>from agents import Agent, Runner\nfrom refinire import get_llm\n\nllm = get_llm(\"gpt-4o-mini\")\nagent = Agent(\n    name=\"Assistant\",\n    model=llm,\n    instructions=\"You are a helpful assistant. Provide clear and understandable responses.\"\n)\n\nresult = Runner.run_sync(agent, \"Hello!\")\nprint(result.final_output)\n</code></pre>"},{"location":"tutorials/quickstart/#3-genagent-flow-for-advanced-workflows-recommended","title":"3. GenAgent + Flow for Advanced Workflows (Recommended)","text":"<p>Create advanced agents with automatic evaluation and quality improvement features.</p> <pre><code>from refinire import create_simple_gen_agent, Flow, Context\nimport asyncio\n\n# Create GenAgent with automatic evaluation\ngen_agent = create_simple_gen_agent(\n    name=\"ai_expert\",\n    instructions=\"\"\"\n    You are an AI assistant with deep expertise.\n    Generate accurate and clear content based on user requests.\n    Always provide explanations when using technical terms.\n    \"\"\",\n    evaluation_instructions=\"\"\"\n    Evaluate the generated content on a 100-point scale based on:\n    - Accuracy (40 points)\n    - Clarity (30 points)\n    - Completeness (30 points)\n\n    Provide specific improvement suggestions if any issues are found.\n    \"\"\",\n    model=\"gpt-4o-mini\",\n    threshold=75  # Regenerate if score &lt; 75\n)\n\n# Create ultra-simple Flow\nflow = Flow(steps=gen_agent)\n\n# Execute\nasync def main():\n    result = await flow.run(input_data=\"Explain the difference between machine learning and deep learning\")\n    print(\"Generated result:\")\n    print(result.shared_state[\"ai_expert_result\"])\n\n    # Check evaluation score\n    if \"ai_expert_evaluation\" in result.shared_state:\n        print(f\"\\nQuality Score: {result.shared_state['ai_expert_evaluation']}\")\n\n# Run\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/quickstart/#4-tool-enabled-agents","title":"4. Tool-Enabled Agents","text":"<p>Create agents that can use external functions.</p> <pre><code>from refinire import create_simple_gen_agent, Flow\nimport asyncio\n\ndef get_weather(city: str) -&gt; str:\n    \"\"\"Get weather for the specified city\"\"\"\n    # Return dummy data instead of calling actual API\n    return f\"Weather in {city}: Sunny, 22\u00b0C\"\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Calculate mathematical expressions\"\"\"\n    try:\n        return eval(expression)\n    except:\n        return 0.0\n\n# Tool-enabled agent\ntool_agent = create_simple_gen_agent(\n    name=\"tool_assistant\",\n    instructions=\"Answer user questions using tools when necessary.\",\n    model=\"gpt-4o-mini\",\n    tools=[get_weather, calculate]\n)\n\nflow = Flow(steps=tool_agent)\n\nasync def main():\n    result = await flow.run(input_data=\"What's the weather in Tokyo and what's 15 * 23?\")\n    print(result.shared_state[\"tool_assistant_result\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/quickstart/#5-multi-step-workflows","title":"5. Multi-Step Workflows","text":"<p>Create complex workflows combining multiple steps easily.</p> <pre><code>from refinire import Flow, FunctionStep, Context\nimport asyncio\n\ndef analyze_input(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"Analyze user input\"\"\"\n    ctx.shared_state[\"analysis\"] = f\"Analyzed input: '{user_input}'\"\n    return ctx\n\ndef generate_response(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"Generate response\"\"\"\n    analysis = ctx.shared_state.get(\"analysis\", \"\")\n    ctx.shared_state[\"response\"] = f\"Generated response based on {analysis}\"\n    ctx.finish()  # End workflow\n    return ctx\n\n# Multi-step Flow\nflow = Flow([\n    (\"analyze\", FunctionStep(\"analyze\", analyze_input)),\n    (\"respond\", FunctionStep(\"respond\", generate_response))\n])\n\nasync def main():\n    result = await flow.run(input_data=\"Tell me about AI\")\n    print(result.shared_state[\"response\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/quickstart/#6-legacy-agentpipeline-deprecated","title":"6. Legacy AgentPipeline (Deprecated)","text":"<pre><code># Warning: AgentPipeline will be removed in v0.1.0\nfrom refinire import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"eval_example\",\n    generation_instructions=\"You are a helpful assistant.\",\n    evaluation_instructions=\"Evaluate the generated text for clarity on a 100-point scale.\",\n    model=\"gpt-4o-mini\",\n    threshold=70\n)\n\nresult = pipeline.run(\"Tell me about AI use cases\")\nprint(result)\n</code></pre>"},{"location":"tutorials/quickstart/#key-points","title":"Key Points","text":""},{"location":"tutorials/quickstart/#recommended-approaches","title":"\u2705 Recommended Approaches","text":"<ul> <li><code>get_llm</code> for easy access to major LLMs</li> <li><code>GenAgent + Flow</code> for end-to-end generation, evaluation, and self-improvement</li> <li><code>Flow(steps=gen_agent)</code> makes complex workflows ultra-simple</li> <li>Automatic quality management: maintain quality with threshold settings</li> </ul>"},{"location":"tutorials/quickstart/#important-notes","title":"\u26a0\ufe0f Important Notes","text":"<ul> <li>Legacy <code>AgentPipeline</code> will be removed in v0.1.0 (migration is easy)</li> <li>Asynchronous processing (<code>asyncio</code>) is recommended</li> <li>Set API keys properly via environment variables</li> </ul>"},{"location":"tutorials/quickstart/#next-steps","title":"\ud83d\udd17 Next Steps","text":"<ul> <li>API Reference - Detailed feature documentation</li> <li>Composable Flow Architecture - Advanced workflows</li> <li>Examples - Practical use cases</li> </ul>"},{"location":"tutorials/quickstart_ja/","title":"\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8","text":"<p>\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f\u3001Refinire \u3092\u4f7f\u3063\u305f\u6700\u5c0f\u9650\u306eLLM\u6d3b\u7528\u4f8b\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\u6570\u5206\u3067\u52d5\u4f5c\u3059\u308bAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"tutorials/quickstart_ja/#_2","title":"\u524d\u63d0\u6761\u4ef6","text":"<ul> <li>Python 3.9\u4ee5\u4e0a\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u3053\u3068</li> <li>OpenAI\u306eAPI\u30ad\u30fc\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b\u3053\u3068\uff08<code>OPENAI_API_KEY</code>\u74b0\u5883\u5909\u6570\uff09</li> </ul> <pre><code># \u74b0\u5883\u5909\u6570\u306e\u8a2d\u5b9a\u4f8b\uff08Windows\uff09\nset OPENAI_API_KEY=your_api_key_here\n\n# \u74b0\u5883\u5909\u6570\u306e\u8a2d\u5b9a\u4f8b\uff08Linux/Mac\uff09\nexport OPENAI_API_KEY=your_api_key_here\n</code></pre>"},{"location":"tutorials/quickstart_ja/#1","title":"1. \u30e2\u30c7\u30eb\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e\u53d6\u5f97","text":"<p>\u8907\u6570\u306eLLM\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u7d71\u4e00\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3067\u6271\u3048\u307e\u3059\u3002</p> <pre><code>from refinire import get_llm\n\n# OpenAI\nllm = get_llm(\"gpt-4o-mini\")\n\n# Anthropic Claude\nllm = get_llm(\"claude-3-sonnet\")\n\n# Google Gemini\nllm = get_llm(\"gemini-pro\")\n\n# Ollama\uff08\u30ed\u30fc\u30ab\u30ebLLM\uff09\nllm = get_llm(\"llama3.1:8b\")\n</code></pre>"},{"location":"tutorials/quickstart_ja/#2-agent","title":"2. \u30b7\u30f3\u30d7\u30eb\u306aAgent\u4f5c\u6210","text":"<p>\u57fa\u672c\u7684\u306a\u5bfe\u8a71\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</p> <pre><code>from agents import Agent, Runner\nfrom refinire import get_llm\n\nllm = get_llm(\"gpt-4o-mini\")\nagent = Agent(\n    name=\"Assistant\",\n    model=llm,\n    instructions=\"\u3042\u306a\u305f\u306f\u89aa\u5207\u306a\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\u4e01\u5be7\u3067\u5206\u304b\u308a\u3084\u3059\u3044\u56de\u7b54\u3092\u5fc3\u304c\u3051\u3066\u304f\u3060\u3055\u3044\u3002\"\n)\n\nresult = Runner.run_sync(agent, \"\u3053\u3093\u306b\u3061\u306f\uff01\")\nprint(result.final_output)\n</code></pre>"},{"location":"tutorials/quickstart_ja/#3-genagent-flow","title":"3. GenAgent + Flow \u3067\u9ad8\u5ea6\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\uff08\u63a8\u5968\uff09","text":"<p>\u81ea\u52d5\u8a55\u4fa1\u3068\u54c1\u8cea\u5411\u4e0a\u6a5f\u80fd\u3092\u542b\u3080\u9ad8\u5ea6\u306a\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</p> <pre><code>from refinire import create_simple_gen_agent, Flow, Context\nimport asyncio\n\n# \u81ea\u52d5\u8a55\u4fa1\u6a5f\u80fd\u4ed8\u304dGenAgent\u3092\u4f5c\u6210\ngen_agent = create_simple_gen_agent(\n    name=\"ai_expert\",\n    instructions=\"\"\"\n    \u3042\u306a\u305f\u306f\u5c02\u9580\u77e5\u8b58\u8c4a\u5bcc\u306aAI\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\n    \u30e6\u30fc\u30b6\u30fc\u306e\u8981\u671b\u306b\u5fdc\u3058\u3066\u3001\u6b63\u78ba\u3067\u5206\u304b\u308a\u3084\u3059\u3044\u6587\u7ae0\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    \u5c02\u9580\u7528\u8a9e\u3092\u4f7f\u3046\u5834\u5408\u306f\u3001\u5fc5\u305a\u8aac\u660e\u3092\u4ed8\u3051\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    evaluation_instructions=\"\"\"\n    \u751f\u6210\u3055\u308c\u305f\u6587\u7ae0\u3092\u4ee5\u4e0b\u306e\u89b3\u70b9\u3067100\u70b9\u6e80\u70b9\u3067\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\uff1a\n    - \u6b63\u78ba\u6027\uff0840\u70b9\uff09\n    - \u5206\u304b\u308a\u3084\u3059\u3055\uff0830\u70b9\uff09\n    - \u5b8c\u5168\u6027\uff0830\u70b9\uff09\n\n    \u8a55\u4fa1\u3068\u3068\u3082\u306b\u6539\u5584\u70b9\u304c\u3042\u308c\u3070\u5177\u4f53\u7684\u306b\u6307\u6458\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    model=\"gpt-4o-mini\",\n    threshold=75  # 75\u70b9\u672a\u6e80\u306e\u5834\u5408\u306f\u81ea\u52d5\u3067\u518d\u751f\u6210\n)\n\n# \u8d85\u30b7\u30f3\u30d7\u30eb\u306aFlow\u3092\u4f5c\u6210\nflow = Flow(steps=gen_agent)\n\n# \u5b9f\u884c\nasync def main():\n    result = await flow.run(input_data=\"\u6a5f\u68b0\u5b66\u7fd2\u3068\u6df1\u5c64\u5b66\u7fd2\u306e\u9055\u3044\u3092\u6559\u3048\u3066\")\n    print(\"\u751f\u6210\u7d50\u679c:\")\n    print(result.shared_state[\"ai_expert_result\"])\n\n    # \u8a55\u4fa1\u30b9\u30b3\u30a2\u3082\u78ba\u8a8d\u53ef\u80fd\n    if \"ai_expert_evaluation\" in result.shared_state:\n        print(f\"\\n\u54c1\u8cea\u30b9\u30b3\u30a2: {result.shared_state['ai_expert_evaluation']}\")\n\n# \u5b9f\u884c\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/quickstart_ja/#4","title":"4. \u30c4\u30fc\u30eb\u4f7f\u7528\u53ef\u80fd\u306a\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8","text":"<p>\u5916\u90e8\u6a5f\u80fd\u3092\u4f7f\u3048\u308b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</p> <pre><code>from refinire import create_simple_gen_agent, Flow\nimport asyncio\n\ndef get_weather(city: str) -&gt; str:\n    \"\"\"\u6307\u5b9a\u3055\u308c\u305f\u90fd\u5e02\u306e\u5929\u6c17\u3092\u53d6\u5f97\u3057\u307e\u3059\"\"\"\n    # \u5b9f\u969b\u306eAPI\u3092\u547c\u3076\u4ee3\u308f\u308a\u306b\u30c0\u30df\u30fc\u30c7\u30fc\u30bf\u3092\u8fd4\u3059\n    return f\"{city}\u306e\u5929\u6c17: \u6674\u308c\u3001\u6c17\u6e2922\u5ea6\"\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"\u6570\u5f0f\u3092\u8a08\u7b97\u3057\u307e\u3059\"\"\"\n    try:\n        return eval(expression)\n    except:\n        return 0.0\n\n# \u30c4\u30fc\u30eb\u4f7f\u7528\u53ef\u80fd\u306a\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\ntool_agent = create_simple_gen_agent(\n    name=\"tool_assistant\",\n    instructions=\"\u30e6\u30fc\u30b6\u30fc\u306e\u8cea\u554f\u306b\u5bfe\u3057\u3066\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u30c4\u30fc\u30eb\u3092\u4f7f\u3063\u3066\u56de\u7b54\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    tools=[get_weather, calculate]\n)\n\nflow = Flow(steps=tool_agent)\n\nasync def main():\n    result = await flow.run(input_data=\"\u6771\u4eac\u306e\u5929\u6c17\u3068\u300115 * 23\u306e\u8a08\u7b97\u7d50\u679c\u3092\u6559\u3048\u3066\")\n    print(result.shared_state[\"tool_assistant_result\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/quickstart_ja/#5","title":"5. \u8907\u6570\u30b9\u30c6\u30c3\u30d7\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":"<p>\u8907\u6570\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u7d44\u307f\u5408\u308f\u305b\u305f\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3082\u7c21\u5358\u306b\u4f5c\u6210\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from refinire import Flow, FunctionStep, Context\nimport asyncio\n\ndef analyze_input(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u30e6\u30fc\u30b6\u30fc\u5165\u529b\u3092\u5206\u6790\"\"\"\n    ctx.shared_state[\"analysis\"] = f\"\u5165\u529b\u300c{user_input}\u300d\u3092\u5206\u6790\u3057\u307e\u3057\u305f\"\n    return ctx\n\ndef generate_response(user_input: str, ctx: Context) -&gt; Context:\n    \"\"\"\u56de\u7b54\u3092\u751f\u6210\"\"\"\n    analysis = ctx.shared_state.get(\"analysis\", \"\")\n    ctx.shared_state[\"response\"] = f\"{analysis}\u306b\u57fa\u3065\u3044\u3066\u56de\u7b54\u3092\u751f\u6210\u3057\u307e\u3057\u305f\"\n    ctx.finish()  # \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7d42\u4e86\n    return ctx\n\n# \u8907\u6570\u30b9\u30c6\u30c3\u30d7\u306eFlow\nflow = Flow([\n    (\"analyze\", FunctionStep(\"analyze\", analyze_input)),\n    (\"respond\", FunctionStep(\"respond\", generate_response))\n])\n\nasync def main():\n    result = await flow.run(input_data=\"AI\u306b\u3064\u3044\u3066\u6559\u3048\u3066\")\n    print(result.shared_state[\"response\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/quickstart_ja/#6-agentpipeline","title":"6. \u65e7AgentPipeline\uff08\u975e\u63a8\u5968\uff09","text":"<pre><code># \u6ce8\u610f\uff1aAgentPipeline\u306fv0.1.0\u3067\u524a\u9664\u4e88\u5b9a\u3067\u3059\nfrom refinire import AgentPipeline\n\npipeline = AgentPipeline(\n    name=\"eval_example\",\n    generation_instructions=\"\u3042\u306a\u305f\u306f\u5f79\u7acb\u3064\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\",\n    evaluation_instructions=\"\u751f\u6210\u3055\u308c\u305f\u6587\u7ae0\u3092\u5206\u304b\u308a\u3084\u3059\u3055\u3067100\u70b9\u6e80\u70b9\u8a55\u4fa1\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\",\n    threshold=70\n)\n\nresult = pipeline.run(\"AI\u306e\u6d3b\u7528\u4e8b\u4f8b\u3092\u6559\u3048\u3066\")\nprint(result)\n</code></pre>"},{"location":"tutorials/quickstart_ja/#_3","title":"\u91cd\u8981\u306a\u30dd\u30a4\u30f3\u30c8","text":""},{"location":"tutorials/quickstart_ja/#_4","title":"\u2705 \u63a8\u5968\u3055\u308c\u308b\u30a2\u30d7\u30ed\u30fc\u30c1","text":"<ul> <li><code>get_llm</code> \u3067\u4e3b\u8981\u306aLLM\u3092\u7c21\u5358\u53d6\u5f97</li> <li><code>GenAgent + Flow</code> \u3067\u751f\u6210\u30fb\u8a55\u4fa1\u30fb\u81ea\u5df1\u6539\u5584\u307e\u3067\u4e00\u6c17\u901a\u8cab</li> <li><code>Flow(steps=gen_agent)</code> \u3060\u3051\u3067\u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3082\u8d85\u30b7\u30f3\u30d7\u30eb\u306b\u5b9f\u73fe</li> <li>\u81ea\u52d5\u54c1\u8cea\u7ba1\u7406: threshold\u8a2d\u5b9a\u3067\u54c1\u8cea\u3092\u81ea\u52d5\u7dad\u6301</li> </ul>"},{"location":"tutorials/quickstart_ja/#_5","title":"\u26a0\ufe0f \u6ce8\u610f\u4e8b\u9805","text":"<ul> <li>\u65e7 <code>AgentPipeline</code> \u306f v0.1.0 \u3067\u524a\u9664\u4e88\u5b9a\uff08\u79fb\u884c\u306f\u7c21\u5358\u3067\u3059\uff09</li> <li>\u975e\u540c\u671f\u51e6\u7406\uff08<code>asyncio</code>\uff09\u306e\u4f7f\u7528\u3092\u63a8\u5968</li> <li>\u74b0\u5883\u5909\u6570\u3067API\u30ad\u30fc\u3092\u9069\u5207\u306b\u8a2d\u5b9a</li> </ul>"},{"location":"tutorials/quickstart_ja/#_6","title":"\ud83d\udd17 \u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ul> <li>API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 - \u8a73\u7d30\u306a\u6a5f\u80fd\u8aac\u660e</li> <li>\u7d44\u307f\u5408\u308f\u305b\u53ef\u80fd\u306a\u30d5\u30ed\u30fc\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3 - \u9ad8\u5ea6\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc</li> <li>\u30b5\u30f3\u30d7\u30eb\u96c6 - \u5b9f\u7528\u7684\u306a\u4f7f\u7528\u4f8b </li> </ul>"},{"location":"tutorials/routing_migration/","title":"\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u6a5f\u80fd\u79fb\u884c\u30ac\u30a4\u30c9","text":""},{"location":"tutorials/routing_migration/#_2","title":"\u6982\u8981","text":"<p>\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001<code>AgentPipeline</code>\u306e<code>routing_func</code>\u6a5f\u80fd\u3092<code>Flow/Step</code>\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3067\u3069\u306e\u3088\u3046\u306b\u5b9f\u73fe\u3059\u308b\u304b\u3092\u8a73\u3057\u304f\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"tutorials/routing_migration/#agentpipelinerouting_func","title":"AgentPipeline\u306erouting_func\u3068\u306f","text":"<p>AgentPipeline\u3067\u306f\u3001<code>routing_func</code>\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u751f\u6210\u7d50\u679c\u306b\u57fa\u3065\u3044\u3066\u5f8c\u7d9a\u51e6\u7406\u3092\u5236\u5fa1\u3067\u304d\u307e\u3057\u305f\uff1a</p> <pre><code>def my_routing_func(output):\n    \"\"\"\u51fa\u529b\u5185\u5bb9\u306b\u57fa\u3065\u3044\u3066\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\"\"\"\n    if \"\u7dca\u6025\" in output:\n        return f\"\ud83d\udea8 \u7dca\u6025\u5bfe\u5fdc: {output}\"\n    elif \"\u8cea\u554f\" in output:\n        return f\"\u2753 Q&amp;A\u5bfe\u5fdc: {output}\"\n    else:\n        return f\"\ud83d\udcdd \u901a\u5e38\u5bfe\u5fdc: {output}\"\n\npipeline = AgentPipeline(\n    name=\"router\",\n    generation_instructions=\"\u30e6\u30fc\u30b6\u30fc\u306e\u8981\u6c42\u3092\u5206\u6790\u3057\u3066\u304f\u3060\u3055\u3044\",\n    evaluation_instructions=None,\n    routing_func=my_routing_func  # \u51fa\u529b\u306b\u5fdc\u3058\u3066\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\n)\n\nresult = pipeline.run(\"\u30b7\u30b9\u30c6\u30e0\u304c\u505c\u6b62\u3057\u3066\u3044\u307e\u3059\uff01\u52a9\u3051\u3066\uff01\")\n# \u7d50\u679c: \"\ud83d\udea8 \u7dca\u6025\u5bfe\u5fdc: \u30b7\u30b9\u30c6\u30e0\u304c\u505c\u6b62\u3057\u3066\u304a\u308a\u3001\u7dca\u6025\u5bfe\u5fdc\u304c\u5fc5\u8981\u3067\u3059\u3002\"\n</code></pre>"},{"location":"tutorials/routing_migration/#flowstep","title":"Flow/Step\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3067\u306e\u5b9f\u73fe\u65b9\u6cd5","text":""},{"location":"tutorials/routing_migration/#1","title":"1. \u57fa\u672c\u7684\u306a\u6761\u4ef6\u5206\u5c90\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0","text":"<p><code>ConditionStep</code>\u3092\u4f7f\u7528\u3057\u305f\u6761\u4ef6\u5206\u5c90\u3067\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u3092\u5b9f\u73fe\uff1a</p> <pre><code>from agents_sdk_models import Flow, ConditionStep, create_simple_gen_agent\nimport asyncio\n\n# Step 1: \u5206\u6790\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\uff08\u5143\u306eAgentPipeline\u306e\u751f\u6210\u90e8\u5206\uff09\nanalyzer = create_simple_gen_agent(\n    name=\"analyzer\",\n    instructions=\"\"\"\n    \u30e6\u30fc\u30b6\u30fc\u306e\u8981\u6c42\u3092\u5206\u6790\u3057\u3001\u4ee5\u4e0b\u306e\u30ab\u30c6\u30b4\u30ea\u306b\u5206\u985e\u3057\u3066\u304f\u3060\u3055\u3044\uff1a\n    - \u7dca\u6025: \u30b7\u30b9\u30c6\u30e0\u969c\u5bb3\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u554f\u984c\u306a\u3069\n    - \u8cea\u554f: \u60c5\u5831\u3092\u6c42\u3081\u308b\u554f\u3044\u5408\u308f\u305b\n    - \u901a\u5e38: \u305d\u306e\u4ed6\u306e\u4e00\u822c\u7684\u306a\u8981\u6c42\n\n    \u5206\u985e\u7d50\u679c\u3092\u660e\u78ba\u306b\u8a18\u8f09\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    \"\"\",\n    model=\"gpt-4o-mini\"\n)\n\n# Step 2: \u6761\u4ef6\u95a2\u6570\uff08\u5143\u306erouting_func\u306e\u30ed\u30b8\u30c3\u30af\uff09\ndef is_urgent(ctx):\n    \"\"\"\u7dca\u6025\u5ea6\u5224\u5b9a\"\"\"\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n    return \"\u7dca\u6025\" in result or \"\u969c\u5bb3\" in result or \"\u505c\u6b62\" in result\n\ndef is_question(ctx):\n    \"\"\"\u8cea\u554f\u30bf\u30a4\u30d7\u5224\u5b9a\"\"\"\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n    return \"\u8cea\u554f\" in result or \"\u554f\u3044\u5408\u308f\u305b\" in result or \"\u6559\u3048\u3066\" in result\n\n# Step 3: \u5404\u7a2e\u5bfe\u5fdc\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\nurgent_agent = create_simple_gen_agent(\n    name=\"urgent_handler\",\n    instructions=\"\u7dca\u6025\u4e8b\u614b\u306b\u8fc5\u901f\u304b\u3064\u9069\u5207\u306b\u5bfe\u5fdc\u3057\u307e\u3059\u3002\u5177\u4f53\u7684\u306a\u89e3\u6c7a\u624b\u9806\u3092\u63d0\u793a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o\"  # \u7dca\u6025\u6642\u306f\u9ad8\u6027\u80fd\u30e2\u30c7\u30eb\n)\n\nqa_agent = create_simple_gen_agent(\n    name=\"qa_handler\",\n    instructions=\"\u8cea\u554f\u306b\u8a73\u3057\u304f\u3001\u5206\u304b\u308a\u3084\u3059\u304f\u56de\u7b54\u3057\u307e\u3059\u3002\u95a2\u9023\u60c5\u5831\u3082\u542b\u3081\u3066\u8aac\u660e\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\nnormal_agent = create_simple_gen_agent(\n    name=\"normal_handler\",\n    instructions=\"\u4e00\u822c\u7684\u306a\u8981\u6c42\u306b\u4e01\u5be7\u306b\u5bfe\u5fdc\u3057\u307e\u3059\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# Step 4: \u30d5\u30ed\u30fc\u69cb\u7bc9\uff08\u591a\u6bb5\u968e\u6761\u4ef6\u5206\u5c90\uff09\nflow = Flow(\n    start=\"analyzer\",\n    steps={\n        \"analyzer\": analyzer,\n        \"urgent_check\": ConditionStep(\n            \"urgent_check\", \n            is_urgent, \n            if_true=\"urgent_handler\",\n            if_false=\"question_check\"\n        ),\n        \"question_check\": ConditionStep(\n            \"question_check\",\n            is_question,\n            if_true=\"qa_handler\",\n            if_false=\"normal_handler\"\n        ),\n        \"urgent_handler\": urgent_agent,\n        \"qa_handler\": qa_agent,\n        \"normal_handler\": normal_agent\n    }\n)\n\n# \u5b9f\u884c\u4f8b\nasync def run_routing_example():\n    # \u7dca\u6025\u4e8b\u614b\u306e\u4f8b\n    result1 = await flow.run(\"\u30b7\u30b9\u30c6\u30e0\u304c\u505c\u6b62\u3057\u3066\u3044\u307e\u3059\uff01\u52a9\u3051\u3066\uff01\")\n    print(\"\u7dca\u6025\u5bfe\u5fdc:\", result1.shared_state.get(\"urgent_handler_result\"))\n\n    # \u8cea\u554f\u306e\u4f8b\n    result2 = await flow.run(\"Python\u306e\u4f7f\u3044\u65b9\u3092\u6559\u3048\u3066\u304f\u3060\u3055\u3044\")\n    print(\"Q&amp;A\u5bfe\u5fdc:\", result2.shared_state.get(\"qa_handler_result\"))\n\n    # \u901a\u5e38\u8981\u6c42\u306e\u4f8b\n    result3 = await flow.run(\"\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3057\u305f\u3044\u3067\u3059\")\n    print(\"\u901a\u5e38\u5bfe\u5fdc:\", result3.shared_state.get(\"normal_handler_result\"))\n\n# \u5b9f\u884c\nasyncio.run(run_routing_example())\n</code></pre>"},{"location":"tutorials/routing_migration/#2","title":"2. \u52d5\u7684\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u95a2\u6570\u306b\u3088\u308b\u30a2\u30d7\u30ed\u30fc\u30c1","text":"<p>\u3088\u308a\u67d4\u8edf\u306a\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u30ed\u30b8\u30c3\u30af\u306b\u306f<code>FunctionStep</code>\u3092\u4f7f\u7528\uff1a</p> <pre><code>from agents_sdk_models import FunctionStep\n\ndef dynamic_router(user_input, ctx):\n    \"\"\"\u52d5\u7684\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u95a2\u6570\uff08routing_func\u306e\u76f4\u63a5\u7684\u306a\u7f6e\u304d\u63db\u3048\uff09\"\"\"\n    analysis_result = ctx.shared_state.get(\"analyzer_result\", \"\")\n\n    # AgentPipeline\u306erouting_func\u3068\u540c\u69d8\u306e\u30ed\u30b8\u30c3\u30af\n    if \"\u7dca\u6025\" in analysis_result or \"\u969c\u5bb3\" in analysis_result:\n        ctx.goto(\"urgent_handler\")\n        ctx.shared_state[\"route_decision\"] = \"\u7dca\u6025\u5bfe\u5fdc\u30eb\u30fc\u30c8\"\n        ctx.shared_state[\"priority\"] = \"high\"\n    elif \"\u8cea\u554f\" in analysis_result or \"\u6559\u3048\u3066\" in analysis_result:\n        ctx.goto(\"qa_handler\")\n        ctx.shared_state[\"route_decision\"] = \"Q&amp;A\u30eb\u30fc\u30c8\"\n        ctx.shared_state[\"priority\"] = \"medium\"\n    else:\n        ctx.goto(\"normal_handler\")\n        ctx.shared_state[\"route_decision\"] = \"\u901a\u5e38\u5bfe\u5fdc\u30eb\u30fc\u30c8\"\n        ctx.shared_state[\"priority\"] = \"low\"\n\n    # \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u7406\u7531\u3092\u30ed\u30b0\u51fa\u529b\n    ctx.add_system_message(f\"\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u6c7a\u5b9a: {ctx.shared_state['route_decision']}\")\n\n    return ctx\n\n# \u30d5\u30ed\u30fc\u69cb\u7bc9\uff08\u5358\u4e00\u306e\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u95a2\u6570\u4f7f\u7528\uff09\nrouter_step = FunctionStep(\"router\", dynamic_router)\n\nflow = Flow(\n    start=\"analyzer\",\n    steps={\n        \"analyzer\": analyzer,\n        \"router\": router_step,  # \u52d5\u7684\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\n        \"urgent_handler\": urgent_agent,\n        \"qa_handler\": qa_agent,\n        \"normal_handler\": normal_agent\n    }\n)\n</code></pre>"},{"location":"tutorials/routing_migration/#3","title":"3. \u8907\u96d1\u306a\u591a\u6bb5\u968e\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0","text":"<p>\u8907\u6570\u306e\u6761\u4ef6\u3092\u7d44\u307f\u5408\u308f\u305b\u305f\u9ad8\u5ea6\u306a\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u30d1\u30bf\u30fc\u30f3\uff1a</p> <pre><code># \u591a\u6bb5\u968e\u6761\u4ef6\u5206\u5c90\u306e\u4f8b\ndef check_user_level(ctx):\n    \"\"\"\u30e6\u30fc\u30b6\u30fc\u30ec\u30d9\u30eb\u78ba\u8a8d\"\"\"\n    return ctx.shared_state.get(\"user_level\", \"beginner\") == \"expert\"\n\ndef check_complexity(ctx):\n    \"\"\"\u8907\u96d1\u5ea6\u5224\u5b9a\"\"\"\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n    return \"\u8907\u96d1\" in result or \"\u9ad8\u5ea6\" in result\n\n# \u5c02\u9580\u5bb6\u5411\u3051\u3001\u521d\u5fc3\u8005\u5411\u3051\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u8ffd\u52a0\nexpert_agent = create_simple_gen_agent(\n    name=\"expert_handler\",\n    instructions=\"\u5c02\u9580\u7684\u306a\u5185\u5bb9\u3092\u6280\u8853\u7684\u8a73\u7d30\u3092\u542b\u3081\u3066\u8aac\u660e\u3057\u307e\u3059\u3002\",\n    model=\"gpt-4o\"\n)\n\nbeginner_agent = create_simple_gen_agent(\n    name=\"beginner_handler\", \n    instructions=\"\u521d\u5fc3\u8005\u5411\u3051\u306b\u5206\u304b\u308a\u3084\u3059\u304f\u3001\u6bb5\u968e\u7684\u306b\u8aac\u660e\u3057\u307e\u3059\u3002\",\n    model=\"gpt-4o-mini\"\n)\n\n# \u8907\u96d1\u306a\u30d5\u30ed\u30fc\u69cb\u7bc9\ncomplex_flow = Flow(\n    start=\"analyzer\",\n    steps={\n        \"analyzer\": analyzer,\n\n        # 1\u6bb5\u968e\u76ee\uff1a\u7dca\u6025\u5ea6\u5224\u5b9a\n        \"urgent_check\": ConditionStep(\n            \"urgent_check\",\n            is_urgent,\n            if_true=\"urgent_handler\",\n            if_false=\"user_level_check\"\n        ),\n\n        # 2\u6bb5\u968e\u76ee\uff1a\u30e6\u30fc\u30b6\u30fc\u30ec\u30d9\u30eb\u5224\u5b9a\n        \"user_level_check\": ConditionStep(\n            \"user_level_check\",\n            check_user_level,\n            if_true=\"expert_complexity_check\",\n            if_false=\"beginner_complexity_check\"\n        ),\n\n        # 3\u6bb5\u968e\u76ee\uff1a\u8907\u96d1\u5ea6\u5224\u5b9a\uff08\u5c02\u9580\u5bb6\u5411\u3051\uff09\n        \"expert_complexity_check\": ConditionStep(\n            \"expert_complexity_check\",\n            check_complexity,\n            if_true=\"expert_handler\",\n            if_false=\"qa_handler\"\n        ),\n\n        # 3\u6bb5\u968e\u76ee\uff1a\u8907\u96d1\u5ea6\u5224\u5b9a\uff08\u521d\u5fc3\u8005\u5411\u3051\uff09\n        \"beginner_complexity_check\": ConditionStep(\n            \"beginner_complexity_check\",\n            check_complexity,\n            if_true=\"beginner_handler\",\n            if_false=\"normal_handler\"\n        ),\n\n        # \u5404\u7a2e\u5bfe\u5fdc\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\n        \"urgent_handler\": urgent_agent,\n        \"expert_handler\": expert_agent,\n        \"beginner_handler\": beginner_agent,\n        \"qa_handler\": qa_agent,\n        \"normal_handler\": normal_agent\n    }\n)\n</code></pre>"},{"location":"tutorials/routing_migration/#4","title":"4. \u5b9f\u7528\u7684\u306a\u30c8\u30ea\u30a2\u30fc\u30b8\u30b7\u30b9\u30c6\u30e0\u4f8b","text":"<p>\u5b9f\u969b\u306e\u30ab\u30b9\u30bf\u30de\u30fc\u30b5\u30dd\u30fc\u30c8\u30b7\u30b9\u30c6\u30e0\u3092\u60f3\u5b9a\u3057\u305f\u5b9f\u88c5\uff1a</p> <pre><code>from agents_sdk_models import UserInputStep\n\ndef analyze_customer_request(user_input, ctx):\n    \"\"\"\u9867\u5ba2\u8981\u6c42\u306e\u8a73\u7d30\u5206\u6790\"\"\"\n    request = ctx.last_user_input.lower()\n\n    # \u7dca\u6025\u5ea6\u30b9\u30b3\u30a2\u8a08\u7b97\n    urgency_score = 0\n    if any(word in request for word in [\"\u505c\u6b62\", \"\u969c\u5bb3\", \"\u30a8\u30e9\u30fc\", \"\u7dca\u6025\"]):\n        urgency_score += 3\n    if any(word in request for word in [\"\u9045\u3044\", \"\u554f\u984c\", \"\u56f0\u3063\u3066\u3044\u308b\"]):\n        urgency_score += 2\n    if any(word in request for word in [\"\u8cea\u554f\", \"\u6559\u3048\u3066\", \"\u65b9\u6cd5\"]):\n        urgency_score += 1\n\n    # \u30ab\u30c6\u30b4\u30ea\u5224\u5b9a\n    if \"\u8acb\u6c42\" in request or \"\u6599\u91d1\" in request:\n        category = \"billing\"\n    elif \"\u6280\u8853\" in request or \"\u8a2d\u5b9a\" in request:\n        category = \"technical\"\n    elif \"\u89e3\u7d04\" in request or \"\u5909\u66f4\" in request:\n        category = \"account\"\n    else:\n        category = \"general\"\n\n    # \u7d50\u679c\u3092\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u4fdd\u5b58\n    ctx.shared_state.update({\n        \"urgency_score\": urgency_score,\n        \"category\": category,\n        \"original_request\": ctx.last_user_input\n    })\n\n    return ctx\n\n# \u30c8\u30ea\u30a2\u30fc\u30b8\u6761\u4ef6\u95a2\u6570\ndef is_high_priority(ctx):\n    return ctx.shared_state.get(\"urgency_score\", 0) &gt;= 3\n\ndef is_billing_issue(ctx):\n    return ctx.shared_state.get(\"category\") == \"billing\"\n\ndef is_technical_issue(ctx):\n    return ctx.shared_state.get(\"category\") == \"technical\"\n\n# \u5c02\u9580\u5bfe\u5fdc\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\nbilling_agent = create_simple_gen_agent(\n    name=\"billing_specialist\",\n    instructions=\"\u8acb\u6c42\u30fb\u6599\u91d1\u306b\u95a2\u3059\u308b\u5c02\u9580\u5bfe\u5fdc\u3092\u884c\u3044\u307e\u3059\u3002\u6b63\u78ba\u306a\u60c5\u5831\u3092\u63d0\u4f9b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o\"\n)\n\ntechnical_agent = create_simple_gen_agent(\n    name=\"technical_specialist\",\n    instructions=\"\u6280\u8853\u7684\u306a\u554f\u984c\u306b\u5bfe\u5fdc\u3057\u307e\u3059\u3002\u5177\u4f53\u7684\u306a\u89e3\u6c7a\u624b\u9806\u3092\u63d0\u793a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o\"\n)\n\n# \u30ab\u30b9\u30bf\u30de\u30fc\u30b5\u30dd\u30fc\u30c8\u30d5\u30ed\u30fc\nsupport_flow = Flow(\n    start=\"welcome\",\n    steps={\n        \"welcome\": UserInputStep(\n            \"welcome\", \n            \"\u304a\u56f0\u308a\u306e\u5185\u5bb9\u3092\u8a73\u3057\u304f\u6559\u3048\u3066\u304f\u3060\u3055\u3044\uff1a\",\n            \"analyze\"\n        ),\n        \"analyze\": FunctionStep(\"analyze\", analyze_customer_request, \"priority_check\"),\n        \"priority_check\": ConditionStep(\n            \"priority_check\",\n            is_high_priority,\n            if_true=\"urgent_handler\",\n            if_false=\"category_routing\"\n        ),\n        \"category_routing\": ConditionStep(\n            \"category_routing\",\n            is_billing_issue,\n            if_true=\"billing_specialist\",\n            if_false=\"tech_check\"\n        ),\n        \"tech_check\": ConditionStep(\n            \"tech_check\",\n            is_technical_issue,\n            if_true=\"technical_specialist\",\n            if_false=\"normal_handler\"\n        ),\n        \"urgent_handler\": urgent_agent,\n        \"billing_specialist\": billing_agent,\n        \"technical_specialist\": technical_agent,\n        \"normal_handler\": normal_agent\n    }\n)\n</code></pre>"},{"location":"tutorials/routing_migration/#_3","title":"\u79fb\u884c\u30e1\u30ea\u30c3\u30c8\u306e\u6bd4\u8f03","text":"\u9805\u76ee AgentPipeline routing_func Flow/Step \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3 \u5b9f\u88c5\u65b9\u5f0f \u5358\u4e00\u95a2\u6570\u5185\u3067\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0 \u30b9\u30c6\u30c3\u30d7\u5206\u96e2\u306b\u3088\u308b\u660e\u78ba\u306a\u5236\u5fa1\u30d5\u30ed\u30fc \u6761\u4ef6\u306e\u8907\u96d1\u3055 \u8907\u96d1\u306b\u306a\u308b\u3068\u4fdd\u5b88\u56f0\u96e3 \u6bb5\u968e\u7684\u6761\u4ef6\u5206\u5c90\u3067\u7ba1\u7406\u3057\u3084\u3059\u3044 \u518d\u5229\u7528\u6027 \u95a2\u6570\u5358\u4f4d\u3067\u306e\u518d\u5229\u7528\u306e\u307f \u30b9\u30c6\u30c3\u30d7\u5358\u4f4d\u3067\u67d4\u8edf\u306a\u518d\u5229\u7528 \u30c7\u30d0\u30c3\u30b0 \u30d6\u30e9\u30c3\u30af\u30dc\u30c3\u30af\u30b9\u5316\u3057\u3084\u3059\u3044 \u5404\u30b9\u30c6\u30c3\u30d7\u3067\u72b6\u614b\u78ba\u8a8d\u53ef\u80fd \u62e1\u5f35\u6027 \u6761\u4ef6\u8ffd\u52a0\u6642\u306b\u5168\u4f53\u4fee\u6b63\u5fc5\u8981 \u65b0\u3057\u3044\u30b9\u30c6\u30c3\u30d7\u8ffd\u52a0\u3067\u5bfe\u5fdc \u30c6\u30b9\u30c8 \u7d71\u5408\u30c6\u30b9\u30c8\u304c\u4e2d\u5fc3 \u30b9\u30c6\u30c3\u30d7\u5358\u4f4d\u3067\u30e6\u30cb\u30c3\u30c8\u30c6\u30b9\u30c8\u53ef\u80fd \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9 \u5358\u4e00\u5b9f\u884c\u3067\u5b8c\u7d50 \u30b9\u30c6\u30c3\u30d7\u9593\u306e\u30aa\u30fc\u30d0\u30fc\u30d8\u30c3\u30c9\u3042\u308a \u4fdd\u5b88\u6027 \u4fee\u6b63\u6642\u306e\u5f71\u97ff\u7bc4\u56f2\u304c\u5e83\u3044 \u5909\u66f4\u306e\u5f71\u97ff\u7bc4\u56f2\u3092\u9650\u5b9a\u53ef\u80fd"},{"location":"tutorials/routing_migration/#_4","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"tutorials/routing_migration/#1_1","title":"1. \u6bb5\u968e\u7684\u79fb\u884c","text":"<pre><code># Step 1: \u65e2\u5b58\u306erouting_func\u3092FunctionStep\u306b\u79fb\u884c\ndef legacy_router(user_input, ctx):\n    \"\"\"\u65e2\u5b58\u306erouting_func\u3092\u305d\u306e\u307e\u307e\u79fb\u690d\"\"\"\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n\n    # \u65e2\u5b58\u306erouting_func\u30ed\u30b8\u30c3\u30af\u3092\u305d\u306e\u307e\u307e\u4f7f\u7528\n    if \"\u7dca\u6025\" in result:\n        routed_result = f\"\ud83d\udea8 \u7dca\u6025\u5bfe\u5fdc: {result}\"\n        ctx.shared_state[\"final_result\"] = routed_result\n        ctx.finish()  # \u30d5\u30ed\u30fc\u7d42\u4e86\n    elif \"\u8cea\u554f\" in result:\n        routed_result = f\"\u2753 Q&amp;A\u5bfe\u5fdc: {result}\"\n        ctx.shared_state[\"final_result\"] = routed_result\n        ctx.finish()\n    else:\n        routed_result = f\"\ud83d\udcdd \u901a\u5e38\u5bfe\u5fdc: {result}\"\n        ctx.shared_state[\"final_result\"] = routed_result\n        ctx.finish()\n\n    return ctx\n\n# Step 2: \u5f90\u3005\u306bConditionStep\u306b\u5206\u5272\n# Step 3: \u6700\u7d42\u7684\u306b\u5c02\u7528\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306b\u7f6e\u304d\u63db\u3048\n</code></pre>"},{"location":"tutorials/routing_migration/#2_1","title":"2. \u6761\u4ef6\u95a2\u6570\u306e\u8a2d\u8a08\u6307\u91dd","text":"<pre><code># \u2705 \u826f\u3044\u4f8b\uff1a\u5358\u4e00\u8cac\u4efb\u306e\u6761\u4ef6\u95a2\u6570\ndef is_urgent_request(ctx):\n    \"\"\"\u7dca\u6025\u8981\u6c42\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\u3059\u308b\u5358\u4e00\u76ee\u7684\u95a2\u6570\"\"\"\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n    urgent_keywords = [\"\u7dca\u6025\", \"\u969c\u5bb3\", \"\u505c\u6b62\", \"\u30a8\u30e9\u30fc\", \"\u554f\u984c\"]\n    return any(keyword in result for keyword in urgent_keywords)\n\ndef has_high_priority_user(ctx):\n    \"\"\"\u9ad8\u512a\u5148\u5ea6\u30e6\u30fc\u30b6\u30fc\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\"\"\"\n    user_level = ctx.shared_state.get(\"user_level\", \"standard\")\n    return user_level in [\"premium\", \"enterprise\"]\n\n# \u274c \u907f\u3051\u308b\u3079\u304d\u4f8b\uff1a\u8907\u6570\u306e\u8cac\u4efb\u3092\u6301\u3064\u6761\u4ef6\u95a2\u6570\ndef complex_routing_logic(ctx):\n    \"\"\"\u8907\u96d1\u3059\u304e\u308b\u6761\u4ef6\u5224\u5b9a\uff08\u907f\u3051\u308b\u3079\u304d\uff09\"\"\"\n    result = ctx.shared_state.get(\"analyzer_result\", \"\")\n    user_level = ctx.shared_state.get(\"user_level\", \"standard\")\n    time_of_day = ctx.shared_state.get(\"current_time\", 12)\n\n    # \u8907\u6570\u306e\u6761\u4ef6\u304c\u6df7\u5728\u3057\u3066\u304a\u308a\u3001\u4fdd\u5b88\u56f0\u96e3\n    if (\"\u7dca\u6025\" in result and user_level == \"premium\") or \\\n       (\"\u8cea\u554f\" in result and 9 &lt;= time_of_day &lt;= 17) or \\\n       (user_level == \"enterprise\"):\n        return True\n    return False\n</code></pre>"},{"location":"tutorials/routing_migration/#3_1","title":"3. \u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0","text":"<pre><code>def safe_condition_check(ctx):\n    \"\"\"\u5b89\u5168\u306a\u6761\u4ef6\u30c1\u30a7\u30c3\u30af\uff08\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u4ed8\u304d\uff09\"\"\"\n    try:\n        result = ctx.shared_state.get(\"analyzer_result\", \"\")\n        if not result:\n            # \u5206\u6790\u7d50\u679c\u304c\u306a\u3044\u5834\u5408\u306e\u30d5\u30a9\u30fc\u30eb\u30d0\u30c3\u30af\n            ctx.add_system_message(\"\u8b66\u544a: \u5206\u6790\u7d50\u679c\u304c\u898b\u3064\u304b\u308a\u307e\u305b\u3093\")\n            return False\n\n        return \"\u7dca\u6025\" in result.lower()\n\n    except Exception as e:\n        # \u30a8\u30e9\u30fc\u6642\u306f\u5b89\u5168\u5074\uff08False\uff09\u306b\u5012\u3059\n        ctx.add_system_message(f\"\u6761\u4ef6\u30c1\u30a7\u30c3\u30af\u30a8\u30e9\u30fc: {e}\")\n        return False\n\n# \u30a8\u30e9\u30fc\u5bfe\u5fdc\u30b9\u30c6\u30c3\u30d7\u306e\u8ffd\u52a0\nerror_handler = create_simple_gen_agent(\n    name=\"error_handler\",\n    instructions=\"\u30b7\u30b9\u30c6\u30e0\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u307e\u3057\u305f\u3002\u304a\u5ba2\u69d8\u306b\u306f\u4e01\u5be7\u306b\u8b1d\u7f6a\u3057\u3001\u4ee3\u66ff\u624b\u6bb5\u3092\u63d0\u793a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre>"},{"location":"tutorials/routing_migration/#_5","title":"\u307e\u3068\u3081","text":"<p>Flow/Step\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3067\u306f\u3001AgentPipeline\u306e<code>routing_func</code>\u3088\u308a\u3082\uff1a</p> <ol> <li>\u660e\u78ba\u306a\u5236\u5fa1\u30d5\u30ed\u30fc - \u5404\u30b9\u30c6\u30c3\u30d7\u306e\u8cac\u4efb\u304c\u660e\u78ba</li> <li>\u6bb5\u968e\u7684\u306a\u6761\u4ef6\u5206\u5c90 - \u8907\u96d1\u306a\u30ed\u30b8\u30c3\u30af\u3082\u7ba1\u7406\u3057\u3084\u3059\u3044</li> <li>\u9ad8\u3044\u518d\u5229\u7528\u6027 - \u30b9\u30c6\u30c3\u30d7\u5358\u4f4d\u3067\u306e\u7d44\u307f\u5408\u308f\u305b\u304c\u53ef\u80fd</li> <li>\u512a\u308c\u305f\u4fdd\u5b88\u6027 - \u5909\u66f4\u306e\u5f71\u97ff\u7bc4\u56f2\u3092\u9650\u5b9a\u53ef\u80fd</li> <li>\u8c4a\u5bcc\u306a\u30c7\u30d0\u30c3\u30b0\u60c5\u5831 - \u5404\u30b9\u30c6\u30c3\u30d7\u3067\u72b6\u614b\u78ba\u8a8d\u53ef\u80fd</li> </ol> <p>\u3053\u308c\u306b\u3088\u308a\u3001\u3088\u308a\u5805\u7262\u3067\u62e1\u5f35\u6027\u306e\u9ad8\u3044\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u69cb\u7bc9\u3067\u304d\u307e\u3059\u3002 </p>"}]}