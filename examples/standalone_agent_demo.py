"""
GenAgent, ClarifyAgent, LLMPipelineã®å˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢
Standalone execution demo for GenAgent, ClarifyAgent, and LLMPipeline

ã“ã®ãƒ‡ãƒ¢ã§ã¯ã€Flowã‚’ä½¿ã‚ãšã«å„Agentã‚’ç›´æ¥å˜ä½“ã§å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚
This demo shows how to run each Agent directly without using Flow.
"""

import asyncio
from typing import List
from pydantic import BaseModel

from agents_sdk_models import (
    GenAgent, ClarifyAgent, LLMPipeline, Context,
    create_simple_gen_agent, create_simple_clarify_agent,
    create_simple_llm_pipeline, create_evaluated_llm_pipeline,
    ClarificationResult
)


# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾© / Data model definition
class TaskRequest(BaseModel):
    """
    Task request data model
    ã‚¿ã‚¹ã‚¯è¦æ±‚ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
    """
    task_name: str      # Task name / ã‚¿ã‚¹ã‚¯å
    priority: str       # Priority level / å„ªå…ˆåº¦
    deadline: str       # Deadline / ç· åˆ‡
    description: str    # Task description / ã‚¿ã‚¹ã‚¯èª¬æ˜


async def demo_genagent_standalone():
    """
    GenAgentå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢
    GenAgent standalone execution demo
    """
    print("ğŸ¤– === GenAgentå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢ / GenAgent Standalone Demo ===")
    
    # 1. GenAgentã‚’ç›´æ¥ä½œæˆ
    # Create GenAgent directly
    agent = create_simple_gen_agent(
        name="story_generator",
        instructions="""
        ã‚ãªãŸã¯å‰µé€ çš„ãªç‰©èªä½œå®¶ã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åŸºã¥ã„ã¦çŸ­ã„ç‰©èªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        You are a creative story writer.
        Generate short stories based on user requests.
        """,
        model="gpt-4o-mini"
    )
    
    # 2. Contextä½œæˆï¼ˆFlowãªã—ã§ã‚‚å˜ä½“å®Ÿè¡Œå¯èƒ½ï¼‰
    # Create Context (can run standalone without Flow)
    context = Context()
    
    # 3. ç›´æ¥å®Ÿè¡Œ
    # Execute directly
    user_input = "å®‡å®™é£›è¡Œå£«ãŒæœªçŸ¥ã®æƒ‘æ˜Ÿã§ç™ºè¦‹ã—ãŸã‚‚ã®ã«ã¤ã„ã¦ã®ç‰©èª"
    print(f"ğŸ“ å…¥åŠ›: {user_input}")
    
    try:
        # GenAgentã‚’ç›´æ¥run
        # Run GenAgent directly
        result_context = await agent.run(user_input, context)
        
        # çµæœã‚’å–å¾—
        # Get result
        generated_story = result_context.shared_state.get("story_generator_result")
        print(f"âœ… ç”Ÿæˆã•ã‚ŒãŸç‰©èª:\n{generated_story}")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚‚ç¢ºèªå¯èƒ½
        # Message history is also available
        print(f"\nğŸ“š ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(result_context.messages)}")
        
    except Exception as e:
        print(f"âš ï¸ å®Ÿéš›ã®å®Ÿè¡Œã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e}")


async def demo_clarifyagent_standalone():
    """
    ClarifyAgentå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢ï¼ˆã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ«ãƒ¼ãƒ—ï¼‰
    ClarifyAgent standalone execution demo (Interactive Loop)
    """
    print("\nğŸ” === ClarifyAgentå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢ / ClarifyAgent Standalone Demo ===")
    
    # 1. ClarifyAgentã‚’ç›´æ¥ä½œæˆ
    # Create ClarifyAgent directly
    agent = create_simple_clarify_agent(
        name="task_clarifier",
        instructions="""
        ã‚ãªãŸã¯ã‚¿ã‚¹ã‚¯è¦ä»¶æ˜ç¢ºåŒ–ã®å°‚é–€å®¶ã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›–æ˜§ãªã‚¿ã‚¹ã‚¯è¦æ±‚ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã«è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚
        å¿…è¦ãªæƒ…å ±ãŒå…¨ã¦æƒã£ãŸã‚‰ã€ç¢ºå®šã—ãŸè¦ä»¶ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        You are a task requirement clarification specialist.
        Ask questions to clarify user's ambiguous task requests.
        Output confirmed requirements when all necessary information is gathered.
        """,
        output_data=TaskRequest,
        max_turns=5,
        model="gpt-4o-mini"
    )
    
    # 2. ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œç­”ãƒªã‚¹ãƒˆ
    # Simulated user responses for demo
    user_inputs = [
        "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ãŸã„",
        "ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã®é–‹ç™ºã§ã™",
        "é«˜å„ªå…ˆåº¦ã§æ¥é€±æœ«ã¾ã§ã«å®Œäº†ã•ã›ãŸã„",
        "æ–°æ©Ÿèƒ½ã®å®Ÿè£…ã€ç‰¹ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹"
    ]
    
    try:
        # 3. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ
        # Interactive loop execution
        context = Context()
        
        for turn, user_input in enumerate(user_inputs, 1):
            print(f"\nğŸ‘¤ ã‚¿ãƒ¼ãƒ³{turn}: {user_input}")
            
            # Agentå®Ÿè¡Œ
            # Run agent
            result_context = await agent.run(user_input, context)
            clarify_result = result_context.shared_state.get("task_clarifier_result")
            
            if isinstance(clarify_result, ClarificationResult):
                if clarify_result.is_complete:
                    print(f"âœ… æ˜ç¢ºåŒ–å®Œäº†: {clarify_result.data}")
                    break
                else:
                    print(f"ğŸ¤– è³ªå•: {clarify_result.data}")
                    print(f"   ğŸ“Š ã‚¿ãƒ¼ãƒ³é€²æ—: {clarify_result.turn}/{clarify_result.turn + clarify_result.remaining_turns}")
            
            # æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã®ãŸã‚ã«contextã‚’æ›´æ–°
            # Update context for next turn
            context = result_context
        
        else:
            print("â— æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ã«é”ã—ã¾ã—ãŸ / Maximum turns reached")
        
    except Exception as e:
        print(f"âš ï¸ å®Ÿéš›ã®å®Ÿè¡Œã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e}")


async def demo_clarifyagent_interactive_real():
    """
    ClarifyAgentå®Ÿéš›ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    ClarifyAgent real interactive demo (Optional)
    """
    print("\nğŸ® === ClarifyAgentå®Ÿéš›ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢ / ClarifyAgent Real Interactive Demo ===")
    print("ğŸ“ å®Ÿéš›ã«ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã§å¯¾è©±ã—ãŸã„å ´åˆã¯ã€ã“ã®ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¢ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„")
    print("To interact with real keyboard input, uncomment and use this function")
    
    """
    # ãƒªã‚¢ãƒ«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ç‰ˆï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
    # Real interaction version (commented out)
    
    agent = create_simple_clarify_agent(
        name="task_clarifier",
        instructions="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›–æ˜§ãªã‚¿ã‚¹ã‚¯è¦æ±‚ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã«è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚",
        output_data=TaskRequest,
        max_turns=10,
        model="gpt-4o-mini"
    )
    
    context = Context()
    print("ğŸ“ ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ï¼ˆ'quit'ã§çµ‚äº†ï¼‰:")
    
    while True:
        user_input = input("ğŸ‘¤ ã‚ãªãŸ: ").strip()
        if user_input.lower() in ['quit', 'exit', 'q']:
            break
            
        result_context = await agent.run(user_input, context)
        clarify_result = result_context.shared_state.get("task_clarifier_result")
        
        if isinstance(clarify_result, ClarificationResult):
            if clarify_result.is_complete:
                print(f"âœ… æ˜ç¢ºåŒ–å®Œäº†: {clarify_result.data}")
                break
            else:
                print(f"ğŸ¤– Agent: {clarify_result.data}")
        
        context = result_context
    """


def demo_llmpipeline_standalone():
    """
    LLMPipelineå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢
    LLMPipeline standalone execution demo
    """
    print("\nâš™ï¸ === LLMPipelineå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢ / LLMPipeline Standalone Demo ===")
    
    # 1. ã‚·ãƒ³ãƒ—ãƒ«ãªLLMPipelineã‚’ç›´æ¥ä½œæˆ
    # Create simple LLMPipeline directly
    pipeline = create_simple_llm_pipeline(
        name="code_reviewer",
        instructions="""
        ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚
        æä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã€æ”¹å–„ç‚¹ã‚„ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
        
        You are a code review specialist.
        Analyze provided code and suggest improvements and best practices.
        """,
        model="gpt-4o-mini"
    )
    
    # 2. ç›´æ¥å®Ÿè¡Œï¼ˆåŒæœŸï¼‰
    # Execute directly (synchronous)
    code_input = """
def calculate_total(items):
    total = 0
    for item in items:
        total = total + item['price']
    return total
    """
    
    print(f"ğŸ“ å…¥åŠ›ã‚³ãƒ¼ãƒ‰:\n{code_input}")
    
    try:
        # LLMPipelineã‚’ç›´æ¥run
        # Run LLMPipeline directly
        result = pipeline.run(code_input)
        
        if result.success:
            print(f"âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ:\n{result.content}")
            print(f"ğŸ”„ è©¦è¡Œå›æ•°: {result.attempts}")
            print(f"ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {result.metadata}")
        else:
            print(f"âŒ å®Ÿè¡Œå¤±æ•—: {result.metadata}")
            
    except Exception as e:
        print(f"âš ï¸ å®Ÿéš›ã®å®Ÿè¡Œã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e}")


def demo_evaluated_llmpipeline_standalone():
    """
    è©•ä¾¡æ©Ÿèƒ½ä»˜ãLLMPipelineå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢
    Evaluated LLMPipeline standalone execution demo
    """
    print("\nğŸ” === è©•ä¾¡æ©Ÿèƒ½ä»˜ãLLMPipelineå˜ä½“å®Ÿè¡Œãƒ‡ãƒ¢ / Evaluated LLMPipeline Standalone Demo ===")
    
    # 1. è©•ä¾¡æ©Ÿèƒ½ä»˜ãLLMPipelineã‚’ä½œæˆ
    # Create LLMPipeline with evaluation
    pipeline = create_evaluated_llm_pipeline(
        name="technical_writer",
        generation_instructions="""
        ã‚ãªãŸã¯æŠ€è¡“æ–‡æ›¸ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«åŸºã¥ã„ã¦ã€æ˜ç¢ºã§ç†è§£ã—ã‚„ã™ã„æŠ€è¡“æ–‡æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        You are a technical documentation specialist.
        Create clear and understandable technical documents based on user requests.
        """,
        evaluation_instructions="""
        ç”Ÿæˆã•ã‚ŒãŸæŠ€è¡“æ–‡æ›¸ã‚’ä»¥ä¸‹ã®åŸºæº–ã§è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š
        1. æ˜ç¢ºæ€§ã¨ç†è§£ã—ã‚„ã™ã• (0-25ç‚¹)
        2. æŠ€è¡“çš„æ­£ç¢ºæ€§ (0-25ç‚¹)
        3. æ§‹é€ ã¨çµ„ç¹”åŒ– (0-25ç‚¹)
        4. å®Ÿç”¨æ€§ã¨ä¾¡å€¤ (0-25ç‚¹)
        
        100ç‚¹æº€ç‚¹ã§ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã€ç°¡æ½”ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        
        Evaluate the generated technical document based on:
        1. Clarity and understandability (0-25 points)
        2. Technical accuracy (0-25 points)
        3. Structure and organization (0-25 points)
        4. Practicality and value (0-25 points)
        
        Provide a score out of 100 and brief feedback.
        """,
        model="gpt-4o-mini",
        threshold=75.0,
        max_retries=2
    )
    
    # 2. å®Ÿè¡Œ
    # Execute
    request = "APIã®ä½¿ç”¨æ–¹æ³•ã«ã¤ã„ã¦ã€åˆå¿ƒè€…å‘ã‘ã®ã‚¬ã‚¤ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„"
    print(f"ğŸ“ è¦æ±‚: {request}")
    print(f"ğŸ¯ å“è³ªé–¾å€¤: {pipeline.threshold}%")
    
    try:
        result = pipeline.run(request)
        
        if result.success:
            print(f"âœ… é«˜å“è³ªæ–‡æ›¸ç”ŸæˆæˆåŠŸ:")
            print(f"ğŸ“„ å†…å®¹: {result.content[:300]}...")
            print(f"â­ è©•ä¾¡ã‚¹ã‚³ã‚¢: {result.evaluation_score}%")
            print(f"ğŸ”„ è©¦è¡Œå›æ•°: {result.attempts}")
        else:
            print(f"âŒ å“è³ªé–¾å€¤æœªé”æˆ: {result.metadata}")
            
    except Exception as e:
        print(f"âš ï¸ å®Ÿéš›ã®å®Ÿè¡Œã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e}")


async def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    Main execution function
    """
    print("ğŸš€ === Agentå˜ä½“å®Ÿè¡Œç·åˆãƒ‡ãƒ¢ / Comprehensive Agent Standalone Demo ===")
    print("ã“ã®ãƒ‡ãƒ¢ã§ã¯ã€Flowã‚’ä½¿ã‚ãšã«å„Agentã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚")
    print("This demo shows how to run each Agent directly without using Flow.\n")
    
    # å„Agentã®å˜ä½“å®Ÿè¡Œã‚’ãƒ‡ãƒ¢
    # Demo standalone execution of each Agent
    await demo_genagent_standalone()
    await demo_clarifyagent_standalone()
    demo_llmpipeline_standalone()
    demo_evaluated_llmpipeline_standalone()
    
    print("\n" + "="*60)
    print("ğŸ“‹ === å˜ä½“å®Ÿè¡Œã¾ã¨ã‚ / Standalone Execution Summary ===")
    print("âœ… GenAgent: å˜ä½“å®Ÿè¡Œå¯èƒ½ï¼ˆéåŒæœŸï¼‰/ Standalone execution possible (async)")
    print("âœ… ClarifyAgent: å˜ä½“å®Ÿè¡Œå¯èƒ½ãƒ»ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–å¯¾å¿œ / Standalone interactive execution")
    print("âœ… LLMPipeline: å˜ä½“å®Ÿè¡Œå¯èƒ½ï¼ˆåŒæœŸãƒ»éåŒæœŸä¸¡å¯¾å¿œï¼‰/ Standalone sync/async execution")
    print("âœ… å…¨ã¦ã®AgentãŒFlowãªã—ã§ä½¿ç”¨å¯èƒ½ / All Agents can be used without Flow")
    print("âœ… ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ã‚‚å˜ä½“ã§å‹•ä½œ / Interactive features work standalone")


if __name__ == "__main__":
    asyncio.run(main()) 